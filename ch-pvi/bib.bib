
%% Created for Jaan Altosaar at 2020-10-15 08:38:49 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{saxe2013exact,
	Author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	Date-Added = {2017-05-19 05:23:44 +0000},
	Date-Modified = {2020-04-17 10:45:51 -0400},
	Journal = {International Conference on Learning Representations},
	Title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	Year = {2014}}

@inproceedings{DBLP:journals/jmlr/GlorotB10,
	Author = {Xavier Glorot and Yoshua Bengio},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/jmlr/GlorotB10},
	Booktitle = {Artificial Intelligence and Statistics},
	Crossref = {DBLP:conf/aistats/2010},
	Date-Added = {2017-05-19 03:09:51 +0000},
	Date-Modified = {2017-05-19 15:08:48 +0000},
	Pages = {249--256},
	Timestamp = {Thu, 11 Sep 2014 07:28:56 +0200},
	Title = {Understanding the difficulty of training deep feedforward neural networks},
	Url = {http://www.jmlr.org/proceedings/papers/v9/glorot10a.html},
	Year = {2010},
	Bdsk-Url-1 = {http://www.jmlr.org/proceedings/papers/v9/glorot10a.html}}

@inproceedings{pmlr-v15-larochelle11a,
	Abstract = {We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size. Our model circumvents this difficulty by decomposing the joint distribution of observations into tractable conditional distributions and modeling each conditional using a non-linear function similar to a conditional of an RBM. Our model can also be interpreted as an autoencoder wired such that its output can be used to assign valid probabilities to observations. We show that this new model outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM.  },
	Author = {Hugo Larochelle and Iain Murray},
	Booktitle = {Artificial Intelligence and Statistics},
	Date-Added = {2017-05-19 03:04:32 +0000},
	Date-Modified = {2017-05-19 15:09:24 +0000},
	Pages = {29--37},
	Pdf = {http://proceedings.mlr.press/v15/larochelle11a/larochelle11a.pdf},
	Title = {The Neural Autoregressive Distribution Estimator},
	Url = {http://proceedings.mlr.press/v15/larochelle11a.html},
	Volume = {15},
	Year = {2011},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v15/larochelle11a.html}}

@article{Kirkpatrick671,
	Abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
	Author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
	Date-Added = {2017-05-18 02:30:25 +0000},
	Date-Modified = {2017-05-18 02:30:25 +0000},
	Doi = {10.1126/science.220.4598.671},
	Eprint = {http://science.sciencemag.org/content/220/4598/671.full.pdf},
	Issn = {0036-8075},
	Journal = {Science},
	Number = {4598},
	Pages = {671--680},
	Publisher = {American Association for the Advancement of Science},
	Title = {Optimization by Simulated Annealing},
	Url = {http://science.sciencemag.org/content/220/4598/671},
	Volume = {220},
	Year = {1983},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/220/4598/671},
	Bdsk-Url-2 = {http://dx.doi.org/10.1126/science.220.4598.671}}

@article{Katihara:2008,
	Abstract = {The Variational Bayes (VB) method is widely used as an approximation of the Bayesian method. Because the VB method is a gradient algorithm, it is often trapped by poor local optimal solutions. We introduce deterministic annealing to the VB method to overcome such a local optimal problem. A temperature parameter is introduced to the free energy for controlling the annealing process deterministically. Applying the method to a mixture of Gaussian models and hidden Markov models, we show that it can obtain the global optimum of the free energy and discover optimal model structure.},
	Author = {K Katahira and K Watanabe and M Okada},
	Date-Added = {2017-05-17 15:19:50 +0000},
	Date-Modified = {2017-05-17 15:19:50 +0000},
	Journal = {Journal of Physics: Conference Series},
	Number = {1},
	Pages = {012015},
	Title = {Deterministic annealing variant of variational Bayes method},
	Url = {http://stacks.iop.org/1742-6596/95/i=1/a=012015},
	Volume = {95},
	Year = {2008},
	Bdsk-Url-1 = {http://stacks.iop.org/1742-6596/95/i=1/a=012015}}

@inproceedings{Mohamed:2015:VIM:2969442.2969477,
	Acmid = {2969477},
	Address = {Cambridge, MA, USA},
	Author = {Mohamed, Shakir and Rezende, Danilo J.},
	Booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems},
	Date-Added = {2017-05-13 11:47:38 +0000},
	Date-Modified = {2017-05-13 11:47:38 +0000},
	Location = {Montreal, Canada},
	Numpages = {9},
	Pages = {2125--2133},
	Publisher = {MIT Press},
	Series = {NIPS'15},
	Title = {Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning},
	Url = {http://dl.acm.org/citation.cfm?id=2969442.2969477},
	Year = {2015},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2969442.2969477}}

@article{sonderby2016ladder,
	Author = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
	Date-Added = {2017-05-13 11:41:18 +0000},
	Date-Modified = {2017-05-13 11:41:18 +0000},
	Journal = {arXiv preprint arXiv:1602.02282},
	Title = {Ladder Variational Autoencoders},
	Year = {2016}}

@article{nakajima2013,
	Author = {Nakajima, Shinichi and Sugiyama, Masashi and Babacan, S. Derin and Tomioka, Ryota},
	Date-Added = {2017-05-13 11:00:26 +0000},
	Date-Modified = {2017-05-13 11:02:09 +0000},
	Journal = {Journal of Machine Learning Research},
	Title = {Global Analytic Solution of Fully-observed Variational Bayesian Matrix Factorization},
	Year = {2013}}

@incollection{NIPS2010_4063,
	Author = {Nakajima, Shinichi and Sugiyama, Masashi and Tomioka, Ryota},
	Booktitle = {Advances in Neural Information Processing Systems 23},
	Date-Added = {2017-05-13 10:59:37 +0000},
	Date-Modified = {2017-05-13 10:59:37 +0000},
	Editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
	Pages = {1768--1776},
	Publisher = {Curran Associates, Inc.},
	Title = {Global Analytic Solution for Variational Bayesian Matrix Factorization},
	Url = {http://papers.nips.cc/paper/4063-global-analytic-solution-for-variational-bayesian-matrix-factorization.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/4063-global-analytic-solution-for-variational-bayesian-matrix-factorization.pdf}}

@article{mackay2001,
	Author = {David J.C. MacKay},
	Date-Added = {2017-05-13 10:56:32 +0000},
	Date-Modified = {2020-04-17 11:08:40 -0400},
	Journal = {Accessed online at \url{inference.org.uk}},
	Title = {Local minima, symmetry-breaking, and model pruning in variational free energy minimization.},
	Year = {2001}}

@article{DBLP:journals/corr/MnihBMGLHSK16,
	Author = {Volodymyr Mnih and Adri{\`{a}} Puigdom{\`{e}}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihBMGLHSK16},
	Date-Added = {2017-05-13 10:50:44 +0000},
	Date-Modified = {2017-05-13 10:50:44 +0000},
	Journal = {CoRR},
	Timestamp = {Tue, 01 Mar 2016 17:47:25 +0100},
	Title = {Asynchronous Methods for Deep Reinforcement Learning},
	Url = {http://arxiv.org/abs/1602.01783},
	Volume = {abs/1602.01783},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1602.01783}}

@article{DBLP:journals/corr/PereyraTCKH17,
	Author = {Gabriel Pereyra and George Tucker and Jan Chorowski and Lukasz Kaiser and Geoffrey E. Hinton},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/PereyraTCKH17},
	Date-Added = {2017-05-13 10:50:08 +0000},
	Date-Modified = {2017-05-13 10:50:08 +0000},
	Journal = {CoRR},
	Timestamp = {Wed, 01 Feb 2017 17:47:56 +0100},
	Title = {Regularizing Neural Networks by Penalizing Confident Output Distributions},
	Url = {http://arxiv.org/abs/1701.06548},
	Volume = {abs/1701.06548},
	Year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1701.06548}}

@article{2016arXiv160800778R,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160800778R},
	Archiveprefix = {arXiv},
	Author = {{Rudolph}, M.~R. and {Ruiz}, F.~J.~R. and {Mandt}, S. and {Blei}, D.~M.},
	Date-Added = {2017-03-09 13:32:06 +0000},
	Date-Modified = {2017-03-09 13:32:06 +0000},
	Eprint = {1608.00778},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = aug,
	Primaryclass = {stat.ML},
	Title = {{Exponential Family Embeddings}},
	Year = 2016}

@inproceedings{Mnih:2016:VIM:3045390.3045621,
	Author = {Mnih, Andriy and Rezende, Danilo J.},
	Booktitle = {International Conference on Machine Learning},
	Date-Added = {2017-02-24 21:16:05 +0000},
	Date-Modified = {2017-02-24 21:16:32 +0000},
	Pages = {2188--2196},
	Title = {Variational Inference for Monte Carlo Objectives},
	Year = {2016},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=3045390.3045621}}

@inproceedings{DBLP:conf/conll/BowmanVVDJB16,
	Author = {Samuel R. Bowman and Luke Vilnis and Oriol Vinyals and Andrew M. Dai and Rafal J{\'{o}}zefowicz and Samy Bengio},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/conf/conll/BowmanVVDJB16},
	Booktitle = {Conference on Computational Natural Language Learning},
	Crossref = {DBLP:conf/conll/2016},
	Date-Added = {2017-02-24 20:51:08 +0000},
	Date-Modified = {2017-02-24 21:03:59 +0000},
	Timestamp = {Sun, 04 Sep 2016 10:01:12 +0200},
	Title = {Generating Sentences from a Continuous Space},
	Year = {2016},
	Bdsk-Url-1 = {http://aclweb.org/anthology/K/K16/K16-1002.pdf}}

@inproceedings{Khan:2016:FSV:3020948.3020982,
	Author = {Khan, Mohammad E. and Babanezhad, Reza and Lin, Wu and Schmidt, Mark and Sugiyama, Masashi},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Date-Added = {2017-02-24 16:31:08 +0000},
	Date-Modified = {2017-02-24 21:09:31 +0000},
	Pages = {319--328},
	Title = {Faster Stochastic Variational Inference Using Proximal-Gradient Methods with General Divergence Functions},
	Year = {2016},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=3020948.3020982}}

@article{DBLP:journals/corr/MansinghkaSP14,
	Author = {Mansinghka, Vikash and Selsam, Daniel, and Perov, Yura N.},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/MansinghkaSP14},
	Date-Added = {2017-02-24 16:05:45 +0000},
	Date-Modified = {2017-02-24 21:25:34 +0000},
	Journal = {arXiv:1404.0099},
	Timestamp = {Thu, 01 May 2014 14:56:20 +0200},
	Title = {Venture: a higher-order probabilistic programming platform with programmable inference},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1404.0099}}

@article{tran2016edward,
	Author = {Dustin Tran and Alp Kucukelbir and Adji B. Dieng and Maja Rudolph and Dawen Liang and David M. Blei},
	Date-Added = {2017-02-24 16:04:40 +0000},
	Date-Modified = {2017-02-24 21:23:50 +0000},
	Journal = {arXiv:1610.09787},
	Title = {{Edward: A library for probabilistic modeling, inference, and criticism}},
	Year = {2016}}

@article{neal1992connectionist,
	Author = {Neal, Radford M},
	Date-Added = {2017-02-23 19:03:52 +0000},
	Date-Modified = {2017-02-23 19:03:52 +0000},
	Journal = {Artificial intelligence},
	Number = {1},
	Pages = {71--113},
	Publisher = {Elsevier},
	Title = {Connectionist learning of belief networks},
	Volume = {56},
	Year = {1992}}

@book{Goodfellow-et-al-2016,
	Author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	Date-Added = {2017-02-22 01:28:32 +0000},
	Date-Modified = {2017-02-22 01:28:32 +0000},
	Note = {\url{http://www.deeplearningbook.org}},
	Publisher = {MIT Press},
	Title = {Deep Learning},
	Year = {2016}}

@article{2016arXiv160605579H,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160605579H},
	Archiveprefix = {arXiv},
	Author = {{Higgins}, Irina and {Matthey}, Loic and {Glorot}, Xavier and {Pal}, Arka and {Uria}, Benigno and {Blundell}, Charles and {Mohamed}, Shakir and {Lerchner}, Alexander},
	Date-Added = {2017-02-22 01:03:04 +0000},
	Date-Modified = {2017-02-24 21:02:19 +0000},
	Journal = {ArXiv:1606.05579},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning, Quantitative Biology - Neurons and Cognition},
	Primaryclass = {stat.ML},
	Title = {{Early Visual Concept Learning with Unsupervised Deep Learning}},
	Year = 2016}

@article{DBLP:journals/corr/MnihR16,
	Author = {Andriy Mnih and Danilo Jimenez Rezende},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihR16},
	Date-Added = {2016-11-09 01:02:19 +0000},
	Date-Modified = {2016-11-09 01:02:19 +0000},
	Journal = {CoRR},
	Timestamp = {Tue, 01 Mar 2016 17:47:25 +0100},
	Title = {Variational inference for Monte Carlo objectives},
	Url = {http://arxiv.org/abs/1602.06725},
	Volume = {abs/1602.06725},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1602.06725}}

@article{DBLP:journals/corr/KingmaB14,
	Author = {Diederik P. Kingma and Jimmy Ba},
	Date-Added = {2016-11-09 01:01:42 +0000},
	Date-Modified = {2017-02-24 21:08:54 +0000},
	Journal = {International Conference on Learning Representations},
	Timestamp = {Thu, 01 Jan 2015 19:51:08 +0100},
	Title = {Adam: {A} Method for Stochastic Optimization},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1412.6980}}

@inproceedings{mandt2016variational,
	Author = {Mandt, Stephan and McInerney, James and Abrol, Farhan and Ranganath, Rajesh and Blei, David},
	Booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
	Date-Added = {2016-05-20 14:12:48 +0000},
	Date-Modified = {2016-05-20 14:12:48 +0000},
	Pages = {704--712},
	Title = {Variational Tempering},
	Year = {2016}}

@inproceedings{Shah:2015,
	Author = {Shah, Amar and Knowles, David and Ghahramani, Zoubin},
	Booktitle = {Proceedings of the 32nd International Conference on Machine Learning (ICML-15)},
	Pages = {1594--1603},
	Title = {An empirical study of stochastic variational inference algorithms for the beta Bernoulli process},
	Year = {2015}}

@inproceedings{khan2015kullback,
	Author = {Khan, Mohammad E. and Baqu{\'e}, Pierre and Fleuret, Fran{\c{c}}ois and Fua, Pascal},
	Booktitle = {Neural Information Processing Systems},
	Date-Added = {2016-05-18 23:18:49 +0000},
	Date-Modified = {2020-04-17 10:54:58 -0400},
	Pages = {3384--3392},
	Title = {Kullback-Leibler Proximal Variational Inference},
	Year = {2015}}

@inproceedings{Larochelle:2008:CUD:1390156.1390224,
	Acmid = {1390224},
	Address = {New York, NY, USA},
	Author = {Larochelle, Hugo and Bengio, Yoshua},
	Booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	Date-Added = {2016-05-18 14:18:50 +0000},
	Date-Modified = {2016-05-18 14:18:50 +0000},
	Doi = {10.1145/1390156.1390224},
	Isbn = {978-1-60558-205-4},
	Location = {Helsinki, Finland},
	Numpages = {8},
	Pages = {536--543},
	Publisher = {ACM},
	Series = {ICML '08},
	Title = {Classification Using Discriminative Restricted Boltzmann Machines},
	Url = {http://doi.acm.org/10.1145/1390156.1390224},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1390156.1390224},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1390156.1390224}}

@book{boyd2004convex,
	Author = {Boyd, Stephen and Vandenberghe, Lieven},
	Date-Modified = {2017-02-24 20:53:32 +0000},
	Publisher = {{Cambridge University Press}},
	Title = {Convex Optimization},
	Year = {2004}}

@article{DBLP:journals/corr/abs-1212-5701,
	Author = {Matthew D. Zeiler},
	Date-Added = {2016-05-16 06:38:34 +0000},
	Date-Modified = {2016-05-16 06:38:34 +0000},
	Journal = {CoRR},
	Title = {{ADADELTA:} An Adaptive Learning Rate Method},
	Volume = {abs/1212.5701},
	Year = {2012}}

@article{Gowers1975,
	Author = {Gowers, W T},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gowers - 1975 - ´ the Work of Endre Szemer Edi.pdf:pdf},
	Journal = {Work},
	Pages = {1--12},
	Title = {{´ the Work of Endre Szemer Edi}},
	Year = {1975}}

@article{Hemiparesis2012,
	Author = {Hemiparesis, Upper Limb and Opinion, The and Physician, Rehabilitation},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.13225/j.cnki.jccs.2011.03.030},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hemiparesis, Opinion, Physician - 2012 - ーリハビリテーション科専門.pdf:pdf},
	Isbn = {6052520124},
	Keywords = {a,a型ボツリヌ,bont,botulinum toxin type a,intensive occupational therapy,repetitive transcranial magnetic stimulation,rtms,spasticity,ス毒素,中的作業療法,反復性経頭蓋磁気刺激,年間で,減らすこと,痙縮,脳卒中による死亡率を25,集},
	Number = {12},
	Pages = {916--920},
	Title = {ーリハビリテーション科専門医としての主張一＊1 安保雅博＊2 佐々木信幸＊2竹川 徹＊2 角田 亘＊2},
	Url = {http://tomcollinsresearch.net/pdf/collinsEtAlAIEDAM2016.pdf},
	Volume = {35},
	Year = {2012},
	Bdsk-Url-1 = {http://tomcollinsresearch.net/pdf/collinsEtAlAIEDAM2016.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.13225/j.cnki.jccs.2011.03.030}}

@article{Goller,
	Author = {Goller, Christoph and Kuchler, Andreas},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Goller, Kuchler - Unknown - 3 . Backpropagation Through Structure.pdf:pdf},
	Title = {{3 . Backpropagation Through Structure}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D5E9864BA2F656A2378A057B57D02654?doi=10.1.1.52.4759{\&}rep=rep1{\&}type=pdf},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D5E9864BA2F656A2378A057B57D02654?doi=10.1.1.52.4759%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf}}

@article{Hinton2006,
	Abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
	Archiveprefix = {arXiv},
	Arxivid = {1111.6189v1},
	Author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1162/neco.2006.18.7.1527},
	Eprint = {1111.6189v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hinton, Osindero, Teh - 2006 - A fast learning algorithm for deep belief nets.pdf:pdf},
	Isbn = {0899-7667},
	Issn = {0899-7667},
	Journal = {Neural computation},
	Keywords = {Algorithms,Animals,Humans,Learning,Learning: physiology,Neural Networks (Computer),Neurons,Neurons: physiology},
	Number = {7},
	Pages = {1527--54},
	Pmid = {16764513},
	Title = {{A fast learning algorithm for deep belief nets.}},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513},
	Volume = {18},
	Year = {2006},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/16764513},
	Bdsk-Url-2 = {http://dx.doi.org/10.1162/neco.2006.18.7.1527}}

@article{Hinton06,
	Author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee Whye},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Journal = {Neural Computation},
	Pages = {1527--1554},
	Title = {{A Fast Learning Algorithm for Deep Belief Nets}},
	Volume = {18},
	Year = {2006}}

@article{Domingos2012,
	Abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the ``folk knowledge'' that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
	Author = {Domingos, Pedro},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/2347736.2347755},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Domingos - 2012 - A few useful things to know about machine learning.pdf:pdf},
	Isbn = {0001-0782},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Number = {10},
	Pages = {78},
	Title = {{A few useful things to know about machine learning}},
	Url = {https://homes.cs.washington.edu/{~}pedrod/papers/cacm12.pdf},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {https://homes.cs.washington.edu/%7B~%7Dpedrod/papers/cacm12.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2347736.2347755}}

@article{Lu2008b,
	Abstract = {In this paper, we present an algorithm for learning a generative model of natural language sentences together with their formal meaning representations with hierarchical structures. The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning. We introduce dynamic programming techniques for efficient training and decoding. In experiments, we demonstrate that the model, when coupled with a discriminative reranking technique, achieves state-of-the-art performance when tested on two publicly available corpora. The generative model degrades robustly when presented with instances that are different from those seen in training. This allows a notable improvement in recall compared to previous models.},
	Author = {Lu, Wei and Ng, Ht and Lee, Ws and Zettlemoyer, Ls},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.3115/1613715.1613815},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lu et al. - 2008 - A generative model for parsing natural language to meaning representations.pdf:pdf},
	Journal = {{\ldots} Methods in Natural Language {\ldots}},
	Number = {October},
	Pages = {782--791},
	Title = {{A generative model for parsing natural language to meaning representations}},
	Url = {http://dl.acm.org/citation.cfm?id=1613815},
	Year = {2008},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1613815},
	Bdsk-Url-2 = {http://dx.doi.org/10.3115/1613715.1613815}}

@article{Lockhart2009,
	Abstract = {Eighty percent of peak bone mass should be achieved from birth through adolescence. An adequate calcium intake is essential, and it is advisable that 60{\%} of the recommended calcium allowance be dairy calcium. This study was conducted to examine bone mineral content (BMC) in patients with diseases that usually involve long-term suppression of dairy products.},
	Author = {Lockhart, Paul},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lockhart - 2009 - A Mathematician's Lament.pdf:pdf},
	Isbn = {1934137170},
	Issn = {02772116},
	Journal = {Devlin's Angle March},
	Number = {March},
	Pages = {1--25},
	Pmid = {10749417},
	Title = {{A Mathematician's Lament}},
	Url = {http://cla.sd57.bc.ca/{~}rgiroday/admin/pdf/LockhartsLament.pdf},
	Volume = {1},
	Year = {2009},
	Bdsk-Url-1 = {http://cla.sd57.bc.ca/%7B~%7Drgiroday/admin/pdf/LockhartsLament.pdf}}

@article{Anderson1987,
	Author = {Anderson, James R},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Anderson - 1987 - A Mean Field Theory Learning Algorithm for Neural Networks.pdf:pdf},
	Journal = {Complex Systems},
	Pages = {995--1019},
	Title = {{A Mean Field Theory Learning Algorithm for Neural Networks}},
	Volume = {1},
	Year = {1987}}

@article{Com2015,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.05869v2},
	Author = {Com, Q V L Google},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.05869v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Com - 2015 - A Neural Conversational Model.pdf:pdf},
	Keywords = {neural networks, dialog systems, chatbots},
	Title = {{A Neural Conversational Model}},
	Url = {http://arxiv.org/pdf/1506.05869v2.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.05869v2.pdf}}

@article{Bengio2003,
	Abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1301.3781v3},
	Author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal and Janvin, Christian},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1162/153244303322533223},
	Eprint = {arXiv:1301.3781v3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bengio et al. - 2003 - A Neural Probabilistic Language Model.pdf:pdf},
	Isbn = {1532-4435},
	Issn = {15324435},
	Journal = {The Journal of Machine Learning Research},
	Keywords = {artificial neural networks,curse of dimensionality,distributed representation,statistical language modeling},
	Pages = {1137--1155},
	Pmid = {18244602},
	Title = {{A Neural Probabilistic Language Model}},
	Url = {http://jmlr.csail.mit.edu/papers/volume3/bengio03a/bengio03a.pdf},
	Volume = {3},
	Year = {2003},
	Bdsk-Url-1 = {http://jmlr.csail.mit.edu/papers/volume3/bengio03a/bengio03a.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1162/153244303322533223}}

@article{Waldram1971,
	Archiveprefix = {arXiv},
	Arxivid = {1511.01844},
	Author = {Waldram, J.M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1177/096032717100300408},
	Eprint = {1511.01844},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Waldram - 1971 - A note on the evaluation of modelling.pdf:pdf},
	Issn = {1477-1535},
	Journal = {Lighting Research and Technology},
	Number = {4},
	Pages = {284--285},
	Title = {{A note on the evaluation of modelling}},
	Url = {http://lrt.sagepub.com/cgi/doi/10.1177/096032717100300408},
	Volume = {3},
	Year = {1971},
	Bdsk-Url-1 = {http://lrt.sagepub.com/cgi/doi/10.1177/096032717100300408},
	Bdsk-Url-2 = {http://dx.doi.org/10.1177/096032717100300408}}

@article{Chung,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.02216v1},
	Author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.02216v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Chung et al. - Unknown - A Recurrent Latent Variable Model for Sequential Data.pdf:pdf},
	Pages = {1--9},
	Title = {{A Recurrent Latent Variable Model for Sequential Data}},
	Url = {http://arxiv.org/pdf/1506.02216v1.pdf},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.02216v1.pdf}}

@article{Guzella2009,
	Abstract = {In this paper, we present a comprehensive review of recent developments in the application of machine learning algorithms to Spam filtering, focusing on both textual- and image-based approaches. Instead of considering Spam filtering as a standard classification problem, we highlight the importance of considering specific characteristics of the problem, especially concept drift, in designing new filters. Two particularly important aspects not widely recognized in the literature are discussed: the difficulties in updating a classifier based on the bag-of-words representation and a major difference between two early naive Bayes models. Overall, we conclude that while important advancements have been made in the last years, several aspects remain to be explored, especially under more realistic evaluation settings. ?? 2009 Elsevier Ltd. All rights reserved.},
	Author = {Guzella, Thiago S. and Caminhas, Walmir M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1016/j.eswa.2009.02.037},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Guzella, Caminhas - 2009 - A review of machine learning approaches to Spam filtering.pdf:pdf},
	Isbn = {0957-4174},
	Issn = {09574174},
	Journal = {Expert Systems with Applications},
	Keywords = {Bag-of-words (BoW),Image Spam,Naive Bayes,Online learning,Spam filtering},
	Number = {7},
	Pages = {10206--10222},
	Publisher = {Elsevier Ltd},
	Title = {{A review of machine learning approaches to Spam filtering}},
	Url = {http://dx.doi.org/10.1016/j.eswa.2009.02.037 http://cpe.kmutt.ac.th/{~}fay/files/prob/bayesian.pdf},
	Volume = {36},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.eswa.2009.02.037%20http://cpe.kmutt.ac.th/%7B~%7Dfay/files/prob/bayesian.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.eswa.2009.02.037}}

@article{Mourad2013,
	Author = {Mourad, Rapha{\"{e}}l and Sinoquet, Christine and Zhang, Nevin L. and Liu, Tengfei and Leray, Philippe},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1613/jair.3879},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mourad et al. - 2013 - A survey on latent tree models and applications.pdf:pdf},
	Issn = {10769757},
	Journal = {Journal of Artificial Intelligence Research},
	Pages = {157--203},
	Title = {{A survey on latent tree models and applications}},
	Url = {https://www.jair.org/media/3879/live-3879-7058-jair.pdf},
	Volume = {47},
	Year = {2013},
	Bdsk-Url-1 = {https://www.jair.org/media/3879/live-3879-7058-jair.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1613/jair.3879}}

@article{Guidi2015,
	Abstract = {We present a short survey of the literature on indexing and retrieval of mathematical knowledge, with pointers to 72 papers and tentative taxonomies of both retrieval problems and recurring techniques.},
	Archiveprefix = {arXiv},
	Arxivid = {1505.06646},
	Author = {Guidi, F. and Coen, C. Sacerdoti},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1505.06646},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Guidi, Coen - 2015 - A Survey on Retrieval of Mathematical Knowledge.pdf:pdf},
	Title = {{A Survey on Retrieval of Mathematical Knowledge}},
	Url = {http://arxiv.org/abs/1505.06646},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1505.06646}}

@book{Stroustrup2013a,
	Abstract = {The C++11 standard allows programmers to express ideas more clearly, simply, and directly, and to write faster, more efficient code. Bjarne Stroustrup, the designer and original implementer of C++, thoroughly covers the details of this language and its use in his definitive reference, The C++ Programming Language, Fourth Edition. In A Tour of C++, Stroustrup excerpts the overview chapters from that complete reference, expanding and enhancing them to give an experienced programmer-in just a few hours-a clear idea of what constitutes modern C++. In this concise, self-contained guide, Stroustrup covers most major language features and the major standard-library components-not, of course, in great depth, but to a level that gives programmers a meaningful overview of the language, some key examples, and practical help in getting started. Stroustrup presents the C++ features in the context of the programming styles they support, such as object-oriented and generic programming. His tour is remarkably comprehensive. Coverage begins with the basics, then ranges widely through more advanced topics, including many that are new in C++11, such as move semantics, uniform initialization, lambda expressions, improved containers, random numbers, and concurrency. The tour ends with a discussion of the design and evolution of C++ and the extensions added for C++11. This guide does not aim to teach you how to program (see Stroustrup's Programming: Principles and Practice Using C++ for that); nor will it be the only resource you'll need for C++ mastery (see Stroustrup's The C++ Programming Language, Fourth Edition, for that). If, however, you are a C or C++ programmer wanting greater familiarity with the current C++ language, or a programmer versed in another language wishing to gain an accurate picture of the nature and benefits of modern C++, you can't find a shorter or simpler introduction than this tour provides.},
	Author = {Stroustrup, Bjarne},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Stroustrup - 2013 - A Tour of C plus plus.pdf:pdf},
	Isbn = {9780321958310},
	Pages = {192},
	Title = {{A Tour of C plus plus}},
	Url = {http://majokota.weebly.com/uploads/6/2/2/0/62200643/{\_}c{\_}{\_}{\_}in-depth{\_}series{\_}{\_}bjarne{\_}stroustrup-a{\_}tour{\_}of{\_}c{\_}{\_}-addison-wesley{\_}professional{\_}{\_}2013{\_}.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://majokota.weebly.com/uploads/6/2/2/0/62200643/%7B%5C_%7Dc%7B%5C_%7D%7B%5C_%7D%7B%5C_%7Din-depth%7B%5C_%7Dseries%7B%5C_%7D%7B%5C_%7Dbjarne%7B%5C_%7Dstroustrup-a%7B%5C_%7Dtour%7B%5C_%7Dof%7B%5C_%7Dc%7B%5C_%7D%7B%5C_%7D-addison-wesley%7B%5C_%7Dprofessional%7B%5C_%7D%7B%5C_%7D2013%7B%5C_%7D.pdf}}

@article{Theis2015,
	Author = {Theis, Lucas and Hoffman, Matthew D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2017-02-24 21:23:06 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Theis, Hoffman - 2015 - A trust-region method for stochastic variational inference with applications to streaming data.pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Title = {{A trust-region method for stochastic variational inference with applications to streaming data}},
	Year = {2015},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v37/theis15.pdf}}

@article{Gershman2012,
	Author = {Gershman, Samuel J. and Blei, David M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1016/j.jmp.2011.08.004},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gershman, Blei - 2012 - A tutorial on Bayesian nonparametric models.pdf:pdf},
	Issn = {00222496},
	Journal = {Journal of Mathematical Psychology},
	Number = {1},
	Pages = {1--12},
	Publisher = {Elsevier Inc.},
	Title = {{A tutorial on Bayesian nonparametric models}},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S002224961100071X},
	Volume = {56},
	Year = {2012},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S002224961100071X},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jmp.2011.08.004}}

@article{Brochu2010,
	Archiveprefix = {arXiv},
	Arxivid = {1012.2599},
	Author = {Brochu, E and Cora, V M and {De Freitas}, N},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1012.2599},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Brochu, Cora, De Freitas - 2010 - A tutorial on Bayesian optimization of expensive cost functions, with application to active user model.pdf:pdf},
	Journal = {Arxiv preprint arXiv:1012.2599},
	Pages = {1--49},
	Title = {{A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning}},
	Url = {http://arxiv.org/pdf/1012.2599.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1012.2599.pdf}}

@article{Maillard2014,
	Author = {Maillard, Jean and Clark, Stephen and Grefenstette, Edward},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Maillard, Clark, Grefenstette - 2014 - A Type− Driven Tensor− Based Semantics for CCG.pdf:pdf},
	Journal = {Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics},
	Pages = {46--54},
	Title = {{A Type− Driven Tensor− Based Semantics for CCG}},
	Url = {http://www.cl.cam.ac.uk/{~}sc609/pubs/eacl14types.pdf$\backslash$nhttp://www.cs.ox.ac.uk/publications/publication8483-abstract.html},
	Year = {2014},
	Bdsk-Url-1 = {http://www.cl.cam.ac.uk/%7B~%7Dsc609/pubs/eacl14types.pdf$%5Cbackslash$nhttp://www.cs.ox.ac.uk/publications/publication8483-abstract.html}}

@article{Betancourt2015,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.02273v1},
	Author = {Betancourt, Michael},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.02273v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Betancourt - 2015 - A Unified Treatment of Predictive Model Comparison arXiv 1506 . 02273v1 stat . ME 7 Jun 2015.pdf:pdf},
	Pages = {1--20},
	Title = {{A Unified Treatment of Predictive Model Comparison arXiv : 1506 . 02273v1 [ stat . ME ] 7 Jun 2015}},
	Url = {http://arxiv.org/pdf/1506.02273v1.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.02273v1.pdf}}

@article{Izbicki2013,
	Abstract = {We use abstract algebra to derive new algo- rithms for fast cross-validation, online learn- ing, and parallel learning. To use these al- gorithms on a classification model, we must show that the model has appropriate alge- braic structure. It is easy to give algebraic structure to some models, and we do this ex- plicitly for Bayesian classifiers and a novel variation of decision stumps called HomS- tumps. But not all classifiers have an ob- vious structure, so we introduce the Free HomTrainer. This can be used to give a ``generic'' algebraic structure to any classi- fier. We use the Free HomTrainer to give al- gebraic structure to bagging and boosting. In so doing, we derive novel online and parallel algorithms, and present the first fast cross- validation schemes for these classifiers},
	Author = {Izbicki, Michael},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Izbicki - 2013 - Algebraic classifiers a generic approach to fast cross-validation, online training, and parallel training.pdf:pdf},
	Journal = {Izbicki.Me},
	Title = {{Algebraic classifiers: a generic approach to fast cross-validation, online training, and parallel training}},
	Url = {http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf},
	Volume = {28},
	Year = {2013},
	Bdsk-Url-1 = {http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf}}

@article{Jo2011,
	Address = {New York, New York, USA},
	Author = {Jo, Yohan and Oh, Alice H.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1935826.1935932},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Jo, Oh - 2011 - Aspect and sentiment unification model for online review analysis.pdf:pdf},
	Isbn = {9781450304931},
	Journal = {Proceedings of the ACM International Conference on Web Search and Data Mining},
	Keywords = {all or part of,aspect detection,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,sentiment analysis,this work for,topic modeling},
	Pages = {815},
	Publisher = {ACM Press},
	Title = {{Aspect and sentiment unification model for online review analysis}},
	Url = {http://portal.acm.org/citation.cfm?doid=1935826.1935932},
	Volume = {4},
	Year = {2011},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1935826.1935932},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1935826.1935932}}

@article{Eslami2016,
	Abstract = {We present a framework for efficient inference in structured image models that explicitly reason about objects. We achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time. Crucially, the model itself learns to choose the appropriate number of inference steps. We use this scheme to learn to perform inference in partially specified 2D models (variable-sized variational auto-encoders) and fully specified 3D models (probabilistic renderers). We show that such models learn to identify multiple objects - counting, locating and classifying the elements of a scene - without any supervision, e.g., decomposing 3D images with various numbers of objects in a single forward pass of a neural network. We further show that the networks produce accurate inferences when compared to supervised counterparts, and that their structure leads to improved generalization.},
	Archiveprefix = {arXiv},
	Arxivid = {1603.08575},
	Author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Kavukcuoglu, Koray and Hinton, Geoffrey E.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1603.08575},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Eslami et al. - 2016 - Attend, Infer, Repeat Fast Scene Understanding with Generative Models.pdf:pdf},
	Title = {{Attend, Infer, Repeat: Fast Scene Understanding with Generative Models}},
	Url = {http://arxiv.org/abs/1603.08575},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1603.08575}}

@article{Fried2014,
	Abstract = {The modern musician enjoys access to a staggering number of audio samples. Composition software can ship with many gigabytes of data, and there are many more to be found online. However, conventional methods for navigating these libraries are still quite rudimentary, and often involve scrolling through alphabetical lists. We present a system for sample exploration that allows audio clips to be sorted according to user taste, and arranged in any desired 2D formation such that similar samples are located near each other. Our method relies on two advances in machine learning. First, metric learning allows the user to shape the audio feature space to match their own preferences. Second, kernelized sorting finds an optimal arrangement for the samples in 2D. We demonstrate our system with two new interfaces for exploring audio samples, and evaluate the technology qualitatively and quantitatively via a pair of user studies.},
	Author = {Fried, Ohad and Jin, Zeyu and Oda, Reid and Finkelstein, Adam},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/Downloads/FriedJinOdaFinkelstein{\_}NIME2014.pdf:pdf},
	Journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	Keywords = {ker-,metric learning,sample library,sound exploration},
	Pages = {281--286},
	Title = {{AudioQuilt: 2D Arrangements of Audio Samples using Metric Learning and Kernelized Sorting}},
	Url = {http://www.nime.org/proceedings/2014/nime2014{\_}315.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://www.nime.org/proceedings/2014/nime2014%7B%5C_%7D315.pdf}}

@article{Irsoy2014,
	Abstract = {We discuss an autoencoder model in which the encoding and decoding functions are implemented by decision trees. We use the soft decision tree where internal nodes realize soft multivariate splits given by a gating function and the overall output is the average of all leaves weighted by the gating values on their path. The encoder tree takes the input and generates a lower dimensional representation in the leaves and the decoder tree takes this and reconstructs the original input. Exploiting the continuity of the trees, autoencoder trees are trained with stochastic gradient descent. On handwritten digit and news data, we see that the autoencoder trees yield good reconstruction error compared to traditional autoencoder perceptrons. We also see that the autoencoder tree captures hierarchical representations at different granularities of the data on its different levels and the leaves capture the localities in the input space.},
	Archiveprefix = {arXiv},
	Arxivid = {1409.7461},
	Author = {{\.I}rsoy, Ozan and Alpaydın, Ethem},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1409.7461},
	File = {:Users/jaanaltosaar/papers/mendeley collection/{\.I}rsoy, Alpaydın - 2014 - Autoencoder Trees.pdf:pdf},
	Number = {section 3},
	Pages = {1--9},
	Title = {{Autoencoder Trees}},
	Url = {http://arxiv.org/abs/1409.7461},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.7461}}

@article{Kingma2014,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1312.6114v10},
	Author = {Kingma, Diederik P and Welling, Max},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1312.6114v10},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kingma, Welling - 2014 - Auto-Encoding Variational Bayes.pdf:pdf},
	Journal = {ICLR},
	Number = {Ml},
	Pages = {1--14},
	Title = {{Auto-Encoding Variational Bayes}},
	Url = {http://arxiv.org/abs/1312.6114},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.6114}}

@article{Suhara2013,
	Author = {Suhara, Yoshihiko and Toda, Hiroyuki and Nishioka, Shuichi and Susaki, Seiji},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Suhara et al. - 2013 - Automatically generated spam detection based on sentence-level topic information.pdf:pdf},
	Isbn = {9781450320382},
	Journal = {The International Conference on the World Wide Web},
	Keywords = {spam detection,spam feature,topic model},
	Pages = {1157--1160},
	Title = {{Automatically generated spam detection based on sentence-level topic information}},
	Url = {http://dl.acm.org/citation.cfm?id=2488140},
	Volume = {22},
	Year = {2013},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2488140}}

@article{Cemgil2009,
	Abstract = {{\textless}p{\textgreater}We describe nonnegative matrix factorisation (NMF) with a Kullback-Leibler (KL) error measure in a statistical framework, with a hierarchical generative model consisting of an observation and a prior component. Omitting the prior leads to the standard KL-NMF algorithms as special cases, where maximum likelihood parameter estimation is carried out via the Expectation-Maximisation (EM) algorithm. Starting from this view, we develop full Bayesian inference via variational Bayes or Monte Carlo. Our construction retains conjugacy and enables us to develop more powerful models while retaining attractive features of standard NMF such as monotonic convergence and easy implementation. We illustrate our approach on model order selection and image reconstruction.{\textless}/p{\textgreater}},
	Author = {Cemgil, Ali Taylan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1155/2009/785152},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Cemgil - 2009 - Bayesian Inference for Nonnegative Matrix Factorisation Models.pdf:pdf},
	Issn = {1687-5265},
	Journal = {Computational Intelligence and Neuroscience},
	Pages = {1--17},
	Title = {{Bayesian Inference for Nonnegative Matrix Factorisation Models}},
	Url = {http://www.hindawi.com/journals/cin/2009/785152/},
	Volume = {2009},
	Year = {2009},
	Bdsk-Url-1 = {http://www.hindawi.com/journals/cin/2009/785152/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1155/2009/785152}}

@article{Welling2011,
	Abstract = {In this paper we propose a new framework$\backslash$n$\backslash$nfor learning from large scale datasets based$\backslash$n$\backslash$non iterative learning from small mini-batches.$\backslash$n$\backslash$nBy adding the right amount of noise to a$\backslash$n$\backslash$nstandard stochastic gradient optimization algorithm$\backslash$n$\backslash$nwe show that the iterates will converge$\backslash$n$\backslash$nto samples from the true posterior distribution$\backslash$n$\backslash$nas we anneal the stepsize. This$\backslash$n$\backslash$nseamless transition between optimization and$\backslash$n$\backslash$nBayesian posterior sampling provides an inbuilt$\backslash$n$\backslash$nprotection against overfitting. We also$\backslash$n$\backslash$npropose a practical method for Monte Carlo$\backslash$n$\backslash$nestimates of posterior statistics which monitors$\backslash$n$\backslash$na ``sampling threshold'' and collects samples$\backslash$n$\backslash$nafter it has been surpassed. We apply$\backslash$n$\backslash$nthe method to three models: a mixture of$\backslash$n$\backslash$nGaussians, logistic regression and ICA with$\backslash$n$\backslash$nnatural gradients.},
	Author = {Welling, M and Teh, Y W},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Welling, Teh - 2011 - Bayesian Learning via Stochastic Gradient {\{}L{\}}angevin Dynamics.pdf:pdf},
	Isbn = {978-1-4503-0619-5},
	Journal = {Proceedings of the 27th International Conference on Machine Learning (ICML)},
	Keywords = {dynamics,posterior sampling,stochastic gradient},
	Title = {{Bayesian Learning via Stochastic Gradient {\{}L{\}}angevin Dynamics}},
	Url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/ICML2011Welling{\_}398.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://machinelearning.wustl.edu/mlpapers/paper%7B%5C_%7Dfiles/ICML2011Welling%7B%5C_%7D398.pdf}}

@article{Steinhardt2012,
	Author = {Steinhardt, Jacob},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Steinhardt - 2012 - Beyond Bayesians and Frequentists Background on Bayesians and Frequentists.pdf:pdf},
	Pages = {1--7},
	Title = {{Beyond Bayesians and Frequentists Background on Bayesians and Frequentists}},
	Year = {2012}}

@article{Su2015,
	Author = {Su, Jinsong and Xiong, Deyi and Zhang, Biao and Liu, Yang and Yao, Junfeng and Zhang, Min},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Su et al. - 2015 - Bilingual Correspondence Recursive Autoencoders for Statistical Machine Translation.pdf:pdf},
	Number = {September},
	Pages = {1248--1258},
	Title = {{Bilingual Correspondence Recursive Autoencoders for Statistical Machine Translation}},
	Url = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP146.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP146.pdf}}

@article{Zhang2014,
	Author = {Zhang, Jiajun and Liu, Shujie and Li, Mu and Zhou, Ming and Zong, Chengqing},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zhang et al. - 2014 - Bilingually-constrained Phrase Embeddings for Machine Translation.pdf:pdf},
	Isbn = {9781937284725},
	Journal = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	Pages = {111--121},
	Title = {{Bilingually-constrained Phrase Embeddings for Machine Translation}},
	Url = {http://www.aclweb.org/anthology/P14-1011},
	Year = {2014},
	Bdsk-Url-1 = {http://www.aclweb.org/anthology/P14-1011}}

@article{Allamanis2015,
	Author = {Allamanis, Miltiadis and Tarlow, Daniel and Gordon, Andrew D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Allamanis, Tarlow, Gordon - 2015 - Bimodal Modelling of Source Code and Natural Language.pdf:pdf},
	Title = {{Bimodal Modelling of Source Code and Natural Language}},
	Url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/icml2015{\_}allamanis15.pdf},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://machinelearning.wustl.edu/mlpapers/paper%7B%5C_%7Dfiles/icml2015%7B%5C_%7Dallamanis15.pdf}}

@article{Transtrum2015,
	Abstract = {The inherent complexity of biological systems gives rise to complicated mechanistic models with a large number of parameters. On the other hand, the collective behavior of these systems can often be characterized by a relatively small number of phenomenological parameters. We use the Manifold Boundary Approximation Method (MBAM) as a tool for deriving simple phenomenological models from complicated mechanistic models. The resulting models are not black boxes, but remain expressed in terms of the microscopic parameters. In this way, we explicitly connect the macroscopic and microscopic descriptions, characterize the equivalence class of distinct systems exhibiting the same range of collective behavior, and identify the combinations of components that function as tunable control knobs for the behavior. We demonstrate the procedure for adaptation behavior exhibited by the EGFR pathway. From a 48 parameter mechanistic model, the system can be effectively described by a single adaptation parameter {\$}\backslashtau{\$} characterizing the ratio of time scales for the initial response and recovery time of the system which can in turn be expressed as a combination of microscopic reaction rates, Michaelis-Menten constants, and biochemical concentrations. The situation is not unlike modeling in physics in which microscopically complex processes can often be renormalized into simple phenomenological models with only a few effective parameters.},
	Archiveprefix = {arXiv},
	Arxivid = {1509.06278},
	Author = {Transtrum, Mark K. and Qiu, Peng},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1509.06278},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Transtrum, Qiu - 2015 - Bridging Mechanistic and Phenomenological Models of Complex Biological Systems.pdf:pdf},
	Journal = {arXiv preprint},
	Pages = {1--10},
	Title = {{Bridging Mechanistic and Phenomenological Models of Complex Biological Systems}},
	Url = {http://arxiv.org/abs/1509.06278},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1509.06278}}

@article{Lake2016,
	Archiveprefix = {arXiv},
	Arxivid = {1604.00289},
	Author = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1604.00289},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lake et al. - 2016 - Building Machines That Learn and Think Like People.pdf:pdf},
	Pages = {1--44},
	Title = {{Building Machines That Learn and Think Like People}},
	Url = {http://arxiv.org/pdf/1604.00289v1.pdf},
	Volume = {2},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1604.00289v1.pdf}}

@article{Regier2002,
	Author = {Regier, Jeffrey and Miller, A and McAuliffe, J and Adams, R and Hoffman, Matthew D and Lang, Dustin and Schlegel, D and Prabhat, F},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Regier et al. - 2015 - Celeste Variational inference for a generative model of astronomical images.pdf:pdf},
	Journal = {ICML},
	Title = {{Celeste: Variational inference for a generative model of astronomical images}},
	Url = {http://jmlr.org/proceedings/papers/v37/regier15.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v37/regier15.pdf}}

@article{Kim2015,
	Abstract = {We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60{\%} fewer parameters. On languages with rich morphology (Czech, German, French, Spanish, Russian), the model consistently outperforms a Kneser-Ney baseline and word-level/morpheme-level LSTM baselines, again with far fewer parameters. Our results suggest that on many languages, character inputs are sufficient for language modeling.},
	Archiveprefix = {arXiv},
	Arxivid = {1508.06615},
	Author = {Kim, Yoon and Jernite, Yacine and Sontag, David and Rush, Alexander M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1508.06615},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kim et al. - 2015 - Character-Aware Neural Language Models.pdf:pdf},
	Title = {{Character-Aware Neural Language Models}},
	Url = {http://arxiv.org/abs/1508.06615},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1508.06615}}

@article{Name2015,
	Annote = {@inproceedings{\{}Huang:2016:CRC:2856767.2856792,
author = {\{}Huang, Cheng-Zhi Anna and Duvenaud, David and Gajos, Krzysztof Z.{\}},
title = {\{}ChordRipple: Recommending Chords to Help Novice Composers Go Beyond the Ordinary{\}},
booktitle = {\{}Proceedings of the 21st International Conference on Intelligent User Interfaces{\}},
series = {\{}IUI '16{\}},
year = {\{}2016{\}},
isbn = {\{}978-1-4503-4137-0{\}},
location = {\{}Sonoma, California, USA{\}},
pages = {\{}241--250{\}},
numpages = {\{}10{\}},
url = {\{}http://doi.acm.org/10.1145/2856767.2856792{\}},
doi = {\{}10.1145/2856767.2856792{\}},
acmid = {\{}2856792{\}},
publisher = {\{}ACM{\}},
address = {\{}New York, NY, USA{\}},
keywords = {\{}chords, creativity support tools, recommender systems, neural language models, embeddings, harmony, music, songwriting{\}},
{\}}},
	Author = {Huang, Cheng-Zhi Anna and Duvenaud, David and Gajos, Krzysztof Z.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Huang, Duvenaud, Gajos - 2015 - ChordRipple Recommending Chords to Help Novice Composers Go Beyond Themselves.pdf:pdf},
	Isbn = {9781450341370},
	Pages = {241--250},
	Title = {{ChordRipple : Recommending Chords to Help Novice Composers Go Beyond Themselves}},
	Url = {http://delivery.acm.org/10.1145/2860000/2856792/p241-huang.pdf?ip=184.152.36.98{\&}id=2856792{\&}acc=OPEN{\&}key=4D4702B0C3E38B35.4D4702B0C3E38B35.4D4702B0C3E38B35.6D218144511F3437{\&}CFID=762476854{\&}CFTOKEN=97662156{\&}{\_}{\_}acm{\_}{\_}=1458225391{\_}f5b4a3ff3f3194266f8455ea636e28cd},
	Year = {2015},
	Bdsk-Url-1 = {http://delivery.acm.org/10.1145/2860000/2856792/p241-huang.pdf?ip=184.152.36.98%7B%5C&%7Did=2856792%7B%5C&%7Dacc=OPEN%7B%5C&%7Dkey=4D4702B0C3E38B35.4D4702B0C3E38B35.4D4702B0C3E38B35.6D218144511F3437%7B%5C&%7DCFID=762476854%7B%5C&%7DCFTOKEN=97662156%7B%5C&%7D%7B%5C_%7D%7B%5C_%7Dacm%7B%5C_%7D%7B%5C_%7D=1458225391%7B%5C_%7Df5b4a3ff3f3194266f8455ea636e28cd}}

@article{Hu,
	Author = {Hu, Yifan and Park, Florham and Koren, Yehuda and Volinsky, Chris},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2020-04-14 07:25:41 -0400},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hu et al. - 2008 - Collaborative Filtering for Implicit Feedback Datasets.pdf:pdf},
	Journal = {IEEE International Conference on Data Mining},
	Title = {{Collaborative Filtering for Implicit Feedback Datasets}},
	Url = {http://labs.yahoo.com/files/HuKorenVolinsky-ICDM08.pdf},
	Year = {2008},
	Bdsk-Url-1 = {http://labs.yahoo.com/files/HuKorenVolinsky-ICDM08.pdf}}

@article{Hu2008,
	Author = {Hu, Yifan and Park, Florham and Koren, Yehuda and Volinsky, Chris and Park, Florham},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2020-04-13 14:40:25 -0400},
	Doi = {10.1109/ICDM.2008.22},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hu et al. - 2008 - Collaborative Filtering for Implicit Feedback Datasets(2).pdf:pdf},
	Isbn = {978-0-7695-3502-9},
	Issn = {15504786},
	Journal = {IEEE International Conference on Data Mining},
	Keywords = {academic research,academic software,academics,bibliography,digital library,library management,library software,reference software,research paper,research tool,researcher},
	Title = {{Collaborative Filtering for Implicit Feedback Datasets}},
	Url = {https://www.mendeley.com/import/},
	Year = {2008},
	Bdsk-Url-1 = {https://www.mendeley.com/import/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/ICDM.2008.22}}

@article{Neelakantan2015,
	Abstract = {Knowledge base (KB) completion adds new facts to a KB by making inferences from existing facts, for example by inferring with high likelihood nationality(X,Y) from bornIn(X,Y). Most previous methods infer simple one-hop relational synonyms like this, or use as evidence a multi-hop relational path treated as an atomic feature, like bornIn(X,Z) -{\textgreater} containedIn(Z,Y). This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recursive neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path. Not only does this allow us to generalize to paths unseen at training time, but also, with a single high-capacity RNN, to predict new relation types not seen when the compositional model was trained (zero-shot learning). We assemble a new dataset of over 52M relational triples, and show that our method improves over a traditional classifier by 11{\%}, and a method leveraging pre-trained embeddings by 7{\%}.},
	Archiveprefix = {arXiv},
	Arxivid = {1504.06662},
	Author = {Neelakantan, Arvind and Roth, Benjamin and McCallum, Andrew},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1504.06662},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Neelakantan, Roth, McCallum - 2015 - Compositional Vector Space Models for Knowledge Base Completion.pdf:pdf},
	Title = {{Compositional Vector Space Models for Knowledge Base Completion}},
	Url = {http://arxiv.org/abs/1504.06662},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1504.06662}}

@misc{Corrado,
	Author = {Corrado, Greg},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Corrado - 2015 - Computer, respond to this email. Google Research blog, Nov. 3, 2015.html:html},
	Publisher = {Google Research Blog, Nov. 3},
	Title = {{Computer, respond to this email. Google Research blog, Nov. 3, 2015}},
	Url = {http://googleresearch.blogspot.com/2015/11/computer-respond-to-this-email.html},
	Year = {2015},
	Bdsk-Url-1 = {http://googleresearch.blogspot.com/2015/11/computer-respond-to-this-email.html}}

@article{Youyou2015,
	Author = {Youyou, Wu and Kosinski, Michal and Stillwell, David},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1073/pnas.1418680112},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Youyou, Kosinski, Stillwell - 2015 - Computer-based personality judgments are more accurate than those made by humans.pdf:pdf},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences},
	Number = {4},
	Pages = {1036--1040},
	Title = {{Computer-based personality judgments are more accurate than those made by humans}},
	Url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1418680112},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {http://www.pnas.org/lookup/doi/10.1073/pnas.1418680112},
	Bdsk-Url-2 = {http://dx.doi.org/10.1073/pnas.1418680112}}

@article{Torr2014,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1502.03240v1},
	Author = {Torr, Philip H S},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1502.03240v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Torr - 2014 - Conditional Random Fields as Recurrent Neural Networks.pdf:pdf},
	Journal = {arXiv preprint},
	Title = {{Conditional Random Fields as Recurrent Neural Networks}},
	Url = {http://www.robots.ox.ac.uk/{~}tvg/publications/2015/crfasrnn{\_}iccv2015.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://www.robots.ox.ac.uk/%7B~%7Dtvg/publications/2015/crfasrnn%7B%5C_%7Diccv2015.pdf}}

@article{Gopalana,
	Author = {Gopalan, PK and Charlin, L and Blei, DM},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gopalan, Charlin, Blei - 2014 - Content-based recommendations with Poisson factorization.pdf:pdf},
	Journal = {Advances in Neural Information Processing Systems},
	Title = {{Content-based recommendations with Poisson factorization}},
	Url = {http://papers.nips.cc/paper/5440-content-based-recommendations-with-poisson-factorization},
	Year = {2014},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5440-content-based-recommendations-with-poisson-factorization}}

@article{Asgari2015,
	Abstract = {We propose a new approach for representing biological sequences. This method, named protein-vectors or ProtVec for short, can be utilized in bioinformatics applications such as family classification, protein visualization, structure prediction, disordered protein identification, and protein-protein interaction prediction. Using the Skip-gram neural networks, protein sequences are represented with a single dense n-dimensional vector. This method was evaluated by classifying protein sequences obtained from Swiss-Prot belonging to 7,027 protein families where an average family classification accuracy of {\$}94\backslash{\%}\backslashpm 0.03\backslash{\%}{\$} was obtained, outperforming existing family classification methods. In addition, our model was used to predict disordered proteins from structured proteins. Two databases of disordered sequences were used: the DisProt database as well as a database featuring the disordered regions of nucleoporins rich with phenylalanine-glycine repeats (FG-Nups). Using support vector machine classifiers, FG-Nup sequences were distinguished from structured Protein Data Bank (PDB) sequences with 99.81$\backslash${\%} accuracy, and unstructured DisProt sequences from structured DisProt sequences with 100.0$\backslash${\%} accuracy. These results indicate that by only providing sequence data for various proteins into this model, information about protein structure can be determined with high accuracy. This so-called embedding model needs to be trained only once and can then be used to ascertain a diverse set of information regarding the proteins of interest. In addition, this representation can be considered as pre-training for various applications of deep learning in bioinformatics.},
	Archiveprefix = {arXiv},
	Arxivid = {1503.05140},
	Author = {Asgari, Ehsaneddin and Mofrad, Mohammad R K},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1371/journal.pone.0141287},
	Eprint = {1503.05140},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Asgari, Mofrad - 2015 - Continuous distributed representation of biological sequences for deep proteomics and genomics.pdf:pdf},
	Issn = {19326203},
	Journal = {PLoS ONE},
	Number = {11},
	Pages = {1--15},
	Pmid = {26555596},
	Title = {{Continuous distributed representation of biological sequences for deep proteomics and genomics}},
	Url = {http://journals.plos.org/plosone/article/asset?id=10.1371/journal.pone.0141287.PDF},
	Volume = {10},
	Year = {2015},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article/asset?id=10.1371/journal.pone.0141287.PDF},
	Bdsk-Url-2 = {http://dx.doi.org/10.1371/journal.pone.0141287}}

@article{Lin2015,
	Author = {Lin, Wu and Schmidt, Mark},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lin, Schmidt - 2015 - Convergence of Proximal-Gradient Stochastic Variational Inference under Non-Decreasing Step-Size Sequence.pdf:pdf},
	Journal = {Approximate Inference},
	Pages = {1--5},
	Title = {{Convergence of Proximal-Gradient Stochastic Variational Inference under Non-Decreasing Step-Size Sequence}},
	Url = {http://www.approximateinference.org/accepted/KhanEtAl2015.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.approximateinference.org/accepted/KhanEtAl2015.pdf}}

@book{Edition2015,
	Author = {Winship, T and Morgan, G},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Winship, Morgan - 2015 - Counterfactuals and Causal Inference.pdf:pdf},
	Isbn = {9781107587991},
	Title = {{Counterfactuals and Causal Inference}},
	Year = {2015}}

@article{Jain2015,
	Author = {Jain, Sarthak and Batra, Shashank},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Jain, Batra - 2015 - Cross-Lingual Sentiment Analysis using modified BRAE.pdf:pdf},
	Number = {September},
	Pages = {159--168},
	Title = {{Cross-Lingual Sentiment Analysis using modified BRAE}},
	Url = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP016.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP016.pdf}}

@article{Fallis2013a,
	Abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1011.1669v3},
	Author = {Fallis, A.G},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1017/CBO9781107415324.004},
	Eprint = {arXiv:1011.1669v3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Fallis - 2013 - cs106x.pdf:pdf},
	Isbn = {9788578110796},
	Issn = {1098-6596},
	Journal = {Journal of Chemical Information and Modeling},
	Keywords = {icle},
	Number = {9},
	Pages = {1689--1699},
	Pmid = {25246403},
	Title = {cs106x},
	Volume = {53},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/CBO9781107415324.004}}

@article{Bostock2011,
	Author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bostock, Ogievetsky, Heer - 2011 - D3 Data-Driven Documents.pdf:pdf},
	Journal = {InfoVis},
	Number = {March},
	Title = {{D3: Data-Driven Documents}},
	Url = {http://vis.stanford.edu/files/2011-D3-InfoVis.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://vis.stanford.edu/files/2011-D3-InfoVis.pdf}}

@article{Ladicky2015,
	Author = {Ladick{\'{y}}, L'ubor and Jeong, SoHyeon and Solenthaler, Barbara and Pollefeys, Marc and Gross, Markus},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/2816795.2818129},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ladick{\'{y}} et al. - 2015 - Data-driven fluid simulations using regression forests.pdf:pdf},
	Isbn = {9781450339315},
	Issn = {07300301},
	Journal = {ACM Transactions on Graphics},
	Keywords = {data-driven,fluid simulation,regression forest},
	Number = {6},
	Pages = {1--9},
	Title = {{Data-driven fluid simulations using regression forests}},
	Url = {http://dl.acm.org/citation.cfm?doid=2816795.2818129},
	Volume = {34},
	Year = {2015},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2816795.2818129},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2816795.2818129}}

@article{Lee2010,
	Abstract = {Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important as- pect for emerging applications. Our analysis of a set of important throughput computing kernels shows that there is an ample amount of parallelism in these kernels which makes them suitable for to- day's multi-core CPUs and GPUs. In the past few years there have beenmany studies claimingGPUs deliver substantial speedups (be- tween 10X and 1000X) over multi-core CPUs on these kernels. To understand where such large performance difference comes from, we perform a rigorous performance analysis and find that after ap- plying optimizations appropriate for both CPUs and GPUs the per- formance gap between an Nvidia GTX280 processor and the Intel Core i7 960 processor narrows to only 2.5x on average. In this pa- per, we discuss optimization techniques for both CPU and GPU, analyze what architecture features contributed to performance dif- ferences between the two architectures, and recommend a set of architectural features which provide significant improvement in ar- chitectural efficiency for throughput kernels.},
	Author = {Lee, V},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1815961.1816021},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lee - 2010 - Debunking the 100X GPU vs. CPU myth An evaluation of throughput computing on CPU and GPU.pdf:pdf},
	Isbn = {9781450300537},
	Issn = {01635964},
	Journal = {Isca},
	Keywords = {CPU architecture,GPUarchitecture,Performance analysis,Performance measurement,Software optimization,Throughput Computing},
	Number = {3},
	Pages = {451--460},
	Title = {{Debunking the 100X GPU vs. CPU myth: An evaluation of throughput computing on CPU and GPU}},
	Url = {http://dx.doi.org/10.1145/1816038.1816021},
	Volume = {38},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1816038.1816021},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1815961.1816021}}

@misc{Liang2014,
	Author = {Liang, D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Title = {{Deep collaborative Poisson factorization}},
	Url = {https://github.com/dawenl/deep{\_}content{\_}cf},
	Year = {2014},
	Bdsk-Url-1 = {https://github.com/dawenl/deep%7B%5C_%7Dcontent%7B%5C_%7Dcf}}

@article{Ozair2014,
	Abstract = {For discrete data, the likelihood {\$}P(x){\$} can be rewritten exactly and parametrized into {\$}P(X = x) = P(X = x | H = f(x)) P(H = f(x)){\$} if {\$}P(X | H){\$} has enough capacity to put no probability mass on any {\$}x'{\$} for which {\$}f(x')\backslashneq f(x){\$}, where {\$}f(\backslashcdot){\$} is a deterministic discrete function. The log of the first factor gives rise to the log-likelihood reconstruction error of an autoencoder with {\$}f(\backslashcdot){\$} as the encoder and {\$}P(X|H){\$} as the (probabilistic) decoder. The log of the second term can be seen as a regularizer on the encoded activations {\$}h=f(x){\$}, e.g., as in sparse autoencoders. Both encoder and decoder can be represented by a deep neural network and trained to maximize the average of the optimal log-likelihood {\$}\backslashlog p(x){\$}. The objective is to learn an encoder {\$}f(\backslashcdot){\$} that maps {\$}X{\$} to {\$}f(X){\$} that has a much simpler distribution than {\$}X{\$} itself, estimated by {\$}P(H){\$}. This "flattens the manifold" or concentrates probability mass in a smaller number of (relevant) dimensions over which the distribution factorizes. Generating samples from the model is straightforward using ancestral sampling. One challenge is that regular back-propagation cannot be used to obtain the gradient on the parameters of the encoder, but we find that using the straight-through estimator works well here. We also find that although optimizing a single level of such architecture may be difficult, much better results can be obtained by pre-training and stacking them, gradually transforming the data distribution into one that is more easily captured by a simple parametric model.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1410.0630},
	Author = {Ozair, Sherjil and Bengio, Yoshua},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1410.0630},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ozair, Bengio - 2014 - Deep Directed Generative Autoencoders.pdf:pdf},
	Pages = {1--10},
	Title = {{Deep Directed Generative Autoencoders}},
	Url = {http://arxiv.org/abs/1410.0630},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1410.0630}}

@article{Piech2015a,
	Abstract = {Knowledge tracing---where a machine models the knowledge of a student as they interact with coursework---is a well established problem in computer supported education. Though effectively modeling student knowledge would have high ed-ucational impact, the task has many inherent challenges. In this paper we explore the utility of using Recurrent Neural Networks (RNNs) to model student learning. The RNN family of models have important advantages over previous methods in that they do not require the explicit encoding of human domain knowledge, and can capture more complex representations of student knowledge. Using neu-ral networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets. Moreover the learned model can be used for intelligent curriculum design and allows straightforward interpretation and dis-covery of structure in student tasks. These results suggest a promising new line of research for knowledge tracing and an exemplary application task for RNNs.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.05908v1},
	Author = {Piech, Chris and Spencer, Jonathan and Huang, Jonathan and Ganguli, Surya and Sahami, Mehran and Guibas, Leonidas and Sohl-dickstein, Jascha and Academy, Khan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.05908v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Piech et al. - 2015 - Deep Knowledge Tracing.pdf:pdf},
	Pages = {1--13},
	Title = {{Deep Knowledge Tracing}},
	Url = {http://arxiv.org/pdf/1506.05908.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.05908.pdf}}

@article{Dahl2015,
	Abstract = {The deep learning approach to machine learning emphasizes high-capacity, scalable models that learn distributed representations of their input. This dissertation demonstrates the efficacy and generality of this approach in a series of diverse case studies in speech recognition, computational chemistry, and natural language processing. Throughout these studies, I extend and modify the neural network models as needed to be more effective for each task. In the area of speech recognition, I develop a more accurate acoustic model using a deep neural network. This model, which uses rectified linear units and dropout, improves word error rates on a 50 hour broadcast news task. A similar neural network results in a model for molecular activity prediction substantially more effective than production systems used in the pharmaceutical industry. Even though training assays in drug discovery are not typically very large, it is still possible to train very large models by leveraging data from multiple assays in the same model and by using effective regularization schemes. In the area of natural language processing, I first describe a new restricted Boltzmann machine training algorithm suitable for text data. Then, I introduce a new neural network generative model of parsed sentences capable of generating reasonable samples and demonstrate a performance advantage for deeper variants of the model.},
	Author = {Dahl, George Edward},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Dahl - 2015 - Deep Learning Approaches to Problems in Speech Recognition, Computational Chemistry, and Natural Language Text Processing.pdf:pdf},
	Pages = {101},
	Title = {{Deep Learning Approaches to Problems in Speech Recognition, Computational Chemistry, and Natural Language Text Processing}},
	Url = {http://www.cs.toronto.edu/{~}gdahl/papers/Dahl{\_}George{\_}E{\_}201506{\_}PhD{\_}thesis.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cs.toronto.edu/%7B~%7Dgdahl/papers/Dahl%7B%5C_%7DGeorge%7B%5C_%7DE%7B%5C_%7D201506%7B%5C_%7DPhD%7B%5C_%7Dthesis.pdf}}

@article{Sohl-Dickstein2015,
	Abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
	Archiveprefix = {arXiv},
	Arxivid = {1503.03585},
	Author = {Sohl-Dickstein, Jascha and Weiss, Eric a. and Maheswaranathan, Niru and Ganguli, Surya},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1503.03585},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Sohl-Dickstein et al. - 2015 - Deep Unsupervised Learning using Nonequilibrium Thermodynamics.pdf:pdf},
	Title = {{Deep Unsupervised Learning using Nonequilibrium Thermodynamics}},
	Url = {http://arxiv.org/abs/1503.03585},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1503.03585}}

@article{Sohl-Dickstein2015b,
	Abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1503.03585v7},
	Author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1503.03585v7},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Sohl-Dickstein et al. - 2015 - Deep Unsupervised Learning using Nonequilibrium Thermodynamics(2).pdf:pdf},
	Journal = {Proceedings of The 32nd International Conference on Machine Learning},
	Pages = {2256--2265},
	Title = {{Deep Unsupervised Learning using Nonequilibrium Thermodynamics}},
	Url = {http://jmlr.org/proceedings/papers/v37/sohl-dickstein15.html},
	Year = {2015},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v37/sohl-dickstein15.html}}

@article{Ellis,
	Author = {Ellis, Kevin},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ellis - Unknown - Dimensionality Reduction via Program Induction.pdf:pdf},
	Pages = {1--8},
	Title = {{Dimensionality Reduction via Program Induction}},
	Url = {http://web.mit.edu/ellisk/www/pidimred.pdf},
	Bdsk-Url-1 = {http://web.mit.edu/ellisk/www/pidimred.pdf}}

@article{Linderman,
	Abstract = {Networks play a central role in modern data analysis, enabling us to reason about systems by studying the relationships between their parts. Most often in network analysis, the edges are given. How-ever, in many systems it is difficult or impossible to measure the network directly. Examples of latent networks include economic in-teractions linking financial instruments and patterns of reciprocity in gang violence. In these cases, we are limited to noisy observations of events associated with each node. To enable analysis of these implicit networks, we develop a probabilistic model that combines mutually-exciting point processes with random graph models. We show how the Poisson superposition principle enables an elegant auxiliary vari-able formulation and a fully-Bayesian, parallel inference algorithm. We evaluate this new model empirically on several datasets.},
	Author = {Linderman, Scott W and Adams, Ryan P},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Linderman, Adams - Unknown - DISCOVERING LATENT NETWORK STRUCTURE IN POINT PROCESS DATA.pdf:pdf},
	Title = {{DISCOVERING LATENT NETWORK STRUCTURE IN POINT PROCESS DATA}}}

@article{Le2014,
	Abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1405.4053},
	Author = {Le, Qv and Mikolov, Tomas},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1405.4053},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Le, Mikolov - 2014 - Distributed Representations of Sentences and Documents.pdf:pdf},
	Isbn = {9781634393973},
	Journal = {ICML},
	Pages = {1188--1196},
	Title = {{Distributed Representations of Sentences and Documents}},
	Url = {http://arxiv.org/abs/1405.4053},
	Volume = {32},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1405.4053}}

@article{Mikolov2013,
	Abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large num- ber of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alterna- tive to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of ``Canada'' and ``Air'' cannot be easily combined to obtain ``Air Canada''. Motivated by this example,we present a simplemethod for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	Archiveprefix = {arXiv},
	Arxivid = {1310.4546},
	Author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1162/jmlr.2003.3.4-5.951},
	Eprint = {1310.4546},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mikolov et al. - 2013 - Distributed representations of words and phrases and their compositionality.pdf:pdf},
	Issn = {10495258},
	Journal = {Neural Information Processing Systems},
	Pages = {1--9},
	Title = {{Distributed representations of words and phrases and their compositionality}},
	Url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1162/jmlr.2003.3.4-5.951}}

@article{Dai2015,
	Abstract = {Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1507.07998},
	Author = {Dai, Andrew M. and Olah, Christopher and Le, Quoc V.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1507.07998},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Dai, Olah, Le - 2015 - Document Embedding with Paragraph Vectors.pdf:pdf},
	Pages = {1--8},
	Title = {{Document Embedding with Paragraph Vectors}},
	Url = {http://arxiv.org/abs/1507.07998},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1507.07998}}

@article{Hinton2014,
	Abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different ``thinned'' networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
	Author = {Hinton, Geoffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hinton - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
	Isbn = {1532-4435},
	Issn = {15337928},
	Journal = {Journal of Machine Learning Research (JMLR)},
	Keywords = {deep learning,model combination,neural networks,regularization},
	Pages = {1929--1958},
	Title = {{Dropout : A Simple Way to Prevent Neural Networks from Overfitting}},
	Url = {http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf},
	Volume = {15},
	Year = {2014},
	Bdsk-Url-1 = {http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf}}

@article{Socher,
	Author = {Socher, Richard and Huang, Eric H and Pennington, Jeffrey and Ng, Andrew Y and Manning, Christopher D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Socher et al. - 2011 - Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection.pdf:pdf},
	Journal = {NIPS},
	Pages = {1--9},
	Title = {{Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection}},
	Url = {http://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/4204-dynamic-pooling-and-unfolding-recursive-autoencoders-for-paraphrase-detection.pdf}}

@book{Meyers2014,
	Abstract = {Coming to grips with C++11 and C++14 is more than a matter of familiarizing yourself with the features they introduce (e.g., auto type declarations, move semantics, lambda expressions, and concurrency support). The challenge is learning to use those features effectively---so that your software is correct, efficient, maintainable, and portable. That's where this practical book comes in. It describes how to write truly great software using C++11 and C++14---i.e. using modern C++. Topics include: The pros and cons of braced initialization, noexcept specifications, perfect forwarding, and smart pointer make functions The relationships among std::move, std::forward, rvalue references, and universal references Techniques for writing clear, correct, effective lambda expressions How std::atomic differs from volatile, how each should be used, and how they relate to C++'s concurrency API How best practices in "old" C++ programming (i.e., C++98) require revision for software development in modern C++ Effective Modern C++ follows the proven guideline-based, example-driven format of Scott Meyers' earlier books, but covers entirely new material. "After I learned the C++ basics, I then learned how to use C++ in production code from Meyer's series of Effective C++ books. Effective Modern C++ is the most important how-to book for advice on key guidelines, styles, and idioms to use modern C++ effectively and well. Don't own it yet? Buy this one. Now". -- Herb Sutter, Chair of ISO C++ Standards Committee and C++ Software Architect at Microsoft},
	Author = {Meyers, Scott},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Meyers - 2014 - Effective Modern C . 42 Specific ways to improve your use of C11 and C14.pdf:pdf},
	Isbn = {9781491903995},
	Pages = {334},
	Title = {{Effective Modern C ++. 42 Specific ways to improve your use of C++11 and C++14}},
	Year = {2014}}

@article{Mikolov2013a,
	Abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1301.3781v3},
	Author = {Mikolov, Tomas and Corrado, Greg and Chen, Kai and Dean, Jeffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1301.3781v3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf:pdf},
	Journal = {ICLR},
	Pages = {1--12},
	Title = {{Efficient Estimation of Word Representations in Vector Space}},
	Url = {http://arxiv.org/pdf/1301.3781v3.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1301.3781v3.pdf}}

@article{Chen2015,
	Abstract = {We develop a fully discriminative learning approach for supervised Latent Dirichlet Allocation (LDA) model using Back Propagation (i.e., BP-sLDA), which maximizes the posterior probability of the prediction variable given the input document. Different from traditional variational learning or Gibbs sampling approaches, the proposed learning method applies (i) the mirror descent algorithm for maximum a posterior inference and (ii) back propagation over a deep architecture together with stochastic gradient/mirror descent for model parameter estimation, leading to scalable and end-to-end discriminative learning of the model. As a byproduct, we also apply this technique to develop a new learning method for the traditional unsupervised LDA model (i.e., BP-LDA). Experimental results on three real-world regression and classification tasks show that the proposed methods significantly outperform the previous supervised topic models, neural networks, and is on par with deep neural networks.},
	Archiveprefix = {arXiv},
	Arxivid = {1508.03398},
	Author = {Chen, Jianshu and He, Ji and Shen, Yelong and Xiao, Lin and He, Xiaodong and Gao, Jianfeng and Song, Xinying and Deng, Li},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1508.03398},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Chen et al. - 2015 - End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture.pdf:pdf},
	Pages = {1--9},
	Title = {{End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture}},
	Url = {http://arxiv.org/abs/1508.03398},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1508.03398}}

@article{Zhang2015,
	Abstract = {Weak topic correlation across document collections with different numbers of topics in individual collections presents challenges for existing cross-collection topic models. This paper introduces two probabilistic topic models, Correlated LDA (C-LDA) and Correlated HDP (C-HDP). These address problems that can arise when analyzing large, asymmetric, and potentially weakly-related collections. Topic correlations in weakly-related collections typically lie in the tail of the topic distribution, where they would be overlooked by models unable to fit large numbers of topics. To efficiently model this long tail for large-scale analysis, our models implement a parallel sampling algorithm based on the Metropolis-Hastings and alias methods (Yuan et al., 2015). The models are first evaluated on synthetic data, generated to simulate various collection-level asymmetries. We then present a case study of modeling over 300k documents in collections of sciences and humanities research from JSTOR.},
	Archiveprefix = {arXiv},
	Arxivid = {1508.04562},
	Author = {Zhang, Jingwei and Gerow, Aaron and Altosaar, Jaan and Evans, James and So, Richard Jean},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1508.04562},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zhang et al. - 2015 - Fast, flexible models for discovering topic correlation across weakly-related collections.pdf:pdf},
	Journal = {Empirical Methods on Natural Language Processing},
	Title = {{Fast, flexible models for discovering topic correlation across weakly-related collections}},
	Url = {http://arxiv.org/abs/1508.04562},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1508.04562}}

@article{Hohnhold,
	Author = {Hohnhold, Henning and Brien, Deirdre O and Tang, Diane},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/Downloads/Focusing on the Long-term- It's Good for Users and Business.pdf:pdf},
	Isbn = {9781450336642},
	Keywords = {a,b testing,controlled experiments,overall evaluation criterion,predictive modeling},
	Title = {{Focusing on the Long-term : It ' s Good for Users and Business}}}

@book{Seeger2004,
	Abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
	Archiveprefix = {arXiv},
	Arxivid = {026218253X},
	Author = {Rasmussen},
	Booktitle = {International journal of neural systems},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1142/S0129065704001899},
	Eprint = {026218253X},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Rasmussen - 2004 - Gaussian processes for machine learning.pdf:pdf},
	Isbn = {026218253X},
	Issn = {0129-0657},
	Number = {2},
	Pages = {69--106},
	Pmid = {15112367},
	Title = {{Gaussian processes for machine learning.}},
	Url = {http://www.gaussianprocess.org/gpml/chapters/RW.pdf},
	Volume = {14},
	Year = {2004},
	Bdsk-Url-1 = {http://www.gaussianprocess.org/gpml/chapters/RW.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1142/S0129065704001899}}

@article{Ritchie2015,
	Author = {Ritchie, Daniel and Lin, Sharon and Goodman, Noah D and Hanrahan, Pat},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ritchie et al. - 2015 - Generating Design Suggestions under Tight Constraints with Gradient-based Probabilistic Programming.pdf:pdf},
	Number = {2},
	Title = {{Generating Design Suggestions under Tight Constraints with Gradient-based Probabilistic Programming}},
	Url = {http://cocolab.stanford.edu/papers/RitchieEtAl2015-Eurographics.pdf},
	Volume = {34},
	Year = {2015},
	Bdsk-Url-1 = {http://cocolab.stanford.edu/papers/RitchieEtAl2015-Eurographics.pdf}}

@article{Bowman2015a,
	Abstract = {The standard unsupervised recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global distributed sentence representation. In this work, we present an RNN-based variational autoencoder language model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate strong performance in the imputation of missing tokens, and explore many interesting properties of the latent sentence space.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1511.06349},
	Author = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1511.06349},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bowman et al. - 2015 - Generating Sentences from a Continuous Space.pdf:pdf},
	Pages = {1--13},
	Title = {{Generating Sentences from a Continuous Space}},
	Url = {http://arxiv.org/abs/1511.06349},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.06349}}

@article{Paulus,
	Author = {Paulus, Romain and Socher, Richard and Manning, Christopher D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Paulus, Socher, Manning - Unknown - Global Belief Recursive Neural Networks.pdf:pdf},
	Pages = {1--9},
	Title = {{Global Belief Recursive Neural Networks}},
	Url = {http://papers.nips.cc/paper/5275-global-belief-recursive-neural-networks.pdf},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5275-global-belief-recursive-neural-networks.pdf}}

@article{Pennington,
	Author = {Pennington, Jeffrey and Manning, C},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Pennington, Manning - Unknown - Glove Global vectors for word representation.pdf:pdf},
	Journal = {Emnlp2014.Org},
	Title = {{Glove: Global vectors for word representation}},
	Url = {http://emnlp2014.org/papers/pdf/EMNLP2014162.pdf},
	Bdsk-Url-1 = {http://emnlp2014.org/papers/pdf/EMNLP2014162.pdf}}

@article{Erosheva2002,
	Abstract = {Multivariate categorical data, such as binary or multiple choice individual responses to a set of questions, are abundant in the social sciences. These data can be recorded in a multi-way con- tingency table, which quickly becomes sparse with any practical sample size when the number of questions goes up. Latent structure models, such as latent class and latent trait models, provide a way to model the distribution of counts in a large sparse contingency table based on assump- tions about the latent structure of the data. This work examines a relatively new latent structure model, the Grade of Membership (GoM) model, integrating the GoM language and ideas with more standard statistical literature on latent variable models. The GoM model assumes that indi- viduals can have mixed membership in several subpopulations. Representing the GoM model as a constrained latent class model leads naturally to the Bayesian estimation framework developed and implemented in this dissertation. The analysis of a subset of functional disability data from the National Long Term Care survey provides an illustration of using the GoM and other latent structure models to describe the distribution of counts in a large sparse contingency table. Finally, a general class of mixed membership models is presented that unifies the latent structure of the GoM model and two other mixed membership models that recently appeared in the genetics and the machine learning literatures. i},
	Author = {Erosheva, Elena Aleksandrovna and Junker, Brian W and Lazar, Nicole a and Singer, Burton H and Erosheva, Elena a},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Erosheva et al. - 2002 - Grade of Membership and Latent Structure Models With Application to Disability Survey Data.pdf:pdf},
	Journal = {Simulation},
	Number = {August},
	Pages = {226},
	Title = {{Grade of Membership and Latent Structure Models With Application to Disability Survey Data}},
	Url = {http://www.stat.cmu.edu/{~}fienberg/NLTCS{\_}Models/Erosheva-thesis-2002.pdf},
	Year = {2002},
	Bdsk-Url-1 = {http://www.stat.cmu.edu/%7B~%7Dfienberg/NLTCS%7B%5C_%7DModels/Erosheva-thesis-2002.pdf}}

@article{Vinyals2014b,
	Abstract = {Syntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1412.7449},
	Author = {Vinyals, Oriol and Kaiser, Lukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1412.7449},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Vinyals et al. - 2014 - Grammar as a Foreign Language.pdf:pdf},
	Pages = {1--10},
	Title = {{Grammar as a Foreign Language}},
	Url = {http://arxiv.org/abs/1412.7449},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1412.7449}}

@article{Wainwright2007,
	Author = {Wainwright, Martin J. and Jordan, Michael I.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Wainwright, Jordan - 2007 - Graphical Models, Exponential Families, and Variational Inference.pdf:pdf},
	Journal = {Foundations and Trends in Machine Learning},
	Number = {2},
	Pages = {1--305},
	Title = {{Graphical Models, Exponential Families, and Variational Inference}},
	Url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000001},
	Volume = {1},
	Year = {2007},
	Bdsk-Url-1 = {http://www.nowpublishers.com/product.aspx?product=MAL%7B%5C&%7Ddoi=2200000001}}

@article{Cohl2015,
	Abstract = {One initial goal for the DRMF is to seed our digital compendium with fundamental orthogonal polynomial formulae. We had used the data from the NIST Digital Library of Mathematical Functions (DLMF) as initial seed for our DRMF project. The DLMF input LaTeX source already contains some semantic information encoded using a highly customized set of semantic LaTeX macros. Those macros could be converted to content MathML using LaTeXML. During that conversion the semantics were translated to an implicit DLMF content dictionary. This year, we have developed a semantic enrichment process whose goal is to infer semantic information from generic LaTeX sources. The generated context-free semantic information is used to build DRMF formula home pages for each individual formula. We demonstrate this process using selected chapters from the book "Hypergeometric Orthogonal Polynomials and their {\$}q{\$}-Analogues" (2010) by Koekoek, Lesky and Swarttouw (KLS) as well as an actively maintained addendum to this book by Koornwinder (KLSadd). The generic input KLS and KLSadd LaTeX sources describe the printed representation of the formulae, but does not contain explicit semantic information. See http://drmf.wmflabs.org.},
	Archiveprefix = {arXiv},
	Arxivid = {1505.01431},
	Author = {Cohl, Howard S. and Schubotz, Moritz and McClain, Marjorie a. and Saunders, Bonita V. and Zou, Cherry Y. and Mohammed, Azeem S. and Danoff, Alex a.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1505.01431},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Cohl et al. - 2015 - Growing the Digital Repository of Mathematical Formulae with Generic LaTeX Sources.pdf:pdf},
	Number = {2},
	Title = {{Growing the Digital Repository of Mathematical Formulae with Generic LaTeX Sources}},
	Url = {http://arxiv.org/abs/1505.01431},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1505.01431}}

@article{Bornmann2014,
	Abstract = {Many studies in information science have looked at the growth of science. In this study, we re-examine the question of the growth of science. To do this we (i) use current data up to publication year 2012 and (ii) analyse it across all disciplines and also separately for the natural sciences and for the medical and health sciences. Furthermore, the data are analysed with an advanced statistical technique -- segmented regression analysis -- which can identify specific segments with similar growth rates in the history of science. The study is based on two different sets of bibliometric data: (1) The number of publications held as source items in the Web of Science (WoS, Thomson Reuters) per publication year and (2) the number of cited references in the publications of the source items per cited reference year. We have looked at the rate at which science has grown since the mid-1600s. In our analysis of cited references we identified three growth phases in the development of science, which each led to growth rates tripling in comparison with the previous phase: from less than 1{\%} up to the middle of the 18th century, to 2 to 3{\%} up to the period between the two world wars and 8 to 9{\%} to 2012.},
	Archiveprefix = {arXiv},
	Arxivid = {1402.4578v3},
	Author = {Bornmann, Lutz and Mutz, R{\"{u}}diger},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1402.4578v3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bornmann, Mutz - 2014 - Growth rates of modern science A bibliometric analysis based on the number of publications and cited references.pdf:pdf},
	Journal = {Journal of the Association for Information Science and Technology},
	Pages = {1--28},
	Title = {{Growth rates of modern science : A bibliometric analysis based on the number of publications and cited references}},
	Url = {http://arxiv.org/abs/1402.4578},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1402.4578}}

@article{Sculley,
	Author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Dennison, Dan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Sculley et al. - Unknown - Hidden Technical Debt in Machine Learning Systems.pdf:pdf},
	Pages = {1--9},
	Title = {{Hidden Technical Debt in Machine Learning Systems}},
	Url = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf}}

@article{Ioannidis2014,
	Author = {Ioannidis, John P. A.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1371/journal.pmed.1001747},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ioannidis - 2014 - How to Make More Published Research True.pdf:pdf},
	Issn = {1549-1676},
	Journal = {PLoS Medicine},
	Month = {oct},
	Number = {10},
	Pages = {e1001747},
	Title = {{How to Make More Published Research True}},
	Url = {http://dx.plos.org/10.1371/journal.pmed.1001747},
	Volume = {11},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.plos.org/10.1371/journal.pmed.1001747},
	Bdsk-Url-2 = {http://dx.doi.org/10.1371/journal.pmed.1001747}}

@article{Dinu,
	Author = {Dinu, Georgiana and Baroni, Marco},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Dinu, Baroni - Unknown - How to make words with vectors Phrase generation in distributional semantics.pdf:pdf},
	Title = {{How to make words with vectors : Phrase generation in distributional semantics}},
	Url = {http://clic.cimec.unitn.it/marco/publications/acl2014/dinu-baroni-generation-acl2014.pdf},
	Bdsk-Url-1 = {http://clic.cimec.unitn.it/marco/publications/acl2014/dinu-baroni-generation-acl2014.pdf}}

@article{Keshav2007,
	Abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	Author = {Keshav, S.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1273445.1273458},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Keshav - 2007 - How to read a paper.pdf:pdf},
	Isbn = {1405139765},
	Issn = {01464833},
	Journal = {ACM SIGCOMM Computer Communication Review},
	Keywords = {4,at the end of,glance over the references,hints,mentally ticking off the,ones you,paper,reading,the first pass,to answer,ve already read,you should be able},
	Number = {3},
	Pages = {83},
	Pmid = {15735874},
	Title = {{How to read a paper}},
	Url = {http://ccr.sigcomm.org/online/files/p83-keshavA.pdf},
	Volume = {37},
	Year = {2007},
	Bdsk-Url-1 = {http://ccr.sigcomm.org/online/files/p83-keshavA.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1273445.1273458}}

@article{Lake2015,
	Abstract = {People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms---for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several " visual Turing tests " probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior. D espite remarkable advances in artificial intelligence and machine learning, two aspects of human conceptual knowledge have eluded machine systems. First, for most interesting kinds of natural and man-made categories, people can learn a new concept from just one or a handful of examples, whereas standard algorithms in machine learning require tens or hundreds of examples to perform simi-larly. For instance, people may only need to see one example of a novel two-wheeled vehicle (Fig. 1A) in order to grasp the boundaries of the new concept, and even children can make mean-ingful generalizations via " one-shot learning " (1--3). In contrast, many of the leading approaches in machine learning are also the most data-hungry, especially " deep learning " models that have achieved new levels of performance on object and speech recognition benchmarks (4--9). Sec-ond, people learn richer representations than machines do, even for simple concepts (Fig. 1B), using them for a wider range of functions, in-cluding (Fig. 1, ii) creating new exemplars (10), (Fig. 1, iii) parsing objects into parts and rela-tions (11), and (Fig. 1, iv) creating new abstract categories of objects based on existing categories (12, 13). In contrast, the best machine classifiers do not perform these additional functions, which are rarely studied and usually require special-ized algorithms. A central challenge is to ex-plain these two aspects of human-level concept learning: How do people learn new concepts from just one or a few examples? And how do people learn such abstract, rich, and flexible rep-resentations? An even greater challenge arises when putting them together: How can learning succeed from such sparse data yet also produce such rich representations? For any theory of RESEARCH},
	Author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1126/science.aab3050},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lake, Salakhutdinov, Tenenbaum - 2015 - Human-level concept learning through probabilistic program induction.pdf:pdf},
	Issn = {0036-8075},
	Number = {December},
	Title = {{Human-level concept learning through probabilistic program induction}},
	Url = {http://www.sciencemag.org/content/suppl/2015/12/09/350.6266.1332.DC1/Lake-SM.pdf},
	Volume = {1332},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/suppl/2015/12/09/350.6266.1332.DC1/Lake-SM.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1126/science.aab3050}}

@article{Burda2016,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1509.00519v2},
	Author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2017-02-24 20:58:16 +0000},
	Eprint = {arXiv:1509.00519v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Burda, Grosse, Salakhutdinov - 2016 - Importance weighted autoencoders.pdf:pdf},
	Journal = {International Conference on Learning Representations},
	Title = {{Importance weighted autoencoders}},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1509.00519v2.pdf}}

@article{Tai2015,
	Abstract = {A Long Short-Term Memory (LSTM) net-work is a type of recurrent neural net-work architecture which has recently ob-tained strong results on a variety of se-quence modeling tasks. The only under-lying LSTM structure that has been ex-plored so far is a linear chain. How-ever, natural language exhibits syntac-tic properties that would naturally com-bine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Senti-ment Treebank).},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1503.00075v2},
	Author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1503.00075v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Tai, Socher, Manning - 2015 - Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks.pdf:pdf},
	Journal = {Acl-2015},
	Pages = {1556--1566},
	Title = {{Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks}},
	Url = {http://arxiv.org/pdf/1503.00075v3.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1503.00075v3.pdf}}

@article{Levy2015a,
	Abstract = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distri-butional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter op-timizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
	Author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Levy, Goldberg, Dagan - 2015 - Improving Distributional Similarity with Lessons Learned from Word Embeddings.pdf:pdf},
	Issn = {2307-387X},
	Journal = {Transactions of the ACL},
	Pages = {211--225},
	Title = {{Improving Distributional Similarity with Lessons Learned from Word Embeddings}},
	Url = {http://aclweb.org/anthology/Q/Q15/Q15-1016.pdf},
	Volume = {3},
	Year = {2015},
	Bdsk-Url-1 = {http://aclweb.org/anthology/Q/Q15/Q15-1016.pdf}}

@article{Dias2013,
	Author = {Dias, Ricardo and Fonseca, Manuel J.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1109/ICTAI.2013.120},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Dias, Fonseca - 2013 - Improving Music Recommendation in Session-Based Collaborative Filtering by Using Temporal Context.pdf:pdf},
	Isbn = {978-1-4799-2972-6},
	Journal = {2013 IEEE 25th International Conference on Tools with Artificial Intelligence},
	Month = {nov},
	Pages = {783--788},
	Publisher = {Ieee},
	Title = {{Improving Music Recommendation in Session-Based Collaborative Filtering by Using Temporal Context}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6735331},
	Year = {2013},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6735331},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/ICTAI.2013.120}}

@article{Huang2012,
	Abstract = {Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one represen- tation per word. This is problematic because words are often polysemous and global con- text can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the se- mantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning mul- tiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outper- forms competitive baselines and other neural language models.},
	Author = {Huang, Eric H and Socher, Richard and Manning, Christopher D and Ng, Andrew Y},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Huang et al. - 2012 - Improving Word Representations via Global Context and MultipleWord Prototypes.pdf:pdf},
	Isbn = {9781937284244},
	Journal = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics},
	Number = {July},
	Pages = {873--882},
	Title = {{Improving Word Representations via Global Context and MultipleWord Prototypes}},
	Url = {http://www.aclweb.org/anthology/P12-1092},
	Year = {2012},
	Bdsk-Url-1 = {http://www.aclweb.org/anthology/P12-1092}}

@article{Li2009,
	Author = {Li, Xin and Li, Fan and Ji, Shihao and Zheng, Zhaohui and Chang, Yi and Dong, Anlei},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1645953.1646288},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Li et al. - 2009 - Incorporating robustness into web ranking evaluation.pdf:pdf},
	Isbn = {9781605585123},
	Journal = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
	Keywords = {ndcg,ranking robustness,web ranking},
	Pages = {2007},
	Title = {{Incorporating robustness into web ranking evaluation}},
	Url = {http://portal.acm.org/citation.cfm?doid=1645953.1646288},
	Year = {2009},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1645953.1646288},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1645953.1646288}}

@article{Pritchard,
	Abstract = {We describe a model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations. We assume a model in which there are K populations (where K may be unknown), each of which is characterized by a set of allele frequencies at each locus. Individuals in the sample are assigned (probabilistically) to populations, or jointly to two or more popula-tions if their genotypes indicate that they are admixed. Our model does not assume a particular mutation process, and it can be applied to most of the commonly used genetic markers, provided that they are not closely linked. Applications of our method include demonstrating the presence of population structure, assigning individuals to populations, studying hybrid zones, and identifying migrants and admixed individu-als. We show that the method can produce highly accurate assignments using modest numbers of loci---e.g., seven microsatellite loci in an example using genotype data from an endangered bird species. The software used for this article is available from},
	Author = {Pritchard, Jonathan K and Stephens, Matthew and Donnelly, Peter},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Pritchard, Stephens, Donnelly - Unknown - Inference of Population Structure Using Multilocus Genotype Data.pdf:pdf},
	Title = {{Inference of Population Structure Using Multilocus Genotype Data}}}

@article{Joulin2015a,
	Abstract = {Despite the recent achievements in machine learning, we are still very far from achieving real artificial intelligence. In this paper, we discuss the limitations of standard deep learning approaches and show that some of these limitations can be overcome by learning how to grow the complexity of a model in a structured way. Specifically, we study the simplest sequence prediction problems that are beyond the scope of what is learnable with standard recurrent networks, algorithmically generated sequences which can only be learned by models which have the capacity to count and to memorize sequences. We show that some basic algorithms can be learned from sequential data using a recurrent network associated with a trainable memory.},
	Archiveprefix = {arXiv},
	Arxivid = {1503.01007},
	Author = {Joulin, Armand and Mikolov, Tomas},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1503.01007},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Joulin, Mikolov - 2015 - Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets.pdf:pdf},
	Pages = {1--10},
	Title = {{Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets}},
	Url = {http://arxiv.org/abs/1503.01007},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1503.01007}}

@book{Mezard:2009:IPC:1592967,
	Address = {New York, NY, USA},
	Author = {Mezard, Marc and Montanari, Andrea},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Isbn = {019857083X, 9780198570837},
	Publisher = {Oxford University Press, Inc.},
	Title = {{Information, Physics, and Computation}},
	Year = {2009}}

@article{Tkacik2014,
	Abstract = {Life depends as much on the flow of information as on the flow of energy. Here we review the many efforts to make this intuition precise. Starting with the building blocks of information theory, we explore examples where it has been possible to measure, directly, the flow of information in biological networks, or more generally where information theoretic ideas have been used to guide the analysis of experiments. Systems of interest range from single molecules (the sequence diversity in families of proteins) to groups of organisms (the distribution of velocities in flocks of birds), and all scales in between. Many of these analyses are motivated by the idea that biological systems may have evolved to optimize the gathering and representation of information, and we review the experimental evidence for this optimization, again across a wide range of scales.},
	Archiveprefix = {arXiv},
	Arxivid = {1412.8752},
	Author = {Tka{\v{c}}ik, Ga{\v{s}}per and Bialek, William},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1412.8752},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Tka{\v{c}}ik, Bialek - 2014 - Information processing in living systems.pdf:pdf},
	Journal = {Exploring Complexity Fall 2011/ Information Processing In LivingSystems},
	Pages = {1--21},
	Title = {{Information processing in living systems}},
	Url = {http://arxiv.org/abs/1412.8752},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1412.8752}}

@article{Baqu,
	Author = {Baqu, Pierre and Fua, Pascal},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Baqu, Fua - 2015 - Kullback-Leibler Proximal Variational Inference.pdf:pdf},
	Journal = {Neural Information Processing Systems},
	Pages = {1--9},
	Title = {{Kullback-Leibler Proximal Variational Inference}},
	Url = {http://papers.nips.cc/paper/5895-kullback-leibler-proximal-variational-inference.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5895-kullback-leibler-proximal-variational-inference.pdf}}

@article{Thomas2001b,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1511.08228v2},
	Author = {Thomas, Pierre},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.2307/2486811},
	Eprint = {arXiv:1511.08228v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Thomas - 2001 - L 'a ,.pdf:pdf},
	Issn = {1097-0266},
	Pages = {1--9},
	Title = {{L 'a , ?}},
	Url = {http://arxiv.org/pdf/1511.08228v2.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1511.08228v2.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.2307/2486811}}

@article{Blei2003,
	Author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Blei, Ng, Jordan - 2003 - Latent Dirichlet Allocation.pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Pages = {993--1022},
	Title = {{Latent Dirichlet Allocation}},
	Url = {http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf},
	Volume = {3},
	Year = {2003},
	Bdsk-Url-1 = {http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf}}

@article{Guardia-Sebaoun2015,
	Abstract = {For recommender systems, time is often an important source of information but it is also a complex dimension to apprehend. We propose here to learn item and user representations such that any timely ordered sequence of items selected by a user will be repre- sented as a trajectory of the user in a representation space. This allows us to rank new items for this user. We then enrich the item and user representations in order to perform rating prediction using a classical matrix factorization scheme. We demonstrate the interest of our approach regarding both item ranking and rating prediction on a series of classical benchmarks.},
	Author = {Guardia-Sebaoun, Elie and Guigue, Vincent and Gallinari, Patrick},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/2792838.2799676},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Guardia-Sebaoun, Guigue, Gallinari - 2015 - Latent Trajectory Modeling A Light and Efficient Way to Introduce Time in Recommender Syste.pdf:pdf},
	Isbn = {9781450336925},
	Journal = {the 2015 ACM conference on Recommender systems, RecSys 2015},
	Pages = {281--284},
	Title = {{Latent Trajectory Modeling : A Light and Efficient Way to Introduce Time in Recommender Systems}},
	Url = {http://www-connex.lip6.fr/{~}guigue/wikihomepage/uploads/Research/recsys15.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www-connex.lip6.fr/%7B~%7Dguigue/wikihomepage/uploads/Research/recsys15.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2792838.2799676}}

@article{Choi2010,
	Abstract = {We study the problem of learning a latent tree graphical model where samples are available only from a subset of variables. We propose two consistent and computationally efficient algorithms for learning minimal latent trees, that is, trees without any redundant hidden nodes. Unlike many existing methods, the observed nodes (or variables) are not constrained to be leaf nodes. Our first algorithm, recursive grouping, builds the latent tree recursively by identifying sibling groups using so-called information distances. One of the main contributions of this work is our second algorithm, which we refer to as CLGrouping. CLGrouping starts with a pre-processing procedure in which a tree over the observed variables is constructed. This global step groups the observed nodes that are likely to be close to each other in the true latent tree, thereby guiding subsequent recursive grouping (or equivalent procedures) on much smaller subsets of variables. This results in more accurate and efficient learning of latent trees. We also present regularized versions of our algorithms that learn latent tree approximations of arbitrary distributions. We compare the proposed algorithms to other methods by performing extensive numerical experiments on various latent tree graphical models such as hidden Markov models and star graphs. In addition, we demonstrate the applicability of our methods on real-world datasets by modeling the dependency structure of monthly stock returns in the S{\&}P index and of the words in the 20 newsgroups dataset.},
	Archiveprefix = {arXiv},
	Arxivid = {1009.2722},
	Author = {Choi, Myung Jin and Tan, Vincent Y F and Anandkumar, Animashree and Willsky, Alan S},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1009.2722},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Choi et al. - 2010 - Learning Latent Tree Graphical Models.pdf:pdf},
	Isbn = {1532-4435},
	Issn = {1532-4435},
	Journal = {arXiv.org},
	Pages = {2722},
	Title = {{Learning Latent Tree Graphical Models}},
	Url = {http://adsabs.harvard.edu/cgi-bin/nph-data{\_}query?bibcode=2010arXiv1009.2722C{\&}link{\_}type=ABSTRACT$\backslash$npapers2://publication/uuid/132A76A7-20E1-4E5B-A6A8-BBBD6039BD93},
	Volume = {stat.ML},
	Year = {2010},
	Bdsk-Url-1 = {http://adsabs.harvard.edu/cgi-bin/nph-data%7B%5C_%7Dquery?bibcode=2010arXiv1009.2722C%7B%5C&%7Dlink%7B%5C_%7Dtype=ABSTRACT$%5Cbackslash$npapers2://publication/uuid/132A76A7-20E1-4E5B-A6A8-BBBD6039BD93}}

@article{Cho2014a,
	Abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1406.1078},
	Author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1406.1078},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.pdf:pdf},
	Title = {{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}},
	Url = {http://arxiv.org/abs/1406.1078},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1406.1078}}

@article{Piech2015b,
	Abstract = {Providing feedback, both assessing final work and giving hints to stuck students, is difficult for open-ended assignments in massive online classes which can range from thousands to mil- lions of students. We introduce a neural network method to encode programs as a linear mapping from an embedded precondition space to an em- bedded postcondition space and propose an al- gorithm for feedback at scale using these lin- ear maps as features. We apply our algorithm to assessments from the Code.org Hour of Code and Stanford University's CS1 course, where we propagate human comments on student assign- ments to orders of magnitude more submissions.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1505.05969v1},
	Author = {Piech, Christopher and Huang, Jonathan and Nguyen, Andy and Phulsuksombati, Mike and Sahami, Mehran and Guibas, Leonidas},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1505.05969v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Piech et al. - 2015 - Learning Program Embeddings to Propagate Feedback on Student Code(2).pdf:pdf},
	Journal = {Icml '15},
	Title = {{Learning Program Embeddings to Propagate Feedback on Student Code}},
	Url = {http://arxiv.org/pdf/1505.05969v1.pdf},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1505.05969v1.pdf}}

@article{Piech2015,
	Author = {Piech, Chris and Phulsuksombati, Mike and Guibas, Leonidas and Cs, Piech and Edu, Stanford},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Piech et al. - 2015 - Learning Program Embeddings to Propagate Feedback on Student Code.pdf:pdf},
	Title = {{Learning Program Embeddings to Propagate Feedback on Student Code}},
	Url = {http://jmlr.org/proceedings/papers/v37/piech15.pdf},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v37/piech15.pdf}}

@article{Liang2010,
	Author = {Liang, Percy and Jordan, Michael I and Klein, Dan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Liang, Jordan, Klein - 2010 - Learning Programs A Hierarchical {\{}Bayesian{\}} Approach.pdf:pdf},
	Journal = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
	Pages = {639--646},
	Title = {{Learning Programs: A Hierarchical {\{}Bayesian{\}} Approach}},
	Url = {http://www.icml2010.org/papers/568.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://www.icml2010.org/papers/568.pdf}}

@article{Bayer2014,
	Abstract = {Leveraging advances in variational inference, we propose to enhance recurrent neural networks with latent variables, resulting in Stochastic Recurrent Networks (STORNs). The model i) can be trained with stochastic gradient methods, ii) allows structured and multi-modal conditionals at each time step, iii) features a reliable estimator of the marginal likelihood and iv) is a generalisation of deterministic recurrent neural networks. We evaluate the method on four polyphonic musical data sets and motion capture data.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1411.7610},
	Author = {Bayer, Justin and Osendorfer, Christian},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1411.7610},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bayer, Osendorfer - 2014 - Learning Stochastic Recurrent Networks.pdf:pdf},
	Pages = {1--9},
	Title = {{Learning Stochastic Recurrent Networks}},
	Url = {http://arxiv.org/abs/1411.7610},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1411.7610}}

@article{Zaremba2014,
	Abstract = {In this paper we explore how machine learning techniques can be applied to the discovery of efficient mathematical identities. We introduce an attribute grammar framework for representing symbolic expressions. Given a set of grammar rules we build trees that combine different rules, looking for branches which yield compositions that are analytically equivalent to a target expression, but of lower computational complexity. However, as the size of the trees grows exponentially with the complexity of the target expression, brute force search is impractical for all but the simplest of expressions. Consequently, we introduce two novel learning approaches that are able to learn from simpler expressions to guide the tree search. The first of these is a simple n-gram model, the other being a recursive neural-network. We show how these approaches enable us to derive complex identities, beyond reach of brute-force search, or human derivation.},
	Archiveprefix = {arXiv},
	Arxivid = {1406.1584},
	Author = {Zaremba, Wojciech and Kurach, Karol and Fergus, Rob},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1406.1584},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zaremba, Kurach, Fergus - 2014 - Learning to Discover Efficient Mathematical Identities.pdf:pdf},
	Journal = {Advances in Neural Information Processing Systems},
	Number = {i},
	Pages = {1278--1286},
	Title = {{Learning to Discover Efficient Mathematical Identities}},
	Url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2014{\_}5350.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://machinelearning.wustl.edu/mlpapers/paper%7B%5C_%7Dfiles/NIPS2014%7B%5C_%7D5350.pdf}}

@article{Zaremba2014a,
	Abstract = {Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are widely used because they are expressive and are easy to train. Our interest lies in empirically evaluating the expressiveness and the learnability of LSTMs in the sequence-to-sequence regime by training them to evaluate short computer programs, a domain that has traditionally been seen as too complex for neural networks. We consider a simple class of programs that can be evaluated with a single left-to-right pass using constant memory. Our main result is that LSTMs can learn to map the character-level representations of such programs to their correct outputs. Notably, it was necessary to use curriculum learning, and while conventional curriculum learning proved ineffective, we developed a new variant of curriculum learning that improved our networks' performance in all experimental conditions. The improved curriculum had a dramatic impact on an addition problem, making it possible to train an LSTM to add two 9-digit numbers with 99{\%} accuracy.},
	Archiveprefix = {arXiv},
	Arxivid = {1410.4615},
	Author = {Zaremba, Wojciech and Sutskever, Ilya},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1410.4615},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zaremba, Sutskever - 2014 - Learning to Execute.pdf:pdf},
	Isbn = {1410.4615},
	Journal = {Iclr},
	Number = {Section 3},
	Pages = {1--25},
	Title = {{Learning to Execute}},
	Url = {http://arxiv.org/abs/1410.4615},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1410.4615}}

@article{Mnih2013,
	Abstract = {Continuous-valued word embeddings learned by neural language models have recently been shown to capture semantic and syntactic information aboutwords very well, setting performance records on severalword similarity tasks. The best results are obtained by learning high-dimensional embeddings from very large quantities of data, which makes scalability of the training method a critical factor. We propose a simple and scalable new approach to learning word embeddings based on training log-bilinear models with noise-contrastive estimation. Our approach is simpler, faster, and produces better results than the current state-of-the- art method. We achieve results comparable to the best ones reported, which were obtained on a cluster, using four times less data and more than an order of mag- nitude less computing time. We also investigate several model types and find that the embeddings learned by the simpler models perform at least as well as those learned by the more complex ones.},
	Author = {Mnih, Andriy},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mnih - 2013 - Learning word embeddings efficiently with noise-contrastive estimation.pdf:pdf},
	Journal = {Nips},
	Pages = {1--9},
	Title = {{Learning word embeddings efficiently with noise-contrastive estimation}},
	Url = {http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf}}

@article{Hinton,
	Author = {Tieleman, Tijmen and Hinton, Geoffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Tieleman, Hinton - 2012 - Lecture 6.5 - rmsprop.pdf:pdf},
	Journal = {COURSERA: Neural Networks for Machine Learning},
	Title = {{Lecture 6.5 - rmsprop}},
	Url = {http://www.cs.toronto.edu/{~}tijmen/csc321/slides/lecture{\_}slides{\_}lec6.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://www.cs.toronto.edu/%7B~%7Dtijmen/csc321/slides/lecture%7B%5C_%7Dslides%7B%5C_%7Dlec6.pdf}}

@article{tieleman2012lecture,
	Abstract = {Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012},
	Author = {Tieleman, Tijmen and Hinton, Geoffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2020-10-15 08:38:46 -0400},
	Journal = {COURSERA: Neural Networks for Machine Learning},
	Title = {{Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.}},
	Year = {2012}}

@book{Lange2013,
	Author = {Lange, Christoph and Sojka, Petr and Eds, Wolfgang Windsteiger and Goebel, Randy},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lange et al. - 2013 - LNAI 7961 - Intelligent Computer Mathematics.pdf:pdf},
	Isbn = {9783642393198},
	Number = {July},
	Title = {{LNAI 7961 - Intelligent Computer Mathematics}},
	Url = {http://download.springer.com/static/pdf/202/bok:978-3-642-39320-4.pdf?originUrl=http://link.springer.com/book/10.1007/978-3-642-39320-4{\&}token2=exp=1444235755{~}acl=/static/pdf/202/bok{\%}3A978-3-642-39320-4.pdf?originUrl=http://link.springer.com/bo},
	Year = {2013}}

@article{Hochreiter1997,
	Author = {Hochreiter, Sepp and Schmidhuber, Jurgen},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1162/neco.1997.9.8.1735},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hochreiter, Schmidhuber - 1997 - Long short-term memory.pdf:pdf},
	Isbn = {08997667 (ISSN)},
	Issn = {0899-7667},
	Journal = {Neural Computation},
	Number = {8},
	Pages = {1--32},
	Pmid = {9377276},
	Title = {{Long short-term memory}},
	Url = {http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97{\_}lstm.pdf},
	Volume = {9},
	Year = {1997},
	Bdsk-Url-1 = {http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97%7B%5C_%7Dlstm.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1162/neco.1997.9.8.1735}}

@article{Zhu2015,
	Abstract = {The chain-structured long short-term memory (LSTM) has showed to be effective in a wide range of problems such as speech recognition and machine translation. In this paper, we pro-pose to extend it to tree structures, in which a memory cell can reflect the history memories of multiple child cells or multiple descendant cells in a recursive process. We call the model S-LSTM, which provides a principled way of considering long-distance interaction over hier-archies, e.g., language or image parse structures. We leverage the models for semantic composi-tion to understand the meaning of text, a funda-mental problem in natural language understand-ing, and show that it outperforms a state-of-the-art recursive model by replacing its composition layers with the S-LSTM memory blocks. We also show that utilizing the given structures is helpful in achieving a performance better than that with-out considering the structures.},
	Author = {Zhu, Xiaodan and Sobhani, Parinaz and Guo, Hongyu},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zhu, Sobhani, Guo - 2015 - Long Short-Term Memory Over Recursive Structures.pdf:pdf},
	Journal = {Icml-2015},
	Title = {{Long Short-Term Memory Over Recursive Structures}},
	Url = {http://jmlr.org/proceedings/papers/v37/zhub15.pdf},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v37/zhub15.pdf}}

@article{Berman2014,
	Author = {Berman, Gordon J and Choi, Daniel M and Bialek, William and Shaevitz, Joshua W},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Berman et al. - 2014 - Mapping the stereotyped behaviour of freely moving fruit flies Mapping the stereotyped behaviour of freely moving.pdf:pdf},
	Journal = {Journal of the Royal Society Interface},
	Keywords = {biomechanics,biophysics,computational},
	Pages = {20140672},
	Title = {{Mapping the stereotyped behaviour of freely moving fruit flies Mapping the stereotyped behaviour of freely moving fruit flies}},
	Url = {http://rsif.royalsocietypublishing.org/content/11/99/20140672.full.pdf},
	Volume = {11},
	Year = {2014},
	Bdsk-Url-1 = {http://rsif.royalsocietypublishing.org/content/11/99/20140672.full.pdf}}

@article{Neal2000,
	Abstract = {This article reviews Markov chain methods for sampling from the posterior distribution of a Dirichlet process mixture model and presents two new classes of methods. One new approach is to make Metropolis-Hastings updates of the indicators specifying which mixture component is associated with each observation, perhaps supplemented with a partial form of Gibbs sampling. The other new approach extends Gibbs sampling for these indicators by using a set of auxiliary parameters. These methods are simple to implement and are more efficient than previous ways of handling general Dirichlet process mixture models with non-conjugate priors.},
	Author = {Neal, R M},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.2307/1390653},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Neal - 2000 - Markov chain sampling methods for Dirichlet process mixture models.pdf:pdf},
	Isbn = {1061-8600},
	Issn = {10618600},
	Journal = {Journal of computational and graphical statistics},
	Number = {2},
	Pages = {249--265},
	Title = {{Markov chain sampling methods for Dirichlet process mixture models}},
	Url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879$\backslash$npapers3://publication/uuid/87767AA7-9632-4186-975D-FA73EBF4B8E6},
	Volume = {9},
	Year = {2000},
	Bdsk-Url-1 = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879$%5Cbackslash$npapers3://publication/uuid/87767AA7-9632-4186-975D-FA73EBF4B8E6},
	Bdsk-Url-2 = {http://dx.doi.org/10.2307/1390653}}

@article{Silver2016,
	Author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1038/nature16961},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Silver et al. - 2016 - Mastering the game of Go with deep neural networks and tree search.pdf:pdf},
	Issn = {0028-0836},
	Journal = {Nature},
	Number = {7587},
	Pages = {484--489},
	Publisher = {Nature Publishing Group},
	Title = {{Mastering the game of Go with deep neural networks and tree search}},
	Url = {http://www.nature.com/doifinder/10.1038/nature16961},
	Volume = {529},
	Year = {2016},
	Bdsk-Url-1 = {http://www.nature.com/doifinder/10.1038/nature16961},
	Bdsk-Url-2 = {http://dx.doi.org/10.1038/nature16961}}

@article{Stamerjohanns2009,
	Author = {Stamerjohanns, Heinrich and Ginev, Deyan and David, Catalin and Misev, Dimitar and Kohlhase, Michael and Stamerjohanns, Heinrich and Ginev, Deyan and David, Catalin and Misev, Dimitar and Zamdzhiev, Vladimir and Kohlhase, Michael},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Stamerjohanns et al. - 2009 - MathML-aware Article Conversion from Latex.pdf:pdf},
	Isbn = {9788021047815},
	Title = {{MathML-aware Article Conversion from Latex}},
	Url = {http://dml.cz/bitstream/handle/10338.dmlcz/702561/DML{\_}002-2009-1{\_}12.pdf},
	Year = {2009},
	Bdsk-Url-1 = {http://dml.cz/bitstream/handle/10338.dmlcz/702561/DML%7B%5C_%7D002-2009-1%7B%5C_%7D12.pdf}}

@article{Koren2009,
	Abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.},
	Archiveprefix = {arXiv},
	Arxivid = {ISSN 0018-9162},
	Author = {Koren, Y. and Bell, R. and Volinsky, C.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1109/MC.2009.263},
	Eprint = {ISSN 0018-9162},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Koren, Bell, Volinsky - 2009 - Matrix Factorization Techniques for Recommender Systems.pdf:pdf},
	Isbn = {0018-9162},
	Issn = {0018-9162},
	Journal = {Computer},
	Keywords = {Computational intelligence,Matrix factorization,Netflix Prize},
	Number = {8},
	Pages = {42--49},
	Title = {{Matrix Factorization Techniques for Recommender Systems}},
	Url = {http://www.columbia.edu/{~}jwp2128/Teaching/W4721/papers/ieeecomputer.pdf},
	Volume = {42},
	Year = {2009},
	Bdsk-Url-1 = {http://www.columbia.edu/%7B~%7Djwp2128/Teaching/W4721/papers/ieeecomputer.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/MC.2009.263}}

@article{Liang2015,
	Abstract = {Collaborative filtering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis, the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative filtering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-the-art approaches as a special case of our model, and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four different domains both with and without exposure covariates.},
	Archiveprefix = {arXiv},
	Arxivid = {1510.07025},
	Author = {Liang, Dawen and Charlin, Laurent and McInerney, James and Blei, David M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1510.07025},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Liang et al. - 2015 - Modeling User Exposure in Recommendation.pdf:pdf},
	Title = {{Modeling User Exposure in Recommendation}},
	Year = {2015}}

@article{Lei2015,
	Abstract = {The success of deep learning often derives from well-chosen operational building blocks. In this work, we revise the temporal convolution operation in CNNs to better adapt it to text processing. Instead of concatenating word representations, we appeal to tensor algebra and use low-rank n-gram tensors to directly exploit interactions between words already at the convolution stage. Moreover, we extend the n-gram convolution to non-consecutive words to recognize patterns with intervening words. Through a combination of low-rank tensors, and pattern weighting, we can efficiently evaluate the resulting convolution operation via dynamic programming. We test the resulting architecture on standard sentiment classification and news categorization tasks. Our model achieves state-of-the-art performance both in terms of accuracy and training speed. For instance, we obtain 51.4{\%} accuracy on the fine-grained sentiment classification task.},
	Annote = {via alp},
	Archiveprefix = {arXiv},
	Arxivid = {1508.04112},
	Author = {Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1508.04112},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Lei, Barzilay, Jaakkola - 2015 - Molding CNNs for text non-linear, non-consecutive convolutions.pdf:pdf},
	Title = {{Molding CNNs for text: non-linear, non-consecutive convolutions}},
	Url = {http://arxiv.org/abs/1508.04112},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1508.04112}}

@article{May,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1505.02798v1},
	Author = {May, I R},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1505.02798v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/May - Unknown - Multimodal Search Interfaces and.pdf:pdf},
	Keywords = {character recognition,design,handwriting recognition,mathematical information retrieval,mir,user interface},
	Title = {{Multimodal Search Interfaces and}},
	Url = {http://arxiv.org/pdf/1505.02798v1.pdf},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1505.02798v1.pdf}}

@article{Gu2015a,
	Abstract = {Deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm. Stochastic neural networks combine the power of large parametric functions with that of graphical models, which makes it possible to learn very complex distributions. However, as backpropagation is not directly applicable to stochastic networks that include discrete sampling operations within their computational graph, training such networks remains difficult. We present MuProp, an unbiased gradient estimator for stochastic networks, designed to make this task easier. MuProp improves on the likelihood-ratio estimator by reducing its variance using a control variate based on the first-order Taylor expansion of a mean-field network. Crucially, unlike prior attempts at using backpropagation for training stochastic networks, the resulting estimator is unbiased and well behaved. Our experiments on structured output prediction and discrete latent variable modeling demonstrate that MuProp yields consistently good performance across a range of difficult tasks.},
	Archiveprefix = {arXiv},
	Arxivid = {1511.05176},
	Author = {Gu, Shixiang and Levine, Sergey and Sutskever, Ilya and Mnih, Andriy},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1511.05176},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gu et al. - 2015 - MuProp Unbiased Backpropagation for Stochastic Neural Networks.pdf:pdf},
	Number = {2014},
	Pages = {1--11},
	Title = {{MuProp: Unbiased Backpropagation for Stochastic Neural Networks}},
	Url = {http://arxiv.org/abs/1511.05176},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.05176}}

@article{ShixiangGu2015,
	Abstract = {Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterised proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterisations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a neural network-based deep recurrent generative model achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.03338v2},
	Author = {{Shixiang Gu} and {Zoubin Ghahramani} and {Richard E. Turner}},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.03338v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Shixiang Gu, Zoubin Ghahramani, Richard E. Turner - 2015 - Neural Adaptive Sequential Monte Carlo.pdf:pdf},
	Pages = {1--10},
	Title = {{Neural Adaptive Sequential Monte Carlo}},
	Url = {http://arxiv.org/abs/1506.03338v2},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.03338v2}}

@article{Hopfield1982,
	Abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	Author = {Hopfield, J J},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1073/pnas.79.8.2554},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hopfield - 1982 - Neural networks and physical systems with emergent collective computational abilities.pdf:pdf},
	Isbn = {0027-8424},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Number = {8},
	Pages = {2554--2558},
	Pmid = {6953413},
	Title = {{Neural networks and physical systems with emergent collective computational abilities.}},
	Url = {http://www.pnas.org/content/79/8/2554.full.pdf},
	Volume = {79},
	Year = {1982},
	Bdsk-Url-1 = {http://www.pnas.org/content/79/8/2554.full.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1073/pnas.79.8.2554}}

@article{Neelakantan2015a,
	Abstract = {Deep neural networks have achieved impressive supervised classification performance in many tasks including image recognition, speech recognition, and sequence to sequence learning. However, this success has not been translated to applications like question answering that may involve complex arithmetic and logic reasoning. A major limitation of these models is in their inability to learn even simple arithmetic and logic operations. For example, it has been shown that neural networks fail to learn to add two binary numbers reliably. In this work, we propose Neural Programmer, an end-to-end differentiable neural network augmented with a small set of basic arithmetic and logic operations. Neural Programmer can call these augmented operations over several steps, thereby inducing compositional programs that are more complex than the built-in operations. The model learns from a weak supervision signal which is the result of execution of the correct program, hence it does not require expensive annotation of the correct program itself. The decisions of what operations to call, and what data segments to apply to are inferred by Neural Programmer. Such decisions, during training, are done in a differentiable fashion so that the entire network can be trained jointly by gradient descent. We find that training the model is difficult, but it can be greatly improved by adding random noise to the gradient. On a fairly complex synthetic table-comprehension dataset, traditional recurrent networks and attentional models perform poorly while Neural Programmer typically obtains nearly perfect accuracy.},
	Archiveprefix = {arXiv},
	Arxivid = {1511.04834},
	Author = {Neelakantan, Arvind and Le, Quoc V. and Sutskever, Ilya},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1511.04834},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Neelakantan, Le, Sutskever - 2015 - Neural Programmer Inducing Latent Programs with Gradient Descent.pdf:pdf},
	Number = {2005},
	Pages = {1--17},
	Title = {{Neural Programmer: Inducing Latent Programs with Gradient Descent}},
	Url = {http://arxiv.org/abs/1511.04834},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.04834}}

@article{Levy,
	Abstract = {We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word simi-larity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization.},
	Author = {Levy, Omer and Goldberg, Yoav},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Levy, Goldberg - 2014 - Neural Word Embedding as Implicit Matrix Factorization.pdf:pdf},
	Journal = {NIPS},
	Pages = {1--9},
	Title = {{Neural Word Embedding as Implicit Matrix Factorization}},
	Url = {http://u.cs.biu.ac.il/{~}nlp/wp-content/uploads/Neural-Word-Embeddings-as-Implicit-Matrix-Factorization-NIPS-2014.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://u.cs.biu.ac.il/%7B~%7Dnlp/wp-content/uploads/Neural-Word-Embeddings-as-Implicit-Matrix-Factorization-NIPS-2014.pdf}}

@article{Grefenstette2014,
	Author = {Grefenstette, Edward and Moritz, Karl and Dinu, Georgiana and Blunsom, Phil},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Grefenstette et al. - 2014 - New Directions in Vector Space Models of Meaning.pdf:pdf},
	Journal = {ACL2014 Tutorials},
	Title = {{New Directions in Vector Space Models of Meaning}},
	Url = {https://www.cs.ox.ac.uk/files/6605/aclVectorTutorial.pdf},
	Year = {2014},
	Bdsk-Url-1 = {https://www.cs.ox.ac.uk/files/6605/aclVectorTutorial.pdf}}

@article{Song2014,
	Abstract = {Tree structured graphical models are powerful at expressing long range or hierarchical dependency among many variables, and have been widely applied in different areas of computer science and statistics. However, existing methods for parameter estimation, inference, and structure learning mainly rely on the Gaussian or discrete assumptions, which are restrictive under many applications. In this paper, we propose new nonparametric methods based on reproducing kernel Hilbert space embeddings of distributions that can recover the latent tree structures, estimate the parameters, and perform inference for high dimensional continuous and non-Gaussian variables. The usefulness of the proposed methods are illustrated by thorough numerical results.},
	Archiveprefix = {arXiv},
	Arxivid = {1401.3940},
	Author = {Song, Le and Liu, Han and Parikh, Ankur and Xing, Eric},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1401.3940},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Song et al. - 2014 - Nonparametric Latent Tree Graphical Models Inference, Estimation, and Structure Learning.pdf:pdf},
	Journal = {arXiv preprint arXiv:1401.3940},
	Keywords = {embedding of distribu-,latent tree graphical models,latent variable models,parameter estimation,reproducing kernel hilbert space,structure learning,tions},
	Pages = {1--29},
	Title = {{Nonparametric Latent Tree Graphical Models: Inference, Estimation, and Structure Learning}},
	Url = {http://arxiv.org/abs/1401.3940},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1401.3940}}

@article{Query2014,
	Author = {Kohlhase, Michael},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kohlhase - 2014 - NTCIR-11 Math-2 Task Overview.pdf:pdf},
	Journal = {Research.Nii.Ac.Jp},
	Keywords = {content,information access to mathematical,mathml},
	Pages = {88--98},
	Title = {{NTCIR-11 Math-2 Task Overview}},
	Url = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/OVERVIEW/01-NTCIR11-OV-MATH-AizawaA{\_}poster.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings11/pdf/NTCIR/OVERVIEW/01-NTCIR11-OV-MATH-AizawaA%7B%5C_%7Dposter.pdf}}

@book{Nocedal1999,
	Author = {Nocedal, Jorge and Stephen, J. Wright},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1007/978-0-387-40065-5},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Nocedal, Stephen - 1999 - Numerical Optimization.pdf:pdf},
	Isbn = {9780387303031},
	Issn = {0011-4235},
	Pmid = {21384397},
	Title = {{Numerical Optimization}},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-0-387-40065-5}}

@article{Chelba2013,
	Abstract = {We propose a new benchmark corpus to be used for measuring progress in statistical language modeling. With almost one billion words of training data, we hope this benchmark will be useful to quickly evaluate novel language modeling techniques, and to compare their contribution when combined with other advanced techniques. We show performance of several well-known types of language models, with the best results achieved with a recurrent neural network based language model. The baseline unpruned Kneser-Ney 5-gram model achieves perplexity 67.6; a combination of techniques leads to 35{\%} reduction in perplexity, or 10{\%} reduction in cross-entropy (bits), over that baseline. The benchmark is available as a code.google.com project; besides the scripts needed to rebuild the training/held-out data, it also makes available log-probability values for each word in each of ten held-out data sets, for each of the baseline n-gram models.},
	Archiveprefix = {arXiv},
	Arxivid = {1312.3005},
	Author = {Chelba, Ciprian and Mikolov, Tomas and Schuster, Mike and Ge, Qi and Brants, Thorsten and Koehn, Phillipp and Robinson, Tony},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1312.3005},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Chelba et al. - 2013 - One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling.pdf:pdf},
	Issn = {19909772},
	Journal = {arXiv preprint 1312.3005},
	Keywords = {[Electronic Manuscript]},
	Number = {September},
	Pages = {2635--2639},
	Title = {{One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling}},
	Url = {http://arxiv.org/abs/1312.3005},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.3005}}

@article{Rezende2016,
	Archiveprefix = {arXiv},
	Arxivid = {1603.05106},
	Author = {Rezende, Danilo J and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1603.05106},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Rezende et al. - 2016 - One-Shot Generalization in Deep Generative Models.pdf:pdf},
	Title = {{One-Shot Generalization in Deep Generative Models}},
	Url = {http://arxiv.org/pdf/1603.05106v1.pdf},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1603.05106v1.pdf}}

@article{Hoffman,
	Author = {Hoffman, Matthew D and Blei, David M and Bach, Francis},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hoffman, Blei, Bach - 2010 - Online Learning for Latent Dirichlet Allocation.pdf:pdf},
	Journal = {Advances in Neural Information Processing Systems},
	Pages = {1--9},
	Title = {{Online Learning for Latent Dirichlet Allocation}},
	Url = {https://www.cs.princeton.edu/{~}blei/papers/HoffmanBleiBach2010b.pdf},
	Volume = {23},
	Year = {2010},
	Bdsk-Url-1 = {https://www.cs.princeton.edu/%7B~%7Dblei/papers/HoffmanBleiBach2010b.pdf}}

@article{Ranganath2016,
	Author = {Ranganath, Rajesh},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ranganath - 2016 - Operator Variational Inference.pdf:pdf},
	Journal = {Unpublished},
	Pages = {1--6},
	Title = {{Operator Variational Inference}},
	Year = {2016}}

@article{RichardSocherandJohnBauerandChristopherD.ManningandAndrewY.Ng2013,
	Abstract = {Natural language parsing has typically been done with small sets of discrete categories such as {\{}NP{\}} and {\{}VP{\}}, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases or splitting categories only partly address the problem at the cost of huge feature spaces and sparseness. Instead, we introduce a Compositional Vector Grammar ({\{}CVG){\}}, which combines {\{}PCFGs{\}} with a syntactically untied recursive neural network that learns syntactico-semantic, compositional vector representations. The {\{}CVG{\}} improves the {\{}PCFG{\}} of the Stanford Parser by 3.8 {\%} to obtain an F1 score of 90.4{\%}. It is fast to train and implemented approximately as an efficient reranker it is about 20 {\%} faster than the current Stanford factored parser. The {\{}CVG{\}} learns a soft notion of head words and improves performance on the types of ambiguities that require semantic information such as {\{}PP{\}} attachments. 1},
	Author = {{Richard Socher and John Bauer and Christopher D. Manning and Andrew Y. Ng} and Socher, Richard and Bauer, John and Manning, Christopher D and Ng, Andrew Y},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Richard Socher and John Bauer and Christopher D. Manning and Andrew Y. Ng et al. - 2013 - Parsing With Compositional Vector Grammars.pdf:pdf},
	Journal = {In Proceedings of the {\{}ACL{\}} conference},
	Pages = {455--465},
	Title = {{Parsing With Compositional Vector Grammars}},
	Url = {http://www.socher.org/uploads/Main/SocherBauerManningNg{\_}ACL2013.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://www.socher.org/uploads/Main/SocherBauerManningNg%7B%5C_%7DACL2013.pdf}}

@article{Transtrum2015a,
	Abstract = {Large scale models of physical phenomena demand the development of new statistical and computational tools in order to be effective. Many such models are `sloppy', i.e., exhibit behavior controlled by a relatively small number of parameter combinations. We review an information theoretic framework for analyzing sloppy models. This formalism is based on the Fisher Information Matrix, which we interpret as a Riemannian metric on a parameterized space of models. Distance in this space is a measure of how distinguishable two models are based on their predictions. Sloppy model manifolds are bounded with a hierarchy of widths and extrinsic curvatures. We show how the manifold boundary approximation can extract the simple, hidden theory from complicated sloppy models. We attribute the success of simple effective models in physics as likewise emerging from complicated processes exhibiting a low effective dimensionality. We discuss the ramifications and consequences of sloppy models for biochemistry and science more generally. We suggest that the reason our complex world is understandable is due to the same fundamental reason: simple theories of macroscopic behavior are hidden inside complicated microscopic processes.},
	Archiveprefix = {arXiv},
	Arxivid = {1501.07668},
	Author = {Transtrum, Mark K. and Machta, Benjamin B. and Brown, Kevin S. and Daniels, Bryan C. and Myers, Christopher R. and Sethna, James P.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1063/1.4923066},
	Eprint = {1501.07668},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Transtrum et al. - 2015 - Perspective Sloppiness and emergent theories in physics, biology, and beyond.pdf:pdf},
	Issn = {00219606},
	Journal = {Journal of Chemical Physics},
	Number = {1},
	Pages = {1--15},
	Pmid = {26156455},
	Title = {{Perspective: Sloppiness and emergent theories in physics, biology, and beyond}},
	Url = {http://arxiv.org/pdf/1501.07668.pdf},
	Volume = {143},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1501.07668.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1063/1.4923066}}

@article{Bialek2015b,
	Abstract = {Theoretical physics is the search for simple and universal mathematical descriptions of the natural world. In contrast, much of modern biology is an exploration of the complexity and diversity of life. For many, this contrast is prima facie evidence that theory, in the sense that physicists use the word, is impossible in a biological context. For others, this contrast serves to highlight a grand challenge. I'm an optimist, and believe (along with many colleagues) that the time is ripe for the emergence of a more unified theoretical physics of biological systems, building on successes in thinking about particular phenomena. In this essay I try to explain the reasons for my optimism, through a combination of historical and modern examples.},
	Archiveprefix = {arXiv},
	Arxivid = {1512.08954},
	Author = {Bialek, William},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1512.08954},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bialek - 2015 - Perspectives At the Interface of Physics and Biology.pdf:pdf},
	Journal = {Arxiv},
	Pages = {1--21},
	Title = {{Perspectives At the Interface of Physics and Biology}},
	Url = {http://arxiv.org/pdf/1512.08954.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1512.08954.pdf}}

@article{Gelman2010,
	Abstract = {A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico-deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science. Clarity about these matters should benefit not just philosophy of science, but also statistical practice. At best, the inductivist view has encouraged researchers to fit and compare models without checking them; at worst, theorists have actively discouraged practitioners from performing model checking because it does not fit into their framework.},
	Archiveprefix = {arXiv},
	Arxivid = {1006.3868},
	Author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1111/j.2044-8317.2011.02037.x},
	Eprint = {1006.3868},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gelman, Shalizi - 2010 - Philosophy and the practice of Bayesian statistics.pdf:pdf},
	Isbn = {2044-8317 (Electronic) 0007-1102 (Linking)},
	Issn = {2044-8317},
	Journal = {Submitted for publication},
	Keywords = {Data Analysis,Statistics,Statistics and Probability,Theory},
	Number = {1996},
	Pages = {36},
	Pmid = {22364575},
	Title = {{Philosophy and the practice of Bayesian statistics}},
	Url = {http://arxiv.org/abs/1006.3868},
	Year = {2010},
	Bdsk-Url-1 = {http://arxiv.org/abs/1006.3868},
	Bdsk-Url-2 = {http://dx.doi.org/10.1111/j.2044-8317.2011.02037.x}}

@article{Wilczek2015,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1503.07735v1},
	Author = {Wilczek, Frank},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1503.07735v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Wilczek - 2015 - Physics in 100 Years.pdf:pdf},
	Title = {{Physics in 100 Years}},
	Url = {http://arxiv.org/pdf/1503.07735v1.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1503.07735v1.pdf}}

@misc{Kingman1995,
	Abstract = {Two fundamental theories are commonly debated in the study of random processes: the Bachelier Wiener model of Brownian motion, which has been the subject of many books, and the Poisson process. While nearly every book mentions the Poisson process, most hurry past to more general point processes or to Markov chains. This comparative neglect is ill judged, and stems from a lack of perception of the real importance of the Poisson process. This distortion partly comes about from a restriction to one dimension, while the theory becomes more natural in more general contexts. This book attempts to redress the balance. It records the author's fascination with the beauty and wide applicability of Poisson processes in one or more dimensions. The mathematical theory is powerful and a few key results often produce surprising consequences.},
	Author = {Kingman, J F C},
	Booktitle = {Technometrics},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.2307/1269173},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kingman - 1995 - Poisson Processes.pdf:pdf},
	Isbn = {0198536933},
	Issn = {00014966},
	Pages = {124},
	Pmid = {17471763},
	Title = {{Poisson Processes}},
	Url = {http://books.google.com/books?hl=en{\&}lr={\&}id=VEiM-OtwDHkC{\&}oi=fnd{\&}pg=PA1{\&}dq=Poisson+Processes{\&}ots=zVEzIUKD5H{\&}sig=btAn5sWyYrRBT41gLZGcnSDwWBM$\backslash$nhttp://books.google.com/books?hl=en{\&}lr={\&}id=VEiM-OtwDHkC{\&}oi=fnd{\&}pg=PA1{\&}dq=Poisson+processes{\&}ots=zVGxJSFB3K{\&}sig=3dmq7s},
	Volume = {37},
	Year = {1995},
	Bdsk-Url-1 = {http://books.google.com/books?hl=en%7B%5C&%7Dlr=%7B%5C&%7Did=VEiM-OtwDHkC%7B%5C&%7Doi=fnd%7B%5C&%7Dpg=PA1%7B%5C&%7Ddq=Poisson+Processes%7B%5C&%7Dots=zVEzIUKD5H%7B%5C&%7Dsig=btAn5sWyYrRBT41gLZGcnSDwWBM$%5Cbackslash$nhttp://books.google.com/books?hl=en%7B%5C&%7Dlr=%7B%5C&%7Did=VEiM-OtwDHkC%7B%5C&%7Doi=fnd%7B%5C&%7Dpg=PA1%7B%5C&%7Ddq=Poisson+processes%7B%5C&%7Dots=zVGxJSFB3K%7B%5C&%7Dsig=3dmq7s},
	Bdsk-Url-2 = {http://dx.doi.org/10.2307/1269173}}

@article{Gelman1996,
	Abstract = {This paper considers Bayesian counterparts of the classical tests for goodness of fit and their use in judging the fit of a single Bayesian model to the observed data. We focus on posterior predictive assessment, in a framework that also includes conditioning on auxiliary statistics. The Bayesian formulation facilitates the construction and calculation of a meaningful reference distribution not only for any (classical) statistic, but also for any parameter-dependent ``statistic" or discrepancy. The latter allows us to propose the realized discrepancy assessment of model fitness, which directly measures the true discrepancy between data and the posited model, for any aspect of the model which we want to explore. The computation required for the realized discrepancy assessment is a straightforward byproduct of the posterior simulation used for the original Bayesian analysis. $\backslash$n$\backslash$nWe illustrate with three applied examples. The first example, which serves mainly to motivate the work, illustrates the difficulty of classical tests in assessing the fitness of a Poisson model to a positron emission tomography image that is constrained to be nonnegative. The second and third examples illustrate the details of the posterior predictive approach in two problems: estimation in a model with inequality constraints on the parameters, and estimation in a mixture model. In all three examples, standard test statistics (either a X 2 or a likelihood ratio) are not pivotal: the difficulty is not just how to compute the reference distribution for the test, but that in the classical framework no such distribution exists, independent of the unknown model parameters.},
	Author = {Gelman, a and Gelman, a and Meng, X.-L and Meng, X.-L and Stern, H and Stern, H},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1.1.142.9951},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gelman et al. - 1996 - Posterior predictive assessment of model fitness via realized discrepancies. Vol.6, No.4.pdf:pdf},
	Isbn = {1017-0405},
	Issn = {10170405},
	Journal = {Statistica Sinica},
	Keywords = {and phrases,bayesian p -value,discrepancy,graphical assess-,ment,mixture model,model criticism,p -value,posterior predictive p -value,prior predictive,realized discrepancy,$\chi$ 2 test},
	Number = {4},
	Pages = {733--807},
	Title = {{Posterior predictive assessment of model fitness via realized discrepancies. Vol.6, No.4.}},
	Url = {http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n41/j6n41.htm},
	Volume = {6},
	Year = {1996},
	Bdsk-Url-1 = {http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n41/j6n41.htm},
	Bdsk-Url-2 = {http://dx.doi.org/10.1.1.142.9951}}

@article{Ruelle2014,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1308.4678v1},
	Author = {Ruelle, David},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1308.4678v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ruelle - 2014 - Post-Human Mathematics.pdf:pdf},
	Journal = {ArXiv Mathematics},
	Pages = {1--8},
	Title = {{Post-Human Mathematics.}},
	Url = {http://arxiv.org/pdf/1308.4678v1.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1308.4678v1.pdf}}

@article{Liang2009,
	Author = {Liang, Percy and Jordan, Mi and Klein, Dan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Liang, Jordan, Klein - 2009 - Probabilistic grammars and hierarchical Dirichlet processes.pdf:pdf},
	Isbn = {9780199548903},
	Journal = {The handbook of applied Bayesian analysis},
	Keywords = {natural language processing,nonparametric bayesian statistics,variational inference},
	Title = {{Probabilistic grammars and hierarchical Dirichlet processes}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.4804{\&}rep=rep1{\&}type=pdf},
	Year = {2009},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.4804%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf}}

@article{Kamali2013a,
	Author = {Kamali, Shahab},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kamali - 2013 - Querying Large Collections of Semistructured Data.pdf:pdf},
	Title = {{Querying Large Collections of Semistructured Data}},
	Url = {https://uwspace.uwaterloo.ca/bitstream/handle/10012/7979/Kamali{\_}Shahab.pdf?sequence=1},
	Year = {2013},
	Bdsk-Url-1 = {https://uwspace.uwaterloo.ca/bitstream/handle/10012/7979/Kamali%7B%5C_%7DShahab.pdf?sequence=1}}

@article{Arora2015,
	Abstract = {Semantic word embeddings use vector representations to represent the meaning of a word. Methods to create them include Vector Space Methods (VSMs) such as Latent Semantic Analysis (LSA), matrix factorization, generative text models such as Topic Models, and neural nets. A flurry of work has resulted from the papers of Mikolov et al.{\~{}}$\backslash$cite{\{}mikolov2013efficient{\}}. These showed how to solve word analogy tasks very well by leveraging linear structure in word embeddings even though the embeddings were created using highly nonlinear energy based models. No clear explanation is known why such linear structure emerges in low-dimensional embeddings. This paper presents a loglinear generative model---related to{\~{}}$\backslash$citet{\{}mnih2007three{\}}---that models the generation of a text corpus as a random walk in a latent discourse space. A novel methodological twist is that the model is solved in closed form by integrating out the random walk. This yields a simple method for constructing word embeddings. Experiments are presented to support the modeling assumptions as well as the efficacy of the word embeddings for solving analogies. This simple model links and provides theoretical support for several prior methods for finding embeddings, as well as provides interpretations for various linear algebraic structures in word embeddings obtained from nonlinear techniques.},
	Archiveprefix = {arXiv},
	Arxivid = {1502.03520},
	Author = {Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1502.03520},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Arora et al. - 2015 - Random walks on discourse spaces a new generative language model with applications to semantic word embeddings.pdf:pdf},
	Pages = {1--23},
	Title = {{Random walks on discourse spaces: a new generative language model with applications to semantic word embeddings}},
	Url = {http://arxiv.org/abs/1502.03520},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1502.03520}}

@article{Stark2016,
	Abstract = {Physicists use quantum models to describe the behavior of physical systems. Quantum models owe their success to their interpretability, to their relation to probabilistic models (quantization of classical models) and to their high predictive power. Beyond physics, these properties are valuable in general data science. This motivates the use of quantum models to analyze general nonphysical datasets. Here we provide both empirical and theoretical insights into the application of quantum models in data science. In the theoretical part of this paper, we firstly show that quantum models can be exponentially more efficient than probabilistic models because there exist datasets that admit low-dimensional quantum models and only exponentially high-dimensional probabilistic models. Secondly, we explain in what sense quantum models realize a useful relaxation of compressed probabilistic models. Thirdly, we show that sparse datasets admit low-dimensional quantum models and finally, we introduce a method to compute hierarchical orderings of properties of users (e.g., personality traits) and items (e.g., genres of movies). In the empirical part of the paper, we evaluate quantum models in item recommendation and observe that the predictive power of quantum-inspired recommender systems can compete with state-of-the-art recommender systems like SVD++ and PureSVD. Furthermore, we make use of the interpretability of quantum models by computing hierarchical orderings of properties of users and items. This work establishes a connection between data science (item recommendation), information theory (communication complexity), mathematical programming (positive semidefinite factorizations) and physics (quantum models).},
	Archiveprefix = {arXiv},
	Arxivid = {1601.06035},
	Author = {Stark, Cyril},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1601.06035},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Stark - 2016 - Recommender systems inspired by the structure of quantum theory.pdf:pdf},
	Pages = {1--26},
	Title = {{Recommender systems inspired by the structure of quantum theory}},
	Url = {http://arxiv.org/abs/1601.06035},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1601.06035}}

@article{Socher2013,
	Abstract = {Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80{\%} up to 85.4{\%}. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7{\%}, an improvement of 9.7{\%} over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.},
	Author = {Socher, Richard and Perelygin, Alex and Wu, Jy},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Socher, Perelygin, Wu - 2013 - Recursive deep models for semantic compositionality over a sentiment treebank.pdf:pdf},
	Isbn = {9781937284978},
	Journal = {Proceedings of the {\ldots}},
	Pages = {1631--1642},
	Title = {{Recursive deep models for semantic compositionality over a sentiment treebank}},
	Url = {http://nlp.stanford.edu/{~}socherr/EMNLP2013{\_}RNTN.pdf$\backslash$nhttp://www.aclweb.org/anthology/D13-1170$\backslash$nhttp://aclweb.org/supplementals/D/D13/D13-1170.Attachment.pdf$\backslash$nhttp://oldsite.aclweb.org/anthology-new/D/D13/D13-1170.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://nlp.stanford.edu/%7B~%7Dsocherr/EMNLP2013%7B%5C_%7DRNTN.pdf$%5Cbackslash$nhttp://www.aclweb.org/anthology/D13-1170$%5Cbackslash$nhttp://aclweb.org/supplementals/D/D13/D13-1170.Attachment.pdf$%5Cbackslash$nhttp://oldsite.aclweb.org/anthology-new/D/D13/D13-1170.pdf}}

@article{Bowman2014,
	Abstract = {Tree-structured recursive neural networks (TreeRNNs) for sentence meaning have been successful for many applications, but it remains an open question whether the fixed-length representations that they learn can support tasks as demanding as logical deduction. We pursue this question by evaluating whether two such models---plain TreeRNNs and tree-structured neural tensor networks (TreeRNTNs)---can correctly learn to identify logical relationships such as entailment and contradiction using these representations. In our first set of experiments, we generate artificial data from a logical grammar and use it to evaluate the models' ability to learn to handle basic relational reasoning, recursive structures, and quantification. We then evaluate the models on the more natural SICK challenge data. Both models perform competitively on the SICK data and generalize well in all three experiments on simulated data, suggesting that they can learn suitable representations for logical inference in natural language.},
	Archiveprefix = {arXiv},
	Arxivid = {1406.1827},
	Author = {Bowman, Samuel R. and Potts, Christopher and Manning, Christopher D.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1406.1827},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bowman, Potts, Manning - 2014 - Recursive Neural Networks Can Learn Logical Semantics.pdf:pdf},
	Title = {{Recursive Neural Networks Can Learn Logical Semantics}},
	Url = {http://arxiv.org/abs/1406.1827},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1406.1827}}

@article{Henelius2015,
	Abstract = {Spin ices, frustrated magnetic materials analogous to common water ice, are exemplars of high frustration in three dimensions. Recent experimental studies of the low-temperature properties of the paradigmatic Dy{\$}{\_}2{\$}Ti{\$}{\_}2{\$}O{\$}{\_}7{\$} spin ice material, in particular whether the predicted transition to long-range order occurs, raise questions as per the currently accepted microscopic model of this system. In this work, we combine Monte Carlo simulations and mean-field theory calculations to analyze data from magnetization, elastic neutron scattering and specific heat measurements on Dy{\$}{\_}2{\$}Ti{\$}{\_}2{\$}O{\$}{\_}7{\$}. We also reconsider the possible importance of the nuclear specific heat, {\$}C{\_}{\{}\backslashrm nuc{\}}{\$}, in Dy{\$}{\_}2{\$}Ti{\$}{\_}2{\$}O{\$}{\_}7{\$}. We find that {\$}C{\_}{\{}\backslashrm nuc{\}}{\$} is not entirely negligible below a temperature {\$}\backslashsim 0.5{\$} K and must be taken into account in a quantitative analysis of the calorimetric data of this compound below that temperature. We find that small effective exchange interactions compete with the magnetostatic dipolar interaction responsible for the main spin ice phenomenology. This causes an unexpected "refrustration" of the long-range order that would be expected from the incompletely self-screened dipolar interaction and which positions the material at the boundary between two competing classical long-range ordered ground states. This allows for the manifestation of new physical low-temperature phenomena in Dy{\$}{\_}2{\$}Ti{\$}{\_}2{\$}O{\$}{\_}7{\$}, as exposed by recent specific heat measurements. We show that among the four most likely causes for the observed upturn of the specific heat at low temperature -- an exchange-induced transition to long-range order, quantum non-Ising (transverse) terms in the effective spin Hamiltonian, the nuclear hyperfine contribution and random disorder -- only the last appears to be reasonably able to explain the calorimetric data.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1512.05361},
	Author = {Henelius, P. and Lin, T. and Enjalran, M. and Hao, Z. and Rau, J. G. and Altosaar, J. and Flicker, F. and Yavors'kii, T. and Gingras, M. J. P.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1103/PhysRevB.93.024402},
	Eprint = {arXiv:1512.05361},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Henelius et al. - 2015 - Refrustration and competing orders in the prototypical Dy2Ti2O7 spin ice material.pdf:pdf},
	Issn = {2469-9950},
	Journal = {Physical Review B},
	Pages = {1--24},
	Title = {{Refrustration and competing orders in the prototypical Dy2Ti2O7 spin ice material}},
	Url = {http://arxiv.org/abs/1512.05361},
	Volume = {7},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.05361},
	Bdsk-Url-2 = {http://dx.doi.org/10.1103/PhysRevB.93.024402}}

@article{Krueger2015,
	Abstract = {We stabilize the activations of Recurrent Neural Networks (RNNs) by penalizing the squared distance between successive hidden states' norms. This penalty term is an effective regularizer for RNNs including LSTMs and IRNNs, improving performance on character-level language modelling and phoneme recognition, and outperforming weight noise. With this penalty term, IRNN can achieve similar performance to LSTM on language modelling, although adding the penalty term to the LSTM results in superior performance. Our penalty term also prevents the exponential growth of IRNN's activations outside of their training horizon, allowing them to generalize to much longer sequences.},
	Archiveprefix = {arXiv},
	Arxivid = {1511.08400},
	Author = {Krueger, David and Memisevic, Roland},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1511.08400},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Krueger, Memisevic - 2015 - Regularizing RNNs by Stabilizing Activations.pdf:pdf},
	Pages = {1--8},
	Title = {{Regularizing RNNs by Stabilizing Activations}},
	Url = {http://arxiv.org/abs/1511.08400},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.08400}}

@article{Bengio2012,
	Abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and joint training of deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep architectures. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	Archiveprefix = {arXiv},
	Arxivid = {1206.5538},
	Author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1109/TPAMI.2013.50},
	Eprint = {1206.5538},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bengio, Courville, Vincent - 2012 - Representation Learning A Review and New Perspectives.pdf:pdf},
	Isbn = {0162-8828 VO - 35},
	Issn = {1939-3539},
	Journal = {arXiv},
	Number = {1993},
	Pages = {1--34},
	Pmid = {23787338},
	Title = {{Representation Learning: A Review and New Perspectives}},
	Url = {http://arxiv.org/abs/1206.5538},
	Volume = {35},
	Year = {2012},
	Bdsk-Url-1 = {http://arxiv.org/abs/1206.5538},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/TPAMI.2013.50}}

@misc{Jaynes1963,
	Abstract = {This paper has two purposes: 1) to clarify the relationship between the quantum theory of radiation, where the electromagnetic field-expansion coefficients satisfy commutation relations, and the semiclassical theory, where the electromagnetic field is considered as a definite function of time rather than as an operator; and 2) to apply some of the results in a study of amplitude and frequency stability in a molecular beam maser. In 1), it is shown that the semiclassical theory, when extended te take into account both the effect of the field on the molecules and the effect of the molecules on the field, reproduces almost quantitatively the same laws of energy exchange and coherence properties as the quantized field theory, even in the limit of one or a few quanta in the field mode. In particular, the semiclassical theory is shown to lead to a prediction of spontaneous emission, with the same decay rate as given by quantum electrodynamics, described by the Einstein A coefficients. In 2), the semiclassical theory is applied to the molecular beam maser. Equilibrium amplitude and frequency of oscillation are obtained for an arbitrary velocity distribution of focused molecules, generalizing the results obtained previously by Gordon, Zeiger, and Townes for a singel-velocity beam, and by Lamb and Helmer for a Maxwellian beam. A somewhat surprising result is obtained; which is that the measurable properties of the maser, such as starting current, effective molecular Q, etc., depend mostly on the slowest 5 to 10 per cent of the molecules. Next we calculate the effect of amplitude and frequency of oscillation, of small systematic perturbations. We obtain a prediction that stability can be improved by adjusting the system so that the molecules emit all their energy h $\Omega$ to the field, then reabsorb part of it, before leaving the cavity. In general, the most stable operation is obtained when the molecules are in the process of absorbing energy from the radiation as they leave the cavity, most unstable when they are still emitting energy at that time. Finally, we consider the response of an oscillating maser to randomly time-varying perturbations. Graphs are given showing predicted response to a small superimposed signal of a frequency near the - oscillation frequency. The existence of "noise enhancing" and "noise quieting" modes of operation found here is a general property of any oscillating system in which amplitude is limited by nonlinearity.},
	Author = {{Bengio, Yoshua}, Aaron Courville},
	Booktitle = {Proceedings of the IEEE},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bengio, Yoshua - 1963 - Representation learning, a review and new perspectives.html:html},
	Keywords = {jaynes cummings},
	Number = {1},
	Pages = {89 -- 109},
	Title = {{Representation learning, a review and new perspectives}},
	Url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1443594},
	Volume = {51},
	Year = {1963},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1443594}}

@article{Kamali2013,
	Abstract = {Many documents with mathematical content are published on the Web, but conventional search engines that rely on keyword search only cannot fully exploit their mathematical information. In particular, keyword search is insufficient when expressions in a document are not annotated with natural keywords or the user cannot describe her query with keywords. Retrieving documents by querying their mathematical content directly is very appealing in various domains such as education, digital libraries, engineering, patent documents, medical sciences, etc. Capturing the relevance of mathematical expressions also greatly enhances document classification in such domains. Unlike text retrieval, where keywords carry enough semantics to distinguish text documents and rank them, math symbols do not contain much semantic information on their own. In fact, mathematical expressions typically consist of few alphabetical symbols organized in rather complex structures. Hence, the structure of an expression, which describes the way such symbols are combined, should also be considered. Unfortunately, there is no standard testbed with which to evaluate the effectiveness of a mathematics retrieval algorithm. In this paper we study the fundamental and challenging problems in mathematics retrieval, that is how to capture the relevance of mathematical expressions, how to query them, and how to evaluate the results. We describe various search paradigms and propose retrieval systems accordingly. We discuss the benefits and drawbacks of each approach, and further compare them through an extensive empirical study.},
	Author = {Kamali, Shahab and Tompa, Frank Wm.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/2484028.2484083},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kamali, Tompa - 2013 - Retrieving documents with mathematical content.pdf:pdf},
	Isbn = {9781450320344},
	Journal = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '13},
	Keywords = {documents with math content,math queries,mathematics retrieval,search},
	Pages = {353},
	Title = {{Retrieving documents with mathematical content}},
	Url = {http://dl.acm.org/citation.cfm?id=2484028.2484083},
	Year = {2013},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2484028.2484083},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2484028.2484083}}

@article{Racah2016,
	Abstract = {Experiments in particle physics produce enormous quantities of data that must be analyzed and interpreted by teams of physicists. This analysis is often exploratory, where scientists are unable to enumerate the possible types of signal prior to performing the experiment. Thus, tools for summarizing, clustering, visualizing and classifying high-dimensional data are essential. In this work, we show that meaningful physical content can be revealed by transforming the raw data into a learned high-level representation using deep neural networks, with measurements taken at the Daya Bay Neutrino Experiment as a case study. We further show how convolutional deep neural networks can provide an effective classification filter with greater than 97{\%} accuracy across different classes of physics events, significantly better than other machine learning approaches.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1601.07621},
	Author = {Racah, Evan and Ko, Seyoon and Sadowski, Peter and Bhimji, Wahid and Tull, Craig and Oh, Sang-Yun and Baldi, Pierre and Prabhat},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1601.07621},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Racah et al. - 2016 - Revealing Fundamental Physics from the Daya Bay Neutrino Experiment using Deep Neural Networks.pdf:pdf},
	Pages = {1--8},
	Title = {{Revealing Fundamental Physics from the Daya Bay Neutrino Experiment using Deep Neural Networks}},
	Url = {http://arxiv.org/abs/1601.07621},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1601.07621}}

@article{Bornschein2015,
	Archiveprefix = {arXiv},
	Arxivid = {1406.2751v4},
	Author = {Bornschein, Jorg and Bengio, Yoshua},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1406.2751v4},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bornschein, Bengio - 2015 - Reweighted Wake-Sleep.pdf:pdf},
	Title = {{Reweighted Wake-Sleep}},
	Url = {http://arxiv.org/pdf/1406.2751v4.pdf},
	Volume = {1},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1406.2751v4.pdf}}

@article{VanBalen2013,
	Author = {{Van Balen}, J and Serr{\`{a}}, J and Haro, M},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/Downloads/chp{\%}3A10.1007{\%}2F978-3-642-41248-6{\_}16.pdf:pdf},
	Journal = {Music and Emotions},
	Keywords = {content-based music retrieval,digital sampling,musical influence,sample recognition},
	Pages = {301--312},
	Title = {{Sample identification in hip-hop music}},
	Year = {2013}}

@article{Shanahan2012,
	Author = {Shanahan, Murray},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Shanahan - 2012 - Satori Before Singularity.pdf:pdf},
	Number = {7},
	Pages = {87--102},
	Title = {{Satori Before Singularity}},
	Url = {http://www.doc.ic.ac.uk/{~}mpsha/ShanahanJCS2012.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://www.doc.ic.ac.uk/%7B~%7Dmpsha/ShanahanJCS2012.pdf}}

@article{Gopalan2013,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1311.1704},
	Author = {Gopalan, PK and Hofman, JM and Blei, DM},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1311.1704},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Gopalan, Hofman, Blei - 2013 - Scalable Recommendation with Poisson Factorization.pdf:pdf},
	Month = {nov},
	Title = {{Scalable Recommendation with Poisson Factorization}},
	Url = {http://arxiv.org/abs/1311.1704v3},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1311.1704v3}}

@incollection{Bengio+chapter2007,
	Author = {Bengio, Yoshua and LeCun, Yann},
	Booktitle = {Large Scale Kernel Machines},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Publisher = {MIT Press},
	Title = {{Scaling Learning Algorithms Towards {\{}AI{\}}}},
	Year = {2007}}

@article{Pedregosa2011,
	Abstract = {Abstract Scikit - learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high- ... $\backslash$n},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1201.0490v2},
	Author = {Pedregosa, Fabian and Varoquaux, G},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1201.0490v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Pedregosa, Varoquaux - 2011 - Scikit-learn Machine learning in Python.pdf:pdf},
	Isbn = {9781783281930},
	Journal = {Journal of Machine Learning Research},
	Pages = {2825--2830},
	Pmid = {1000044560},
	Title = {{Scikit-learn: Machine learning in Python}},
	Url = {http://dl.acm.org/citation.cfm?id=2078195},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2078195}}

@article{Baldi2014,
	Abstract = {Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine-learning approaches are often used. Standard approaches have relied on 'shallow' machine-learning models that have a limited capacity to learn complex nonlinear functions of the inputs, and rely on a painstaking search through manually constructed nonlinear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Here, using benchmark data sets, we show that deep-learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8{\%} over the best current approaches. This demonstrates that deep-learning approaches can improve the power of collider searches for exotic particles.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1402.4735},
	Author = {Baldi, P and Sadowski, P and Whiteson, D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1038/ncomms5308},
	Eprint = {arXiv:1402.4735},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Baldi, Sadowski, Whiteson - 2014 - Searching for exotic particles in high-energy physics with deep learning.pdf:pdf},
	Issn = {2041-1723},
	Journal = {Nature Communications},
	Pages = {4308},
	Pmid = {24986233},
	Publisher = {Nature Publishing Group},
	Title = {{Searching for exotic particles in high-energy physics with deep learning.}},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/24986233},
	Volume = {5},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/24986233},
	Bdsk-Url-2 = {http://dx.doi.org/10.1038/ncomms5308}}

@article{Socher2011,
	Author = {Socher, Richard and Pennington, Jeffrey and Huang, Eh},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Socher, Pennington, Huang - 2011 - Semi-supervised recursive autoencoders for predicting sentiment distributions.pdf:pdf},
	Journal = {Conference on Empirical Methods in Natural Language Processing, EMNLP},
	Number = {i},
	Pages = {151--161},
	Title = {{Semi-supervised recursive autoencoders for predicting sentiment distributions}},
	Url = {http://dl.acm.org/citation.cfm?id=2145450},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2145450}}

@article{Vinyals2014a,
	Author = {Vinyals, Ilya Sutskever Oriol and Le, Quoc V.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Vinyals, Le - 2014 - Sequence to Sequence Learning with Neural Networks.pdf:pdf},
	Journal = {NIPS},
	Pages = {1--9},
	Title = {{Sequence to Sequence Learning with Neural Networks}},
	Url = {http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf}}

@article{Vinyals2014,
	Abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU score improvements on Flickr30k, from 55 to 66, and on SBU, from 19 to 27.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1411.4555v1},
	Author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1109/CVPR.2015.7298935},
	Eprint = {arXiv:1411.4555v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Vinyals et al. - 2014 - Show and Tell A Neural Image Caption Generator.pdf:pdf},
	Isbn = {9781467369640},
	Title = {{Show and Tell: A Neural Image Caption Generator}},
	Url = {http://arxiv.org/pdf/1411.4555.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1411.4555.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/CVPR.2015.7298935}}

@article{Williams1992,
	Abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	Author = {Williams, Ronald J.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1007/BF00992696},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Williams - 1992 - Simple statistical gradient-following algorithms for connectionist reinforcement learning.pdf:pdf},
	Isbn = {0885-6125},
	Issn = {08856125},
	Journal = {Machine Learning},
	Keywords = {Reinforcement learning,connectionist networks,gradient descent,mathematical analysis},
	Number = {3-4},
	Pages = {229--256},
	Pmid = {903},
	Title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
	Url = {http://www-anw.cs.umass.edu/{~}barto/courses/cs687/williams92simple.pdf},
	Volume = {8},
	Year = {1992},
	Bdsk-Url-1 = {http://www-anw.cs.umass.edu/%7B~%7Dbarto/courses/cs687/williams92simple.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/BF00992696}}

@article{Kiros2015a,
	Abstract = {We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.},
	Archiveprefix = {arXiv},
	Arxivid = {1506.06726},
	Author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan and Zemel, Richard S. and Torralba, Antonio and Urtasun, Raquel and Fidler, Sanja},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1506.06726},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Kiros et al. - 2015 - Skip-Thought Vectors.pdf:pdf},
	Number = {786},
	Pages = {1--11},
	Title = {{Skip-Thought Vectors}},
	Url = {http://arxiv.org/abs/1506.06726},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.06726}}

@article{Diggle2013,
	Abstract = {In this paper we first describe the class of log-Gaussian Cox processes (LGCPs) as models for spatial and spatio-temporal point pro-cess data. We discuss inference, with a particular focus on the compu-tational challenges of likelihood-based inference. We then demonstrate the usefulness of the LGCP by describing four applications: estimat-ing the intensity surface of a spatial point process; investigating spatial segregation in a multi-type process; constructing spatially continuous maps of disease risk from spatially discrete data; and real-time health surveillance. We argue that problems of this kind fit naturally into the realm of geostatistics, which traditionally is defined as the study of spatially continuous processes using spatially discrete observations at a finite number of locations. We suggest that a more useful definition of geostatistics is by the class of scientific problems that it addresses, rather than by particular models or data formats.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1312.6536v1},
	Author = {Diggle, Peter J and Moraga, Paula and Rowlingson, Barry and Taylor, Benjamin M},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1214/13-STS441},
	Eprint = {arXiv:1312.6536v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Diggle et al. - 2013 - Spatial and Spatio-Temporal Log-Gaussian Cox Processes Extending the Geostatistical Paradigm.pdf:pdf},
	Journal = {Statistical Science},
	Keywords = {Cox process,Gaussian process,epidemiology,geostatistics,spatial point process},
	Number = {4},
	Pages = {542--563},
	Title = {{Spatial and Spatio-Temporal Log-Gaussian Cox Processes: Extending the Geostatistical Paradigm}},
	Volume = {28},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1214/13-STS441}}

@article{Stein2012,
	Abstract = {Spin glasses are disordered magnetic systems that exhibit a variety of properties that are characteristic of complex systems. After a brief review of basic spin glass concepts, their use in areas such as computer science, biology, and other fields will be explored. This use and its underlying basis will be termed old complexity. Newer concepts and ideas flowing from more recent studies of spin glasses will then be discussed, leading to a proposal for a kind of new complexity.},
	Archiveprefix = {arXiv},
	Arxivid = {1205.3432},
	Author = {Stein, D. L. and Newman, C. M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1205.3432},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Stein, Newman - 2012 - Spin Glasses Old and New Complexity.pdf:pdf},
	Pages = {1--11},
	Title = {{Spin Glasses: Old and New Complexity}},
	Url = {http://arxiv.org/abs/1205.3432},
	Year = {2012},
	Bdsk-Url-1 = {http://arxiv.org/abs/1205.3432}}

@article{Amit1985,
	Author = {Amit, DJ and Gutfreund, H and Sompolinsky, H},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Amit, Gutfreund, Sompolinsky - 1985 - Spin-glass models of neural networks.pdf:pdf},
	Journal = {Physical Review A},
	Pages = {1007},
	Title = {{Spin-glass models of neural networks}},
	Url = {http://www.ft.uam.es/neurociencia/CURSOS/Biofisica-2004/CLASES/Ami+85.pdf http://journals.aps.org/pra/abstract/10.1103/PhysRevA.32.1007},
	Volume = {2},
	Year = {1985},
	Bdsk-Url-1 = {http://www.ft.uam.es/neurociencia/CURSOS/Biofisica-2004/CLASES/Ami+85.pdf%20http://journals.aps.org/pra/abstract/10.1103/PhysRevA.32.1007}}

@article{Zheleva2010,
	Address = {New York, New York, USA},
	Annote = {session model for modes of listening.},
	Author = {Zheleva, Elena and Guiver, John and {Mendes Rodrigues}, Eduarda and Mili{\'{c}}-Frayling, Nata{\v{s}}a},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1772690.1772794},
	File = {:Users/jaanaltosaar/Downloads/session-model-music-listening.pdf:pdf},
	Isbn = {9781605587998},
	Journal = {The International Conference on the World Wide Web},
	Pages = {1019},
	Publisher = {ACM Press},
	Title = {{Statistical models of music-listening sessions in social media}},
	Url = {http://portal.acm.org/citation.cfm?doid=1772690.1772794},
	Volume = {19},
	Year = {2010},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1772690.1772794},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1772690.1772794}}

@article{Zdeborova2015a,
	Abstract = {Many questions of fundamental interest in todays science can be formulated as inference problems: Some partial, or noisy, observations are performed over a set of variables and the goal is to recover, or infer, the values of the variables based on the indirect information contained in the measurements. For such problems, the central scientific questions are: Under what conditions is the information contained in the measurements sufficient for a satisfactory inference to be possible? What are the most efficient algorithms for this task? A growing body of work has shown that often we can understand and locate these fundamental barriers by thinking of them as phase transitions in the sense of statistical physics. Moreover, it turned out that we can use the gained physical insight to develop new promising algorithms. Connection between inference and statistical physics is currently witnessing an impressive renaissance and we review here the current state-of-the-art, with a pedagogical focus on the Ising model which formulated as an inference problem we call the planted spin glass. In terms of applications we review two classes of problems: (i) inference of clusters on graphs and networks, with community detection as a special case and (ii) estimating a signal from its noisy linear measurements, with compressed sensing as a case of sparse estimation. Our goal is to provide a pedagogical review for researchers in physics and other fields interested in this fascinating topic.},
	Archiveprefix = {arXiv},
	Arxivid = {1511.02476},
	Author = {Zdeborov{\'{a}}, Lenka and Krzakala, Florent},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1511.02476},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zdeborov{\'{a}}, Krzakala - 2015 - Statistical physics of inference Thresholds and algorithms(2).pdf:pdf},
	Journal = {arXiv:1511.02476},
	Number = {i},
	Pages = {1--62},
	Title = {{Statistical physics of inference: Thresholds and algorithms}},
	Url = {http://arxiv.org/abs/1511.02476},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.02476}}

@article{Zdeborova2015,
	Abstract = {Many questions of fundamental interest in todays science can be formulated as inference problems: Some partial, or noisy, observations are performed over a set of variables and the goal is to recover, or infer, the values of the variables based on the indirect information contained in the measurements. For such problems, the central scientific questions are: Under what conditions is the information contained in the measurements sufficient for a satisfactory inference to be possible? What are the most efficient algorithms for this task? A growing body of work has shown that often we can understand and locate these fundamental barriers by thinking of them as phase transitions in the sense of statistical physics. Moreover, it turned out that we can use the gained physical insight to develop new promising algorithms. Connection between inference and statistical physics is currently witnessing an impressive renaissance and we review here the current state-of-the-art, with a pedagogical focus on the Ising model which formulated as an inference problem we call the planted spin glass. In terms of applications we review two classes of problems: (i) inference of clusters on graphs and networks, with community detection as a special case and (ii) estimating a signal from its noisy linear measurements, with compressed sensing as a case of sparse estimation. Our goal is to provide a pedagogical review for researchers in physics and other fields interested in this fascinating topic.},
	Archiveprefix = {arXiv},
	Arxivid = {1511.02476},
	Author = {Zdeborov{\'{a}}, Lenka and Krzakala, Florent},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1511.02476},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Zdeborov{\'{a}}, Krzakala - 2015 - Statistical physics of inference Thresholds and algorithms.pdf:pdf},
	Number = {i},
	Pages = {1--62},
	Title = {{Statistical physics of inference: Thresholds and algorithms}},
	Url = {http://arxiv.org/abs/1511.02476},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.02476}}

@article{Rezende2014,
	Abstract = {Abstract We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition ... $\backslash$n},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1401.4082v3},
	Author = {Rezende, D J and Mohamed, S and Wierstra, D},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1401.4082v3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Rezende, Mohamed, Wierstra - 2014 - Stochastic backpropagation and approximate inference in deep generative models.pdf:pdf},
	Isbn = {9781634393973},
	Journal = {JMLR},
	Pages = {1278--1286},
	Title = {{Stochastic backpropagation and approximate inference in deep generative models}},
	Url = {http://jmlr.org/proceedings/papers/v32/rezende14.html$\backslash$npapers3://publication/uuid/F2747569-7719-4EAC-A5A7-9ECA9D6A8FE6},
	Volume = {32},
	Year = {2014},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v32/rezende14.html$%5Cbackslash$npapers3://publication/uuid/F2747569-7719-4EAC-A5A7-9ECA9D6A8FE6}}

@article{Chen2014,
	Abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recent years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system---such a computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1402.4102v1},
	Author = {Chen, Tianqi and Fox, Emily B and Guestrin, Carlos},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1402.4102v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Chen, Fox, Guestrin - 2014 - Stochastic Gradient Hamiltonian Monte Carlo.pdf:pdf},
	Isbn = {9781634393973},
	Journal = {arXiv},
	Pages = {1--23},
	Title = {{Stochastic Gradient Hamiltonian Monte Carlo}},
	Url = {http://arxiv.org/pdf/1402.4102v2.pdf},
	Volume = {32},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1402.4102v2.pdf}}

@article{Carlson2015,
	Author = {Carlson, David and Hsieh, Ya-Ping and Collins, Edo and Carin, Lawrence and Cevher, Volkan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Carlson et al. - 2015 - Stochastic Spectral Descent for Discrete Graphical Models.pdf:pdf},
	Journal = {IEEE Journal of Special Topics in Signal Processing},
	Pages = {1--16},
	Title = {{Stochastic Spectral Descent for Discrete Graphical Models}},
	Url = {http://infoscience.epfl.ch/record/214739/files/SSD{\_}for{\_}belief{\_}nets{\_}bios.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://infoscience.epfl.ch/record/214739/files/SSD%7B%5C_%7Dfor%7B%5C_%7Dbelief%7B%5C_%7Dnets%7B%5C_%7Dbios.pdf}}

@article{Hoffman2013,
	Author = {Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hoffman et al. - 2013 - Stochastic Variational Inference.pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Pages = {1303--1347},
	Title = {{Stochastic Variational Inference}},
	Url = {http://www.cs.columbia.edu/{~}blei/papers/HoffmanBleiWangPaisley2013.pdf},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {http://www.cs.columbia.edu/%7B~%7Dblei/papers/HoffmanBleiWangPaisley2013.pdf}}

@article{Maddison2014,
	Abstract = {We study the problem of building generative models of natural source code (NSC); that is, source code written and understood by humans. Our primary contribution is to describe a family of generative models for NSC that have three key properties: First, they incorporate both sequential and hierarchical structure. Second, we learn a distributed representation of source code elements. Finally, they integrate closely with a compiler, which allows leveraging compiler logic and abstractions when building structure into the model. We also develop an extension that includes more complex structure, refining how the model generates identifier tokens based on what variables are currently in scope. Our models can be learned efficiently, and we show empirically that including appropriate structure greatly improves the models, measured by the probability of generating test programs.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1401.0514},
	Author = {Maddison, Chris J. and Tarlow, Daniel},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1401.0514},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Maddison, Tarlow - 2014 - Structured Generative Models of Natural Source Code.pdf:pdf},
	Isbn = {9781634393973},
	Pages = {1--17},
	Title = {{Structured Generative Models of Natural Source Code}},
	Url = {http://arxiv.org/abs/1401.0514},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1401.0514}}

@article{Hoffman2014,
	Abstract = {Stochastic variational inference makes it possible to approximate posterior distributions induced by large datasets quickly using stochastic optimization. The algorithm relies on the use of fully factorized variational distributions. However, this "mean-field" independence approximation limits the fidelity of the posterior approximation, and introduces local optima. We show how to relax the mean-field approximation to allow arbitrary dependencies between global parameters and local hidden variables, producing better parameter estimates by reducing bias, sensitivity to local optima, and sensitivity to hyperparameters.},
	Archiveprefix = {arXiv},
	Arxivid = {1404.4114},
	Author = {Hoffman, MD and Blei, DM},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1404.4114},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hoffman, Blei - 2014 - Structured Stochastic Variational Inference.pdf:pdf},
	Journal = {arXiv},
	Month = {apr},
	Title = {{Structured Stochastic Variational Inference}},
	Url = {http://arxiv.org/abs/1404.4114},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1404.4114}}

@article{Blei,
	Abstract = {as OUr COLLeCTive knowledge continues to be digitized and stored---in the form of news, blogs, Web pages, scientific articles, books, images, sound, video, and social networks---it becomes more difficult to find and discover what we are looking for. We need new computational tools to help organize, search, and understand these vast amounts of information. Right now, we work with online information using two main tools---search and links. We type keywords into a search engine and find a set of documents related to them. We look at the documents in that set, possibly navigating to other linked documents. This is a powerful way of interacting with our online archive, but something is missing. Imagine searching and exploring documents based on the themes that run through them. We might " zoom in " and " zoom out " to find specific or broader themes; we might look at how those themes changed through time or how they are connected to each other. Rather than finding documents through keyword search alone, we might first find the theme that we are interested in, and then examine the documents related to that theme. For example, consider using themes to explore the complete history of the New York Times. At a broad level, some of the themes might correspond to the sections of the newspaper---for-eign policy, national affairs, sports. We could zoom in on a theme of in-terest, such as foreign policy, to reveal various aspects of it---Chinese foreign policy, the conflict in the Middle East, the U.S.'s relationship with Russia. We could then navigate through time to reveal how these specific themes have changed, tracking, for example, the changes in the conflict in the Middle East over the last 50 years. And, in all of this exploration, we would be pointed to the original articles relevant to the themes. The thematic structure would be a new kind of window through which to explore and digest the collection. But we do not interact with elec-tronic archives in this way. While more and more texts are available online, we simply do not have the human power to read and study them to provide the kind of browsing experience described above. To this end, machine learning researchers have developed probabilis-tic topic modeling, a suite of algorithms that aim to discover and annotate large archives of documents with thematic information. Topic modeling algo-rithms are statistical methods that ana-lyze the words of the original texts to discover the themes that run through them, how those themes are connected to each other, and how they change over key insights},
	Author = {Blei, David M},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/2133806.2133826},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Blei - Unknown - Surveying a suite of algorithms that offer a solution to managing large document archives. Probabilistic topic models.pdf:pdf},
	Title = {{Surveying a suite of algorithms that offer a solution to managing large document archives. Probabilistic topic models}},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2133806.2133826}}

@article{Mou2014,
	Abstract = {Deep neural networks have made significant breakthroughs in many fields of artificial intelligence. However, it has not been applied in the field of programming language processing. In this paper, we propose the tree-based convolutional neural network (TBCNN) to model programming languages, which contain rich and explicit tree structural information. In our model, program vector representations are learned by the "coding" pretraining criterion based on abstract syntax trees (ASTs); the convolutional layer explicitly captures neighboring features on the tree; with the "binary continuous tree" and "3-way pooling," our model can deal with ASTs of different shapes and sizes.We evaluate the program vector representations empirically, showing that the coding criterion successfully captures underlying features of AST nodes, and that program vector representations significantly speed up supervised learning. We also compare TBCNN to baseline methods; our model achieves better accuracy in the task of program classification. To our best knowledge, this paper is the first to analyze programs with deep neural networks; we extend the scope of deep learning to the field of programming language processing. The experimental results validate its feasibility; they also show a promising future of this new research area.},
	Archiveprefix = {arXiv},
	Arxivid = {1409.5718},
	Author = {Mou, Lili and Li, Ge and Jin, Zhi and Zhang, Lu and Wang, Tao},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1409.5718},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mou et al. - 2014 - TBCNN A Tree-Based Convolutional Neural Network for Programming Language Processing.pdf:pdf},
	Title = {{TBCNN: A Tree-Based Convolutional Neural Network for Programming Language Processing}},
	Url = {http://arxiv.org/abs/1409.5718},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.5718}}

@article{Hermann2015,
	Abstract = {Teaching machines to read natural language documents remains an elusive chal-lenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.03340v1},
	Author = {Hermann, Karm Moritz and Ko{\v{c}}isk{\'{y}}, Tom{\'{a}}{\v{s}} and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.03340v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hermann et al. - 2015 - Teaching Machines to Read and Comprehend.pdf:pdf},
	Pages = {1--13},
	Title = {{Teaching Machines to Read and Comprehend}},
	Url = {http://arxiv.org/pdf/1506.03340v3.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.03340v3.pdf}}

@article{Sohl-Dickstein2015a,
	Abstract = {We observe that the standard log likelihood training objective for a Recurrent Neural Network (RNN) model of time series data is equivalent to a variational Bayesian training objective, given the proper choice of generative and inference models. This perspective may motivate extensions to both RNNs and variational Bayesian models. We propose one such extension, where multiple particles are used for the hidden state of an RNN, allowing a natural representation of uncertainty or multimodality.},
	Archiveprefix = {arXiv},
	Arxivid = {1504.08025},
	Author = {Sohl-Dickstein, Jascha and Kingma, Diederik P.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1504.08025},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Sohl-Dickstein, Kingma - 2015 - Technical Note on Equivalence Between Recurrent Neural Network Time Series Models and Variational Bayesi.pdf:pdf},
	Keywords = {()},
	Title = {{Technical Note on Equivalence Between Recurrent Neural Network Time Series Models and Variational Bayesian Models}},
	Url = {http://arxiv.org/abs/1504.08025},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1504.08025}}

@article{Rota1997,
	Author = {Rota, Gian-Carlo},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Rota - 1997 - Ten lessons I wish I had been taught.pdf:pdf},
	Isbn = {0817638660},
	Journal = {Notices of the American Mathematical Society},
	Number = {1},
	Pages = {22--25},
	Title = {{Ten lessons I wish I had been taught}},
	Url = {http://www.ams.org/mathscinet-getitem?mr=MR1419919$\backslash$npapers2://publication/uuid/8FD07DB5-103E-4A45-B5BD-3AAC0831D0FF},
	Volume = {44},
	Year = {1997},
	Bdsk-Url-1 = {http://www.ams.org/mathscinet-getitem?mr=MR1419919$%5Cbackslash$npapers2://publication/uuid/8FD07DB5-103E-4A45-B5BD-3AAC0831D0FF}}

@article{Abadi2015,
	Author = {Abadi, Martin and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Shlens, Jon and Steiner, Benoit and Sutskever, Ilya and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vinyals, Oriol and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Abadi et al. - 2015 - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
	Title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
	Url = {http://download.tensorflow.org/paper/whitepaper2015.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://download.tensorflow.org/paper/whitepaper2015.pdf}}

@article{Bryan2006,
	Abstract = {Google's success derives in large part from its PageRank algorithm, which ranks the importance of web pages according to an eigenvector of a weighted link matrix. Analysis of the PageRank formula provides a wonderful applied topic for a linear algebra course. Instructors may assign this article as a project to more advanced students or spend one or two lectures presenting the material with assigned homework from the exercises. This material also complements the discussion of Markov chains in matrix algebra. Maple and Mathematica files supporting this material can be found at www.rose-hulman.edu/{\~{}}bryan Read More: http://epubs.siam.org/doi/abs/10.1137/050623280},
	Author = {Bryan, Kurt and Leise, Tanya},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1137/050623280},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bryan, Leise - 2006 - The {\$}25,000,000,000 Eigenvector The Linear Algebra behind Google.pdf:pdf},
	Isbn = {00361445},
	Issn = {0036-1445},
	Journal = {SIAM Review},
	Keywords = {1,15-01,15a18,15a51,ams subject classifications,deliver the,eigenvector,from other search engines,good stuff,in the late 1990,introduction,it apart,linear algebra,one thing that set,pagerank,result listings always seemed,s,stochastic matrix,was that its search,when google went online},
	Number = {3},
	Pages = {569--581},
	Pmid = {23701758},
	Title = {{The {\$}25,000,000,000 Eigenvector: The Linear Algebra behind Google}},
	Url = {http://www.rose-hulman.edu/{~}bryan/googleFinalVersionFixed.pdf},
	Volume = {48},
	Year = {2006},
	Bdsk-Url-1 = {http://www.rose-hulman.edu/%7B~%7Dbryan/googleFinalVersionFixed.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/050623280}}

@article{Webb1961,
	Abstract = {-},
	Author = {Webb, Wilse B.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1037/h0044746},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Webb - 1961 - The choice of the problem.pdf:pdf},
	Issn = {0003-066X},
	Journal = {American Psychologist},
	Pages = {223--227},
	Title = {{The choice of the problem.}},
	Url = {https://slack-files.com/files-pri-safe/T0A4083T5-F0GTQK0VC/webb{\_}1961.pdf?c=1450384732-509e276e145d1cf511088e0bb33b332b59034979},
	Volume = {16},
	Year = {1961},
	Bdsk-Url-1 = {https://slack-files.com/files-pri-safe/T0A4083T5-F0GTQK0VC/webb%7B%5C_%7D1961.pdf?c=1450384732-509e276e145d1cf511088e0bb33b332b59034979},
	Bdsk-Url-2 = {http://dx.doi.org/10.1037/h0044746}}

@article{Liang2007,
	Abstract = {We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process (HDP). Our HDP-PCFG model allows the complexity of the grammar to grow as more training data is available. In addition to presenting a fully Bayesian model for the PCFG, we also develop an efficient variational inference procedure. On synthetic data, we recover the correct grammar without having to specify its complexity in advance. We also show that our techniques can be applied to full-scale parsing applications by demonstrating its effectiveness in learning state-split grammars. 1},
	Author = {Liang, Percy and Petrov, S. and Jordan, Michael I. and Klein, Dan},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Liang et al. - 2007 - The Infnite PCFG using Hierarchical Dirichlet Processes.pdf:pdf},
	Journal = {Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)},
	Pages = {688--697},
	Title = {{The Infnite PCFG using Hierarchical Dirichlet Processes}},
	Url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:The+Infnite+PCFG+using+Hierarchical+Dirichlet+Processes{\#}0},
	Year = {2007},
	Bdsk-Url-1 = {http://scholar.google.com/scholar?hl=en%7B%5C&%7DbtnG=Search%7B%5C&%7Dq=intitle:The+Infnite+PCFG+using+Hierarchical+Dirichlet+Processes%7B%5C#%7D0}}

@article{Perfors2011,
	Abstract = {Children acquiring language infer the correct form of syntactic constructions for which they appear to have little or no direct evidence, avoiding simple but incorrect generalizations that would be consistent with the data they receive. These generalizations must be guided by some inductive bias - some abstract knowledge - that leads them to prefer the correct hypotheses even in the absence of directly supporting evidence. What form do these inductive constraints take? It is often argued or assumed that they reflect innately specified knowledge of language. A classic example of such an argument moves from the phenomenon of auxiliary fronting in English interrogatives to the conclusion that children must innately know that syntactic rules are defined over hierarchical phrase structures rather than linear sequences of words (e.g., Chomsky, 1965, 1971, 1980; Crain {\&} Nakayama, 1987). Here we use a Bayesian framework for grammar induction to address a version of this argument and show that, given typical child-directed speech and certain innate domain-general capacities, an ideal learner could recognize the hierarchical phrase structure of language without having this knowledge innately specified as part of the language faculty. We discuss the implications of this analysis for accounts of human language acquisition. ?? 2010 Elsevier B.V.},
	Author = {Perfors, Amy and Tenenbaum, Joshua B. and Regier, Terry},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1016/j.cognition.2010.11.001},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Perfors, Tenenbaum, Regier - 2011 - The learnability of abstract syntactic principles.pdf:pdf},
	Isbn = {0010-0277},
	Issn = {00100277},
	Journal = {Cognition},
	Keywords = {Bayesian modeling,Language learnability,Poverty of stimulus},
	Number = {3},
	Pages = {306--338},
	Pmid = {21186021},
	Publisher = {Elsevier B.V.},
	Title = {{The learnability of abstract syntactic principles}},
	Url = {http://dx.doi.org/10.1016/j.cognition.2010.11.001 http://lclab.berkeley.edu/papers/perfors-et-al-2011.pdf},
	Volume = {118},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.cognition.2010.11.001%20http://lclab.berkeley.edu/papers/perfors-et-al-2011.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.cognition.2010.11.001}}

@article{Choromanska2015,
	Abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1412.0233},
	Author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'{e}}rard Ben and LeCun, Yann},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1412.0233},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Choromanska et al. - 2015 - The Loss Surfaces of Multilayer Networks.pdf:pdf},
	Isbn = {1412.0233},
	Journal = {AISTATS},
	Keywords = {Neural Network,Optimization},
	Pages = {192----204},
	Title = {{The Loss Surfaces of Multilayer Networks}},
	Url = {http://arxiv.org/abs/1412.0233$\backslash$nhttp://www.arxiv.org/pdf/1412.0233.pdf},
	Volume = {38},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1412.0233$%5Cbackslash$nhttp://www.arxiv.org/pdf/1412.0233.pdf}}

@inproceedings{Bertin-Mahieux2011,
	Author = {Bertin-Mahieux, Thierry and Ellis, Daniel P W and Whitman, Brian and Lamere, Paul},
	Booktitle = {Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR 2011)},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Title = {{The Million Song Dataset}},
	Year = {2011}}

@article{Marcus1994,
	Abstract = {The Penn Treebank has recently implemented a new syn- tactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as "underlying" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles.},
	Author = {Marcus, Mitchell and Kim, Grace and Marcinkiewicz, Mary Ann and MacIntyre, Robert and Bies, Ann and Ferguson, Mark and Katz, Karen and Schasberger, Britta},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.3115/1075812.1075835},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Marcus et al. - 1994 - The Penn Treebank Annotation Predicate Argument Structure.pdf:pdf},
	Isbn = {1558603573},
	Journal = {Proceedings of the workshop on Human Language Technology - HLT '94},
	Pages = {114--119},
	Title = {{The Penn Treebank: Annotation Predicate Argument Structure}},
	Url = {http://dl.acm.org/citation.cfm?id=1075812.1075835},
	Year = {1994},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1075812.1075835},
	Bdsk-Url-2 = {http://dx.doi.org/10.3115/1075812.1075835}}

@article{Hermann,
	Author = {Hermann, Karl Moritz and Blunsom, Phil},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hermann, Blunsom - Unknown - The Role of Syntax in Vector Space Models of Compositional Semantics.pdf:pdf},
	Title = {{The Role of Syntax in Vector Space Models of Compositional Semantics}},
	Url = {http://www.karlmoritz.com/{\_}media/hermannblunsom{\_}acl2013.pdf},
	Bdsk-Url-1 = {http://www.karlmoritz.com/%7B%5C_%7Dmedia/hermannblunsom%7B%5C_%7Dacl2013.pdf}}

@article{Solar-Lezama2009,
	Abstract = {Sketching is a new form of localized software synthesis that aims to bridge the gap between a programmer's high-level insights about a problem and the computer's ability to manage low-level details. In sketching, the programmer uses partial programs to describe the desired implementation strategy , and leaves the low-level details of the implementation to an automated synthesis procedure. This paper describes the sketching approach to program synthesis, including the details of the {\textless}Emphasis language and synthesizer. The paper will then describe some of the techniques that make synthesis from sketches possible, and will close with a brief discussion of open problems in programmer guided synthesis.},
	Author = {Solar-Lezama, Armando},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1007/978-3-642-10672-9_3},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Solar-Lezama - 2009 - The sketching approach to program synthesis.pdf:pdf},
	Isbn = {3642106714},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Pages = {4--13},
	Title = {{The sketching approach to program synthesis}},
	Url = {http://people.csail.mit.edu/asolar/papers/thesis.pdf},
	Volume = {5904 LNCS},
	Year = {2009},
	Bdsk-Url-1 = {http://people.csail.mit.edu/asolar/papers/thesis.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/978-3-642-10672-9_3}}

@article{Henderson2010,
	Abstract = {Hierarchical Bayesian models (HBMs) provide an account of Bayesian inference in a hierarchically structured hypothesis space. Scientific theories are plausibly regarded as organized into hierarchies in many cases, with higher levels sometimes called 'paradigms' and lower levels encoding more specific or concrete hypotheses. Therefore, HBMs provide a useful model for scientific theory change, showing how higher-level theory change may be driven by the impact of evidence on lower levels. HBMs capture features described in the Kuhnian tradition, particularly the idea that higher-level theories guide learning at lower levels. In addition, they help resolve certain issues for Bayesians, such as scientific preference for simplicity and tbe problem of new theories.},
	Author = {Henderson, Leah and Goodman, Noah D. and Tenenbaum, Joshua B. and Woodward, James F.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1086/651319},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Henderson et al. - 2010 - The Structure and Dynamics of Scientific Theories A Hierarchical Bayesian Perspective.pdf:pdf},
	Isbn = {00318248},
	Issn = {00318248},
	Journal = {Philosophy of Science},
	Number = {2},
	Pages = {172--200},
	Title = {{The Structure and Dynamics of Scientific Theories: A Hierarchical Bayesian Perspective*}},
	Url = {http://cocolab.stanford.edu/papers/HendersonEtAl2010-PhilosSci.pdf},
	Volume = {77},
	Year = {2010},
	Bdsk-Url-1 = {http://cocolab.stanford.edu/papers/HendersonEtAl2010-PhilosSci.pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1086/651319}}

@article{Tkacik2015,
	Abstract = {The activity of a neural network is defined by patterns of spiking and silence from the individual neurons. Because spikes are (relatively) sparse, patterns of activity with increasing numbers of spikes are less probable, but, with more spikes, the number of possible patterns increases. This tradeoff between probability and numerosity is mathematically equivalent to the relationship between entropy and energy in statistical physics. We construct this relationship for populations of up to N = 160 neurons in a small patch of the vertebrate retina, using a combination of direct and model-based analyses of experiments on the response of this network to naturalistic movies. We see signs of a thermodynamic limit, where the entropy per neuron approaches a smooth function of the energy per neuron as N increases. The form of this function corresponds to the distribution of activity being poised near an unusual kind of critical point. We suggest further tests of criticality, and give a brief discussion of its functional significance.},
	Archiveprefix = {arXiv},
	Arxivid = {physics/0004057},
	Author = {Tka{\v{c}}ik, Ga{\v{s}}per and Mora, Thierry and Marre, Olivier and Amodei, Dario and Palmer, Stephanie E and Berry, Michael J and Bialek, William},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1073/pnas.1514188112},
	Eprint = {0004057},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Tka{\v{c}}ik et al. - 2015 - Thermodynamics and signatures of criticality in a network of neurons.pdf:pdf},
	Isbn = {1514188112},
	Issn = {1091-6490},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Number = {37},
	Pages = {11508--13},
	Pmid = {26330611},
	Primaryclass = {physics},
	Title = {{Thermodynamics and signatures of criticality in a network of neurons.}},
	Url = {http://www.pnas.org/content/112/37/11508.abstract},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {http://www.pnas.org/content/112/37/11508.abstract},
	Bdsk-Url-2 = {http://dx.doi.org/10.1073/pnas.1514188112}}

@article{Mnih2007,
	Abstract = {The current study characterized the in vitro surface reactions of microroughened bioactive glasses and compared osteoblast cell responses between smooth and microrough surfaces. Three different bioactive glass compositions were used and surface microroughening was obtained using a novel chemical etching method. Porous bioactive glass specimens made of sintered microspheres were immersed in simulated body fluid (SBF) or Tris solutions for 1, 6, 24, 48, or 72 h, and the formation of reaction layers was studied by means of a scanning electron microscope/energy dispersive X-ray analysis (SEM/EDXA). Cell culture studies were performed on bioactive glass disks to examine the influence of surface microroughness on the attachment and proliferation of human osteoblast-like cells (MG-63). Cell attachment was evaluated by means of microscopic counting of in situ stained cells. Cell proliferation was analyzed with a nonradioactive cell proliferation assay combined with in situ staining and laser confocal microscopy. The microroughening of the bioactive glass surface increased the rate of the silica gel layer formation during the first hours of the immersion. The formation of calcium phosphate layer was equal between control and microroughened glass surfaces. In cell cultures on bioactive glass, the microrough surface enhanced the attachment of osteoblast-like cells but did not have an effect on the proliferation rate or morphology of the cells as compared with smooth glass surface. In conclusion, accelerated the early formation of surface reactions on three bioactive glasses and had a positive effect on initial cell attachment.},
	Author = {Mnih, A and Hinton, G},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1145/1273496.1273577},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Mnih, Hinton - 2007 - Three new graphical models for statistical language modelling.pdf:pdf},
	Isbn = {9781595937933},
	Journal = {ICML},
	Pages = {641--648},
	Title = {{Three new graphical models for statistical language modelling.}},
	Url = {http://discovery.ucl.ac.uk/63252/},
	Volume = {62},
	Year = {2007},
	Bdsk-Url-1 = {http://discovery.ucl.ac.uk/63252/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1273496.1273577}}

@article{Hardt2015,
	Abstract = {We show that any model trained by a stochastic gradient method with few iterations has vanishing generalization error. We prove this by showing the method is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. Our results apply to both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. Applying our results to the convex case, we provide new explanations for why multiple epochs of stochastic gradient descent generalize well in practice. In the nonconvex case, we provide a new interpretation of common practices in neural networks, and provide a formal rationale for stability-promoting mechanisms in training large, deep models. Conceptually, our findings underscore the importance of reducing training time beyond its obvious benefit.},
	Archiveprefix = {arXiv},
	Arxivid = {1509.01240},
	Author = {Hardt, Moritz and Recht, Benjamin and Singer, Yoram},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1509.01240},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Hardt, Recht, Singer - 2015 - Train faster, generalize better Stability of stochastic gradient descent.pdf:pdf},
	Pages = {1--24},
	Title = {{Train faster, generalize better: Stability of stochastic gradient descent}},
	Url = {http://arxiv.org/abs/1509.01240},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1509.01240}}

@article{Shabanian,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.03877v1},
	Author = {Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.03877v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Shabanian, Fischer, Bengio - Unknown - Training opposing directed models using geometric mean matching arXiv 1506 . 03877v1 cs . LG 1.pdf:pdf},
	Pages = {1--12},
	Title = {{Training opposing directed models using geometric mean matching arXiv : 1506 . 03877v1 [ cs . LG ] 12 Jun 2015}},
	Url = {http://arxiv.org/pdf/1506.03877v1.pdf},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.03877v1.pdf}}

@article{Stamerjohanns2010,
	Author = {Stamerjohanns, Heinrich and Kohlhase, Michael and Ginev, Deyan and David, Catalin and Miller, Bruce},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1007/s11786-010-0024-7},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Stamerjohanns et al. - 2010 - Transforming Large Collections of Scientific Publications to XML.pdf:pdf},
	Issn = {1661-8270},
	Journal = {Mathematics in Computer Science},
	Month = {feb},
	Number = {3},
	Pages = {299--307},
	Title = {{Transforming Large Collections of Scientific Publications to XML}},
	Url = {http://link.springer.com/10.1007/s11786-010-0024-7},
	Volume = {3},
	Year = {2010},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/s11786-010-0024-7},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11786-010-0024-7}}

@article{Dyer2015,
	Abstract = {We propose a technique for learning representations of parser states in transition-based dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks---the stack LSTM. Like the conventional stack data structures used in transition-based parsing, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents. This lets us formulate an efficient parsing model that captures three facets of a parser's state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures. Standard backpropagation techniques are used for training and yield state-of-the-art parsing performance.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1505.08075v1},
	Author = {Dyer, Chris and Ballesteros, Miguel and Ling, Wang and Matthews, Austin and Smith, Noah a},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1505.08075v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Dyer et al. - 2015 - Transition-Based Dependency Parsing with Stack Long Short-Term Memory.pdf:pdf},
	Journal = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	Pages = {334--343},
	Title = {{Transition-Based Dependency Parsing with Stack Long Short-Term Memory}},
	Url = {http://www.aclweb.org/anthology/P15-1033},
	Year = {2015},
	Bdsk-Url-1 = {http://www.aclweb.org/anthology/P15-1033}}

@article{Cormack2007,
	Abstract = {TREC's Spam Track introduces a standard testing framework that presents a chronological sequence of email messages, one at a time, to a spam filter for classification. The filter yields a binary judgement (spam or ham [i.e. non-spam]) which is compared to a human-adjudicated gold standard. The filter also yields a spamminess score, intended to reflect the likelihood that the classified message is spam, which is the subject of post-hoc ROC (Receiver Operating Characteristic) analysis. The gold standard for each message is communicated to the filter immediately following classification. Eight test corpora -- email messages plus gold standard judgements -- were used to evaluate 53 subject filters. Five of the corpora (the public corpora) were distributed to participants, who ran their filters on the corpora using a track-supplied toolkit implementing the framework. Three of the corpora (the private corpora) were not distributed to participants; rather, participants submitted filter implementations that were run, using the toolkit, on the private data. Twelve groups participated in the track, submitting 44 filters for evaluation. The other nine subject filters were variants of popular open-source implementations adapted for use in the toolkit in consultation with their authors.},
	Author = {Cormack, Gordon and Lynam, Thomas},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Cormack, Lynam - 2007 - TREC 2007 Spam Track Overview.pdf:pdf},
	Issn = {1048776X},
	Journal = {Sixteenth Text Retrieval Conference (TREC 2007)},
	Keywords = {N/A,Proposal},
	Number = {Trec},
	Pages = {1--9},
	Title = {{TREC 2007 Spam Track Overview}},
	Url = {http://trec.nist.gov//pubs/trec14/papers/SPAM.OVERVIEW.pdf},
	Year = {2007},
	Bdsk-Url-1 = {http://trec.nist.gov//pubs/trec14/papers/SPAM.OVERVIEW.pdf}}

@article{Ma2015,
	Abstract = {In sentence modeling and classification, convolutional neural network approaches have recently achieved state-of-the-art results, but all such efforts process word vectors sequentially and neglect long-distance dependencies. To exploit both deep learning and linguistic structures, we propose a tree-based convolutional neural network model which exploit various long-distance relationships between words. Our model improves the sequential baselines on all three sentiment and question classification tasks, and achieves the highest published accuracy on TREC.},
	Archiveprefix = {arXiv},
	Arxivid = {1507.01839},
	Author = {Ma, Mingbo and Huang, Liang and Zhou, Bowen and Xiang, Bing},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1507.01839},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Ma et al. - 2015 - Tree-based Convolution for Sentence Modeling.pdf:pdf},
	Number = {1995},
	Title = {{Tree-based Convolution for Sentence Modeling}},
	Url = {http://arxiv.org/abs/1507.01839},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1507.01839}}

@article{Bowman2015,
	Abstract = {Tree-structured neural networks encode a particular tree geometry for a sentence in the network design. However, these models have at best only slightly outperformed simpler sequence-based models. We hypothesize that neural sequence models like LSTMs are in fact able to discover and implicitly use recursive compositional structure, at least for tasks with clear cues to that structure in the data. We demonstrate this possibility using an artificial data task for which recursive compositional structure is crucial, and find that the sequence model can learn the underlying patterning. The sequence model is better in that it learns the value of tree structure from the data in an emergent way, while the tree-structured model is better in being able to learn with greater statistical efficiency due to its informative prior model structure.},
	Archiveprefix = {arXiv},
	Arxivid = {1506.04834},
	Author = {Bowman, Samuel R. and Manning, Christopher D. and Potts, Christopher},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1506.04834},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bowman, Manning, Potts - 2015 - Tree-structured composition in neural networks without tree-structured architectures.pdf:pdf},
	Title = {{Tree-structured composition in neural networks without tree-structured architectures}},
	Url = {http://arxiv.org/abs/1506.04834},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.04834}}

@misc{Karpathy2014,
	Author = {Karpathy, Andrej},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Karpathy - 2014 - tSNEJS httpsgithub.comkarpathytsnejs.html:html},
	Title = {{tSNEJS; https://github.com/karpathy/tsnejs}},
	Url = {https://github.com/karpathy/tsnejs},
	Year = {2014},
	Bdsk-Url-1 = {https://github.com/karpathy/tsnejs}}

@article{Turner2011,
	Abstract = {Variational methods are a key component of the approximate inference and learning toolbox. These methods fill an important middle ground, retaining distributional information about uncertainty in latent variables, unlike maximum a posteriori methods (MAP), and yet generally requiring less computational time than Monte Carlo Markov Chain methods. In particular the variational Expectation Maximisation (vEM) and variational Bayes algorithms, both involving variational optimisation of a free-energy, are widely used in time-series modelling. Here, we investigate the success of vEM in simple probabilistic time-series models. First we consider the inference step of vEM, and show that a consequence of the well-known compactness property of variational inference is a failure to propagate uncertainty in time, thus limiting the usefulness of the retained distributional information. In particular, the uncertainty may appear to be smallest precisely when the approximation is poorest. Second, we consider parameter learning and analytically reveal systematic biases in the parameters found by vEM. Surprisingly, simpler variational approxi- mations (such a mean-field) can lead to less bias than more complicated structured approximations.},
	Author = {Turner, R. and Sahani, M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1017/CBO9780511984679.006},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Turner, Sahani - 2011 - Two problems with variational expectation maximisation for time-series models.pdf:pdf},
	Isbn = {9780521196765},
	Journal = {Inference and Estimation in Probabilistic TimeSeries Models},
	Keywords = {theory {\&} algorithms},
	Pages = {109--130},
	Title = {{Two problems with variational expectation maximisation for time-series models}},
	Url = {http://eprints.pascal-network.org/archive/00007972/},
	Year = {2011},
	Bdsk-Url-1 = {http://eprints.pascal-network.org/archive/00007972/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1017/CBO9780511984679.006}}

@article{Srivastava2015,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1502.04681v2},
	Author = {Srivastava, Nitish},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1502.04681v2},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Srivastava - 2015 - Unsupervised Learning of Video Representations using LSTMs.pdf:pdf},
	Title = {{Unsupervised Learning of Video Representations using LSTMs}},
	Url = {http://arxiv.org/pdf/1502.04681.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1502.04681.pdf}}

@article{Tran2015a,
	Abstract = {Representations offered by deep generative models are fundamentally tied to their inference method from data. Variational inference methods require a rich family of approximating distributions. We construct the variational Gaussian process (VGP), a Bayesian nonparametric model which adapts its shape to match complex posterior distributions. The VGP generates approximate posterior samples by generating latent inputs and warping them through random non-linear mappings; the distribution over random mappings is learned during inference, enabling the transformed outputs to adapt to varying complexity. We prove a universal approximation theorem for the VGP, demonstrating its representative power for learning any model. For inference we present a variational objective inspired by autoencoders and perform black box inference over a wide class of models. The VGP achieves new state-of-the-art results for unsupervised learning, inferring models such as the deep latent Gaussian model and the recently proposed DRAW.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1511.06499},
	Author = {Tran, Dustin and Ranganath, Rajesh and Blei, David M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1511.06499},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Tran, Ranganath, Blei - 2015 - Variational Gaussian Process.pdf:pdf},
	Pages = {1--14},
	Title = {{Variational Gaussian Process}},
	Url = {http://arxiv.org/abs/1511.06499},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.06499}}

@article{Wang2013,
	Abstract = {Mean-field variational methods are widely used for approximate posterior inference in many probabilistic models. In a typical application, mean-field methods approximately compute the posterior with a coordinate-ascent optimization algorithm. When the model is conditionally conjugate, the coordinate updates are easily derived and in closed form. However, many models of interest---like the correlated topic model and Bayesian logistic regression---are nonconjuate. In these models, mean-field methods cannot be directly applied and practitioners have had to develop variational algorithms on a case-by-case basis. In this paper, we develop two generic methods for nonconjugate models, Laplace variational inference and delta method variational inference. Our methods have several advantages: they allow for easily derived variational algorithms with a wide class of nonconjugate models; they extend and unify some of the existing algorithms that have been derived for specific models; and they work well on real-world datasets. We studied our methods on the correlated topic model, Bayesian logistic regression, and hierarchical Bayesian logistic regression.},
	Archiveprefix = {arXiv},
	Arxivid = {1209.4360},
	Author = {Wang, Chong and Blei, David M.},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1209.4360},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Wang, Blei - 2013 - Variational Inference in Nonconjugate Models.pdf:pdf},
	Issn = {1532-4435},
	Journal = {Journal of Machine Learning Research},
	Keywords = {laplace approximations,nonconjugate models,the multivariate,variational inference},
	Pages = {1005--1031},
	Title = {{Variational Inference in Nonconjugate Models}},
	Url = {http://www.jmlr.org/papers/volume14/wang13b/wang13b.pdf},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {http://www.jmlr.org/papers/volume14/wang13b/wang13b.pdf}}

@article{Karpathy,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1506.02078v1},
	Author = {Karpathy, Andrej and Johnson, Justin},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {arXiv:1506.02078v1},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Karpathy, Johnson - Unknown - Visualizing and Understanding Recurrent Networks.pdf:pdf},
	Pages = {1--13},
	Title = {{Visualizing and Understanding Recurrent Networks}},
	Url = {http://arxiv.org/pdf/1506.02078v1.pdf},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.02078v1.pdf}}

@article{Maaten2008,
	Author = {Maaten, Laurens Van Der and Hinton, Geoffrey},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Maaten, Hinton - 2008 - Visualizing Data using t-SNE.pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
	Pages = {2579--2605},
	Title = {{Visualizing Data using t-SNE}},
	Url = {http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf},
	Volume = {9},
	Year = {2008},
	Bdsk-Url-1 = {http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf}}

@article{Li2015,
	Abstract = {But there have not been rigorous evaluations showing for exactly which tasks this syntax-based method is appropriate. In this paper we benchmark {\{}$\backslash$bf recursive{\}} neural models against sequential {\{}$\backslash$bf recurrent{\}} neural models (simple recurrent and LSTM models). We investigate 4 tasks: (1) sentiment classification at the sentence level and phrase level; (2) matching questions to answer-phrases; (3) discourse parsing; (4) semantic relation extraction (e.g., {\{}$\backslash$em component-whole{\}} between nouns). We implement carefully matched versions of recursive and recurrent models and apply them to each task. Our analysis suggests that sequence-based recurrent models achieve equal or better performance in most tasks with the exception that syntactic tree-based recursive models are particularly helpful for tasks that require representing long-distance relations between words (e.g., semantic relations between nominals). Our results help understand the limitations of both classes of models, and suggest directions for improving recurrent models $\backslash$footnote{\{}Code for models described in Section 3.1 on Stanford Treebank dataset are released at$\backslash$url{\{}http://web.stanford.edu/{\~{}}jiweil/{\}}.{\}}.},
	Archiveprefix = {arXiv},
	Arxivid = {1503.00185},
	Author = {Li, Jiwei and Jurafsky, Dan and Hovy, Eudard},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1503.00185},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Li, Jurafsky, Hovy - 2015 - When Are Tree Structures Necessary for Deep Learning of Representations.pdf:pdf},
	Title = {{When Are Tree Structures Necessary for Deep Learning of Representations?}},
	Url = {http://arxiv.org/abs/1503.00185},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1503.00185}}

@article{Nghiem2014,
	Abstract = {Mathematical content is a valuable information source and retrieving this content has become an important issue. This paper compares two searching strategies for math expressions: presentation-based and content-based approaches. Presentation-based search uses state-of-the-art math search system while content-based search uses semantic enrichment of math expressions to convert math expressions into their content forms and searching is done using these content-based expressions. By considering the meaning of math expressions, the quality of search system is improved over presentation-based systems.},
	Archiveprefix = {arXiv},
	Arxivid = {1405.3353},
	Author = {Nghiem, Minh-Quoc and Kristianto, Giovanni Yoko and Topic, Goran and Aizawa, Akiko},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Eprint = {1405.3353},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Nghiem et al. - 2014 - Which one is better presentation-based or content-based math search.pdf:pdf},
	Keywords = {content-based math search,math retrieval,mathml},
	Pages = {1--14},
	Title = {{Which one is better: presentation-based or content-based math search?}},
	Url = {http://arxiv.org/abs/1405.3353},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1405.3353}}

@article{Charlton2009,
	Abstract = {QUESTION: why are so many leading modern scientists so dull and lacking in scientific ambition? ANSWER: because the science selection process ruthlessly weeds-out interesting and imaginative people. At each level in education, training and career progression there is a tendency to exclude smart and creative people by preferring Conscientious and Agreeable people. The progressive lengthening of scientific training and the reduced independence of career scientists have tended to deter vocational 'revolutionary' scientists in favour of industrious and socially adept individuals better suited to incremental 'normal' science. High general intelligence (IQ) is required for revolutionary science. But educational attainment depends on a combination of intelligence and the personality trait of Conscientiousness; and these attributes do not correlate closely. Therefore elite scientific institutions seeking potential revolutionary scientists need to use IQ tests as well as examination results to pick-out high IQ 'under-achievers'. As well as high IQ, revolutionary science requires high creativity. Creativity is probably associated with moderately high levels of Eysenck's personality trait of 'Psychoticism'. Psychoticism combines qualities such as selfishness, independence from group norms, impulsivity and sensation-seeking; with a style of cognition that involves fluent, associative and rapid production of many ideas. But modern science selects for high Conscientiousness and high Agreeableness; therefore it enforces low Psychoticism and low creativity. Yet my counter-proposal to select elite revolutionary scientists on the basis of high IQ and moderately high Psychoticism may sound like a recipe for disaster, since resembles a formula for choosing gifted charlatans and confidence tricksters. A further vital ingredient is therefore necessary: devotion to the transcendental value of Truth. Elite revolutionary science should therefore be a place that welcomes brilliant, impulsive, inspired, antisocial oddballs - so long as they are also dedicated truth-seekers.},
	Author = {Charlton, Bruce G},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	Doi = {10.1016/j.mehy.2008.11.020},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Charlton - 2009 - Why are modern scientists so dull How science selects for perseverance and sociability at the expense of intelligence.pdf:pdf},
	Isbn = {0306-9877},
	Issn = {0306-9877},
	Journal = {Medical hypotheses},
	Keywords = {Boredom,Career Choice,Educational Measurement,Intelligence,Medical Laboratory Personnel,Medical Laboratory Personnel: organization {\&} admin,Personality,Personnel Selection,Personnel Selection: methods,Science,Science: trends},
	Number = {3},
	Pages = {237--43},
	Pmid = {19070437},
	Title = {{Why are modern scientists so dull? How science selects for perseverance and sociability at the expense of intelligence and creativity.}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0306987708005902},
	Volume = {72},
	Year = {2009},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0306987708005902},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.mehy.2008.11.020}}

@article{Bem2002,
	Author = {Bem, Daryl J},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Bem - 2002 - Writing the empirical journal article.pdf:pdf},
	Isbn = {0898599490},
	Journal = {The Compleat Academic: A Career Guide},
	Pages = {171--201},
	Title = {{Writing the empirical journal article}},
	Url = {papers2://publication/uuid/708A37DB-FEBF-441D-8E33-D08BBC99C04A},
	Year = {2002},
	Bdsk-Url-1 = {papers2://publication/uuid/708A37DB-FEBF-441D-8E33-D08BBC99C04A}}

@article{Fuhr2006,
	Author = {Fuhr, Norbert and Trotman, Andrew},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Fuhr, Trotman - 2006 - XML Document Mining using Graph Neural Network.pdf:pdf},
	Keywords = {INEX},
	Title = {{XML Document Mining using Graph Neural Network}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.8932{\&}rep=rep1{\&}type=pdf{\#}page=366},
	Year = {2006},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.8932%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf%7B%5C#%7Dpage=366}}

@article{SchraudolphJMLR2010,
	Abstract = {We present a unified framework to study graph kernels, special cases of which include the random walk (G{\"{a}}rtner et al., 2003; Borgwardt et al., 2005) and marginalized (Kashima et al., 2003, 2004; Mah{\'{e}} et al., 2004) graph kernels. Through reduction to a Sylvester equation we improve the time complexity of kernel computation between unlabeled graphs with n vertices from O(n 6) to O(n 3). We find a spectral decomposition approach even more efficient when computing entire kernel ma-trices. For labeled graphs we develop conjugate gradient and fixed-point methods that take O(dn 3) time per iteration, where d is the size of the label set. By extending the necessary linear algebra to Reproducing Kernel Hilbert Spaces (RKHS) we obtain the same result for d-dimensional edge ker-nels, and O(n 4) in the infinite-dimensional case; on sparse graphs these algorithms only take O(n 2) time per iteration in all cases. Experiments on graphs from bioinformatics and other application domains show that these techniques can speed up computation of the kernel by an order of mag-nitude or more. We also show that certain rational kernels (Cortes et al., 2002, 2003, 2004) when specialized to graphs reduce to our random walk graph kernel. Finally, we relate our framework to R-convolution kernels (Haussler, 1999) and provide a kernel that is close to the optimal assignment kernel of Fr{\"{o}}hlich et al. (2006) yet provably positive semi-definite.},
	Author = {{Schraudolph JMLR}, Nicol N and {Kondor RISI}, Risi and {Borgwardt KARSTENBORGWARDT}, Karsten M},
	Date-Added = {2016-05-13 19:14:56 +0000},
	Date-Modified = {2016-05-13 19:14:56 +0000},
	File = {:Users/jaanaltosaar/papers/mendeley collection/Schraudolph JMLR, Kondor RISI, Borgwardt KARSTENBORGWARDT - 2010 - ().pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Keywords = {()},
	Pages = {1201--1242},
	Title = {()},
	Volume = {11},
	Year = {2010}}

@article{Duane:1987,
	Author = {Duane, Simon and Kennedy, Anthony D and Pendleton, Brian J and Roweth, Duncan},
	Journal = {Physics letters B},
	Number = {2},
	Pages = {216--222},
	Publisher = {Elsevier},
	Title = {Hybrid monte carlo},
	Volume = {195},
	Year = {1987}}

@inproceedings{Stein:1972,
	Author = {Stein, Charles and others},
	Booktitle = {Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 2: Probability Theory},
	Organization = {The Regents of the University of California},
	Title = {A bound for the error in the normal approximation to the distribution of a sum of dependent random variables},
	Year = {1972}}

@article{Oates:2014,
	Author = {Oates, Chris J and Girolami, Mark and Chopin, Nicolas},
	Journal = {arXiv preprint arXiv:1410.2392},
	Title = {Control functionals for Monte Carlo integration},
	Year = {2014}}

@inproceedings{Gorham:2015,
	Author = {Gorham, Jackson and Mackey, Lester},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {226--234},
	Title = {Measuring Sample Quality with Stein's Method},
	Year = {2015}}

@article{Ley:2011,
	Author = {Ley, Christophe and Swan, Yvik},
	Journal = {arXiv preprint arXiv:1105.4925},
	Title = {A unified approach to Stein characterizations},
	Year = {2011}}

@incollection{Stein:2004,
	Author = {Stein, Charles and Diaconis, Persi and Holmes, Susan and Reinert, Gesine and others},
	Booktitle = {Stein's Method},
	Pages = {1--25},
	Publisher = {Institute of Mathematical Statistics},
	Title = {Use of exchangeable pairs in the analysis of simulations},
	Year = {2004}}

@article{Barbour:1988,
	Author = {Barbour, Andrew D},
	Journal = {Journal of Applied Probability},
	Pages = {175--184},
	Publisher = {JSTOR},
	Title = {Stein's method and Poisson process convergence},
	Year = {1988}}

@article{Ross:2011,
	Author = {Ross, Nathan and others},
	Journal = {Probab. Surv},
	Pages = {210--293},
	Title = {Fundamentals of Stein's method},
	Volume = {8},
	Year = {2011}}

@inproceedings{Giordano:2015,
	Author = {Giordano, Ryan J and Broderick, Tamara and Jordan, Michael I},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {1441--1449},
	Title = {Linear response methods for accurate covariance estimates from mean field variational Bayes},
	Year = {2015}}

@techreport{ghahramani1997structured,
	Author = {Ghahramani, Zoubin},
	Institution = {Citeseer},
	Title = {On structured variational approximations},
	Year = {1997}}

@inproceedings{Hoffman:2015,
	Author = {Hoffman, Matthew and Blei, David},
	Booktitle = {Artifical Intelligence and Statistics},
	Date-Modified = {2020-04-17 10:55:20 -0400},
	Title = {Stochastic Structured Variational Inference},
	Year = {2015}}

@book{Cover:2012,
	Author = {Cover, Thomas M and Thomas, Joy A},
	Publisher = {John Wiley \& Sons},
	Title = {Elements of information theory},
	Year = {2012}}

@article{Neal:1990,
	Author = {Neal, R.},
	Journal = {Tech. Rep. CRG-TR-90-7: Department of Computer Science, University of Toronto},
	Title = {Learning stochastic feedforward networks},
	Year = {1990}}

@article{Hinton:2006,
	Acmid = {1161605},
	Address = {Cambridge, MA, USA},
	Author = {Hinton, G. and Osindero, S. and Teh, Y.},
	Issn = {0899-7667},
	Issue_Date = {July 2006},
	Journal = {Neural Comput.},
	Month = jul,
	Number = {7},
	Numpages = {28},
	Pages = {1527--1554},
	Publisher = {MIT Press},
	Title = {A Fast Learning Algorithm for Deep Belief Nets},
	Volume = {18},
	Year = {2006}}

@article{Faes:2011,
	Author = {Faes, Christel and Ormerod, John T and Wand, Matt P},
	Journal = {Journal of the American Statistical Association},
	Number = {495},
	Title = {Variational Bayesian inference for parametric and nonparametric regression with missing data},
	Volume = {106},
	Year = {2011}}

@article{Ormerod:2012,
	Author = {Ormerod, John T and Wand, MP},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {1},
	Pages = {2--17},
	Title = {Gaussian variational approximate inference for generalized linear mixed models},
	Volume = {21},
	Year = {2012}}

@article{Dunson:2005,
	Author = {Dunson, David B and Herring, Amy H},
	Journal = {Biostatistics},
	Number = {1},
	Pages = {11--25},
	Publisher = {Biometrika Trust},
	Title = {Bayesian latent variable models for mixed discrete outcomes},
	Volume = {6},
	Year = {2005}}

@article{Pitman:1997,
	Author = {Pitman, Jim and Yor, Marc},
	Journal = {The Annals of Probability},
	Pages = {855--900},
	Title = {The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator},
	Year = {1997}}

@article{Med-Suvisaari:2008,
	Author = {Suvisaari, Jaana and Per{\"a}l{\"a}, Jonna and Saarni, Samuli I and H{\"a}rk{\"a}nen, Tommi and Pirkola, Sami and Joukamaa, Matti and Koskinen, Seppo and L{\"o}nnqvist, Jouko and Reunanen, Antti},
	Journal = {European Archives of Psychiatry and Clinical Neuroscience},
	Number = {3},
	Pages = {129--136},
	Publisher = {Springer},
	Title = {Type 2 diabetes among persons with schizophrenia and other psychotic disorders in a general population survey},
	Volume = {258},
	Year = {2008}}

@article{Med-Liu:2013,
	Author = {Liu, Yanli and Li, Zezhi and Zhang, Meixia and Deng, Youping and Yi, Zhenghui and Shi, Tieliu},
	Journal = {BMC medical genomics},
	Number = {Suppl 1},
	Pages = {S17},
	Publisher = {BioMed Central Ltd},
	Title = {Exploring the pathogenetic association between schizophrenia and type 2 diabetes mellitus diseases based on pathway analysis},
	Volume = {6},
	Year = {2013}}

@inproceedings{Ghahramani:1995,
	Author = {Ghahramani, Zoubin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {617--624},
	Title = {Factorial learning and the EM algorithm},
	Year = {1995}}

@inproceedings{Titsias:2008,
	Author = {Titsias, Michalis K},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {1513--1520},
	Title = {The infinite gamma-Poisson feature model},
	Year = {2008}}

@article{Moller:1998,
	Author = {M{\o}ller, Jesper and Syversveen, Anne Randi and Waagepetersen, Rasmus Plenge},
	Journal = {Scandinavian journal of statistics},
	Number = {3},
	Pages = {451--482},
	Publisher = {Wiley Online Library},
	Title = {Log gaussian cox processes},
	Volume = {25},
	Year = {1998}}

@article{Quinonero-Candela:2005,
	Author = {Qui{\~n}onero-Candela, Joaquin and Rasmussen, Carl Edward},
	Journal = {The Journal of Machine Learning Research},
	Pages = {1939--1959},
	Publisher = {JMLR},
	Title = {A unifying view of sparse approximate Gaussian process regression},
	Volume = {6},
	Year = {2005}}

@inproceedings{Doshi-Velez:2009c,
	Author = {Doshi-Velez, Finale and Ghahramani, Zoubin},
	Booktitle = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
	Organization = {AUAI Press},
	Pages = {143--150},
	Title = {Correlated non-parametric latent feature models},
	Year = {2009}}

@article{Borodin:2009,
	Author = {Borodin, Alexei},
	Journal = {arXiv preprint arXiv:0911.1153},
	Title = {Determinantal point processes},
	Year = {2009}}

@article{Perman:1993,
	Author = {Perman, Mihael},
	Journal = {Stochastic processes and their applications},
	Number = {2},
	Pages = {267--281},
	Publisher = {Elsevier},
	Title = {Order statistics for jumps of normalised subordinators},
	Volume = {46},
	Year = {1993}}

@inproceedings{Foti:2013,
	Author = {Foti, Nicholas J and Futoma, Joseph D and Rockmore, Daniel N and Williamson, Sinead},
	Booktitle = {International Conference on Artifical Intelligence and Statistics},
	Title = {A unifying representation for a class of dependent random measures},
	Year = {2013}}

@inproceedings{Salimans:2015,
	Author = {Salimans, Tim and Kingma, Diederik and Welling, Max},
	Booktitle = {International Conference on Artifical Intelligence and Statistics},
	Title = {Markov chain Monte Carlo and variational inference: Bridging the gap},
	Year = {2015}}

@inproceedings{Gopalan:2014,
	Author = {Gopalan, Prem and Ruiz, Francisco JR and Ranganath, Rajesh and Blei, David M},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Title = {Bayesian Nonparametric Poisson Factorization for Recommendation Systems},
	Year = {2014}}

@article{Broderick:2011,
	Author = {Broderick, Tamara and Mackey, Lester and Paisley, John and Jordan, Michael I},
	Publisher = {IEEE},
	Title = {Combinatorial clustering and the beta negative binomial process},
	Year = {2011}}

@article{Zhou:2015,
	Author = {Zhou, Mingyuan and Carin, Lawrence},
	Journal = {Pattern Analysis and Machine Intelligence},
	Publisher = {IEEE},
	Title = {Negative binomial process count and mixture modeling},
	Year = {2015}}

@article{Manning:2014,
	Author = {Manning, Jeremy R and Ranganath, Rajesh and Norman, Kenneth A and Blei, David M},
	Journal = {PloS one},
	Number = {5},
	Pages = {e94914},
	Publisher = {Public Library of Science},
	Title = {Topographic factor analysis: a bayesian model for inferring brain networks from neural data},
	Volume = {9},
	Year = {2014}}

@article{Casella:1996,
	Author = {Casella, George and Robert, Christian P},
	Journal = {Biometrika},
	Number = {1},
	Pages = {81--94},
	Publisher = {Biometrika Trust},
	Title = {Rao-Blackwellisation of sampling schemes},
	Volume = {83},
	Year = {1996}}

@article{Goldstein:1991,
	Author = {Goldstein, H.},
	Journal = {The Statistician},
	Pages = {235-244},
	Title = {Multilevel modeling of survey data},
	Volume = {6},
	Year = {1991}}

@misc{Bache:2013,
	Author = {K. Bache and M. Lichman},
	Institution = {University of California, Irvine, School of Information and Computer Sciences},
	Title = {{UCI} Machine Learning Repository},
	Url = {http://archive.ics.uci.edu/ml},
	Year = {2013},
	Bdsk-Url-1 = {http://archive.ics.uci.edu/ml}}

@article{Jaakkola:2000,
	Author = {Jaakkola, T. and Jordan, M. I.},
	Journal = {Statistics and Computing},
	Pages = {25-37},
	Title = {{B}ayesian logistic regression: a variational approach},
	Volume = {10},
	Year = {2000}}

@inproceedings{Bottou:2004a,
	Author = {Bottou, L. and LeCun, Y.},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Large Scale Online Learning},
	Year = 2004}

@article{Carlin:1991,
	Author = {Carlin, B. and Polson, N.},
	Journal = {Canadian Journal of Statistics},
	Number = {4},
	Pages = {399--405},
	Publisher = {Wiley Online Library},
	Title = {Inference for nonconjugate {B}ayesian models using the {G}ibbs sampler},
	Volume = {19},
	Year = {1991}}

@article{Xing:2005,
	Author = {Xing, E.},
	Journal = {CMU-ML TR},
	Pages = {05--115},
	Title = {On topic evolution},
	Year = {2005}}

@book{Kotz:2000,
	Author = {Kotz, S. and Balakrishnan, N. and Johnson, N.},
	Publisher = {Wiley-Interscience},
	Title = {Continuous multivariate distributions, models and applications},
	Volume = {334},
	Year = {2000}}

@book{Barber:2012,
	Author = {Barber, D.},
	Publisher = {{Cambridge University Press}},
	Title = {{Bayesian Reasoning and Machine Learning}},
	Year = 2012}

@book{Ross:2002,
	Author = {Ross, S. M.},
	Publisher = {{Elsevier}},
	Title = {{Simulation}},
	Year = 2002}

@inproceedings{Bishop:1999,
	Author = {Bishop, C.},
	Booktitle = {International Conference on Artificial Neural Networks},
	Organization = {IET},
	Pages = {509--514},
	Title = {Variational principal components},
	Volume = {1},
	Year = {1999}}

@inproceedings{Gopalan:2012,
	Author = {P. Gopalan and D. Mimno and S. Gerrish and M. Freedman and D. Blei},
	Booktitle = {Neural Information Processing Systems},
	Title = {Scalable Inference of Overlapping Communities},
	Year = {2012}}

@article{George:2006,
	Author = {George, A. and Powell, W.},
	Journal = {Machine learning},
	Number = {1},
	Pages = {167--198},
	Publisher = {Springer},
	Title = {Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming},
	Volume = {65},
	Year = {2006}}

@article{Rosenberg:2005,
	Author = {Rosenberg, N. and Mahajan, S. and Ramachandran, S. and Zhao, C. and Pritchard, J. K. and Feldman, M.W.},
	Journal = {Plos Genetics},
	Pages = {660-671},
	Publisher = {PLOS},
	Title = {Clines, clusters, and the effect of study design on the inference of human population structure},
	Volume = {1},
	Year = {2005}}

@inproceedings{Snoek:2012,
	Author = {J. Snoek and H. Larochelle and R. Adams},
	Booktitle = {Neural Information Processing Systems},
	Title = {Practical {B}ayesian Optimization of Machine Learning Algorithms},
	Year = {2012}}

@inproceedings{Sato:2012a,
	Acmid = {2339550},
	Address = {New York, NY, USA},
	Author = {Sato, Issei and Kurihara, Kenichi and Nakagawa, Hiroshi},
	Booktitle = {International Conference on Knowledge Discovery and Data Mining},
	Doi = {10.1145/2339530.2339550},
	Isbn = {978-1-4503-1462-6},
	Keywords = {collapsed variational bayes inference, hierarchical dirichlet process, latent dirichlet allocation, nonparametric bayes},
	Location = {Beijing, China},
	Numpages = {9},
	Pages = {105--113},
	Publisher = {ACM},
	Series = {KDD},
	Title = {Practical collapsed variational bayes inference for hierarchical dirichlet process},
	Url = {http://doi.acm.org/10.1145/2339530.2339550},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2339530.2339550},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2339530.2339550}}

@inproceedings{Wang:2012a,
	Author = {Chong Wang and David M. Blei},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Truncation-free Stochastic Variational inference for {B}ayesian Nonparametric Models},
	Year = {2012}}

@article{Rue:2009,
	Author = {Rue, H. and Martino, S. and Chopin, N.},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Number = {2},
	Pages = {319--392},
	Publisher = {Blackwell Publishing Ltd},
	Title = {Approximate {B}ayesian inference for latent {G}aussian models by using integrated nested {L}aplace approximations},
	Volume = {71},
	Year = {2009}}

@inproceedings{Smola:2003,
	Author = {A. Smola and V. Vishwanathan and E. Eskin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Laplace Propagation},
	Year = {2003}}

@article{Paisley:2012b,
	Author = {J. Paisley and C. Wang and D. Blei},
	Journal = {Bayesian Analysis},
	Number = {2},
	Pages = {235--272},
	Title = {The Discrete Infinite Logistic Normal Distribution},
	Volume = {7},
	Year = {2012}}

@inproceedings{Mimno:2012,
	Author = {David Mimno and Matt Hoffman and David Blei},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Title = {Sparse stochastic inference for latent Dirichlet allocation},
	Year = {2012}}

@inproceedings{Sato:2012,
	Author = {Issei Sato and Hiroshi Nakagawa},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Title = {Rethinking Collapsed Variational {B}ayes Inference for {LDA}},
	Year = {2012}}

@article{Collobert:2011,
	Acmid = {2078186},
	Author = {Collobert, R. and Weston, J. and Bottou, L. and Karlen, M. and Kavukcuoglu, K. and Kuksa, P.},
	Journal = {Journal of Machine Learning Research},
	Numpages = {45},
	Pages = {2493--2537},
	Publisher = {JMLR.org},
	Title = {Natural Language Processing (Almost) from Scratch},
	Volume = {12},
	Year = {2011}}

@article{Nemirovski:2009,
	Author = {Nemirovski, A. and Juditsky, A. and Lan, G. and Shapiro, A.},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {1574-1609},
	Title = {Robust Stochastic Approximation Approach to Stochastic Programming},
	Volume = {19},
	Year = {2009}}

@inproceedings{Paisley:2012,
	Author = {J. Paisley and D. Blei and M. Jordan},
	Booktitle = {International Conference on Machine Learning},
	Title = {Variational {B}ayesian Inference with Stochastic Search},
	Year = {2012}}

@inproceedings{Welling:2008,
	Author = {M. Welling and C. Chemudugunta and N. Sutter},
	Booktitle = {SIAM International Conference on Data Mining},
	Title = {Deterministic Latent Variable Models and Their Pitfalls},
	Year = {2008}}

@inproceedings{Chaney:2012,
	Author = {Allison June-Barlow Chaney and David M. Blei},
	Booktitle = {The International AAAI Conference on Weblogs and Social Media},
	Title = {Visualizing Topic Models},
	Year = {2012}}

@inproceedings{Termite:2012,
	Author = {Jason Chuang AND Christopher D. Manning AND Jeffrey Heer},
	Booktitle = {Advanced Visual Interfaces},
	Title = {Termite: Visualization Techniques for Assessing Textual Topic Models},
	Url = {http://vis.stanford.edu/papers/termite},
	Year = {2012},
	Bdsk-Url-1 = {http://vis.stanford.edu/papers/termite}}

@article{Gretarsson:2012,
	Acmid = {2089099},
	Address = {New York, NY, USA},
	Articleno = {23},
	Author = {Gretarsson, Brynjar and O'Donovan, John and Bostandjiev, Svetlin and H\"{o}llerer, Tobias and Asuncion, Arthur and Newman, David and Smyth, Padhraic},
	Doi = {10.1145/2089094.2089099},
	Issn = {2157-6904},
	Issue_Date = {February 2012},
	Journal = {ACM Transactions on Intelligent Systems and Technology},
	Keywords = {Topic modeling, graph visualization, text visualization},
	Month = feb,
	Number = {2},
	Numpages = {26},
	Pages = {23:1--23:26},
	Publisher = {ACM},
	Title = {TopicNets: Visual Analysis of Large Text Corpora with Topic Modeling},
	Url = {http://doi.acm.org/10.1145/2089094.2089099},
	Volume = {3},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2089094.2089099},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2089094.2089099}}

@inproceedings{Schein:2002,
	Author = {Schein, Andrew I. and Popescul, Alexandrin and Ungar, Lyle H. and Pennock, David M.},
	Booktitle = {ACM International Conference on Research and Development in Information Retrieval},
	Title = {Methods and metrics for cold-start recommendations},
	Year = {2002}}

@article{Wang:2012,
	Author = {{Wang}, C. and {Blei}, D.~M.},
	Journal = {JMLR},
	Title = {Variational Inference for Nonconjutate Models},
	Year = 2013}

@article{Kleiner:2012,
	Archiveprefix = {arXiv},
	Author = {{Kleiner}, A. and {Talwalkar}, A. and {Sarkar}, P. and {Jordan}, M.},
	Eprint = {1112.5016},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Methodology, Statistics - Computation, Statistics - Machine Learning},
	Month = Jun,
	Primaryclass = {stat.ME},
	Title = {A Scalable Bootstrap for Massive Data},
	Year = 2012}

@article{Wingate:2013,
	Archiveprefix = {arXiv},
	Author = {{Wingate}, D. and {Weber}, T},
	Eprint = {1301.1299},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, CS - Artificial Intelligence, CS - Learning},
	Month = Jan,
	Primaryclass = {stat.ML},
	Title = {Automated Variational Inference in Probabilistic Programming},
	Year = 2013}

@article{Salimans:2012,
	Archiveprefix = {arXiv},
	Author = {{Salimans}, T. and {Knowles}, D},
	Eprint = {1206.6679},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Computation, CS - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	Month = Aug,
	Primaryclass = {stat.ML},
	Title = {Fixed-Form Variational Approximation through Stochastic Linear Regression},
	Year = 2012}

@article{Hoffman:2013,
	Author = {Hoffman, M. and Blei, D. and Wang, C. and Paisley, J.},
	Journal = {Journal of Machine Learning Research},
	Number = {1303--1347},
	Title = {Stochastic Variational Inference},
	Volume = {14},
	Year = {2013}}

@article{Schaul:2012,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2012arXiv1206.1106S},
	Archiveprefix = {arXiv},
	Author = {{Schaul}, T. and {Zhang}, S. and {LeCun}, Y.},
	Eprint = {1206.1106},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = jun,
	Primaryclass = {stat.ML},
	Title = {{No more pesky learning rates}},
	Year = 2012}

@inproceedings{El-Arini:2011,
	Acmid = {2020479},
	Address = {New York, NY, USA},
	Author = {El-Arini, Khalid and Guestrin, Carlos},
	Booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
	Doi = {10.1145/2020408.2020479},
	Isbn = {978-1-4503-0813-7},
	Keywords = {citation analysis, personalization},
	Location = {San Diego, California, USA},
	Numpages = {9},
	Pages = {439--447},
	Publisher = {ACM},
	Series = {KDD '11},
	Title = {Beyond keyword search: discovering relevant scientific literature},
	Url = {http://doi.acm.org/10.1145/2020408.2020479},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2020408.2020479},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2020408.2020479}}

@inproceedings{YaoLimin:2009,
	Author = {Yao, Limin and Mimno, David and McCallum, Andrew},
	Booktitle = {International Conference on Knowledge Discovery and Data Mining (KDD)},
	Title = {Efficient methods for topic model inference on streaming document collections},
	Year = {2009}}

@inproceedings{Ahmed:2012,
	Author = {Ahmed, Amr and Aly, Moahmed and Gonzalez, Joseph and Narayanamurthy, Shravan and Smola, Alexander J.},
	Booktitle = {International Conference on Web Search and Data Mining (WSDM)},
	Title = {Scalable inference in latent variable models},
	Year = {2012}}

@article{Gershman:2012,
	Author = {Samuel J. Gershman and David M. Blei},
	Doi = {10.1016/j.jmp.2011.08.004},
	Issn = {0022-2496},
	Journal = {Journal of Mathematical Psychology},
	Keywords = {Indian buffet process},
	Number = {1},
	Pages = {1 - 12},
	Title = {A tutorial on {B}ayesian nonparametric models},
	Url = {http://www.sciencedirect.com/science/article/pii/S002224961100071X},
	Volume = {56},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S002224961100071X},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.jmp.2011.08.004}}

@article{Newman:2009a,
	Author = {Newman, David and Asuncion, Arthur and Smyth, Padhraic and Welling, Max},
	Journal = {Journal of Machine Learning Research},
	Keywords = {bayesian, distributional-similarity, topic-models},
	Pages = {1801--1828},
	Title = {Distributed algorithms for topic models},
	Volume = {10},
	Year = {2009}}

@inproceedings{Carlson:2010,
	Author = {Andrew Carlson and Justin Betteridge and Bryan Kisiel and Burr Settles and Estevam R. Hruschka Jr. and Tom M. Mitchell},
	Booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
	Title = {Toward an Architecture for Never-Ending Language Learning},
	Year = {2010}}

@article{Smola:2010,
	Acmid = {1920931},
	Author = {Smola, Alexander and Narayanamurthy, Shravan},
	Issn = {2150-8097},
	Issue_Date = {September 2010},
	Journal = {Proc. VLDB Endow.},
	Month = sep,
	Number = {1-2},
	Numpages = {8},
	Pages = {703--710},
	Publisher = {VLDB Endowment},
	Title = {An architecture for parallel topic models},
	Url = {http://dl.acm.org/citation.cfm?id=1920841.1920931},
	Volume = {3},
	Year = {2010},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1920841.1920931}}

@book{Hjort:2010,
	Address = {Cambridge, UK},
	Author = {Hjort, N. and Holmes, C. and Mueller, P. and Walker, S.},
	Publisher = {Cambridge University Press},
	Title = {Bayesian Nonparametrics: Principles and Practice},
	Year = 2010}

@inproceedings{Zhai:2012,
	Author = {Ke Zhai and Jordan Boyd-Graber and Nima Asadi and Mohamad Alkhouja},
	Booktitle = {International World Wide Web Conference (WWW)},
	Location = {Lyon, France},
	Title = {Mr. {LDA}: A Flexible Large Scale Topic Modeling Package using Variational Inference in {MapReduce}},
	Year = {2012}}

@inbook{Opper:Winther:2001,
	Author = {Opper, Manfred and Winther, Ole},
	Booktitle = {Advanced mean field methods theory and},
	Pages = {1--19},
	Publisher = {MIT Press},
	Title = {From Naive Mean Field Theory to the TAP Equations},
	Year = {2001}}

@article{Stephens:2000,
	Author = {Stephens, Matthew},
	Doi = {10.1111/1467-9868.00265},
	Issn = {1467-9868},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Keywords = {Bayesian approach, Classification, Clustering, Identifiability, Markov chain Monte Carlo methods, Mixture model, Multimodal posterior},
	Number = {4},
	Pages = {795--809},
	Publisher = {Blackwell Publishers Ltd.},
	Title = {Dealing with label switching in mixture models},
	Url = {http://dx.doi.org/10.1111/1467-9868.00265},
	Volume = {62},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/1467-9868.00265}}

@article{Preisser:1999,
	Abstract = {Generalized estimating equations (GEE) can be highly influenced by the presence of unusual data points. A generalization of the GEE procedure, which yields parameter estimates and fitted values that are resistant to influential data, is introduced. Resistant generalized estimating equations (REGEE) include weights in the estimating equations to downweight influential observations or clusters. Influential observations are downweighted according to their leverage or residual in an example of correlated binary regression applied to 137 urinary incontinent elderly patients from 38 medical practices.},
	Author = {Preisser, John S. and Qaqish, Bahjat F.},
	Copyright = {Copyright {\copyright} 1999 International Biometric Society},
	Issn = {0006341X},
	Journal = {Biometrics},
	Jstor_Formatteddate = {Jun., 1999},
	Language = {English},
	Number = {2},
	Pages = {pp. 574-579},
	Publisher = {International Biometric Society},
	Title = {Robust Regression for Clustered Data with Application to Binary Responses},
	Url = {http://www.jstor.org/stable/2533808},
	Volume = {55},
	Year = {1999},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2533808}}

@book{Heritier:2009,
	Acknowledgement = ack-nhfb,
	Bibdate = {Wed Sep 15 09:35:27 MDT 2010},
	Bibsource = {z3950.loc.gov:7090/Voyager},
	Editor = {Stephane Heritier and others},
	Isbn = {0-470-02726-6 (cloth), 0-470-74054-X (e-book)},
	Isbn-13 = {978-0-470-02726-4 (cloth), 978-0-470-74054-5 (e-book)},
	Lccn = {QH323.5 .R615 2009},
	Pages = {xiv + 268},
	Publisher = {pub-WILEY},
	Series = {Wiley series in probability and statistics},
	Subject = {biometry; statistical methods; methods},
	Tableofcontents = {Key measures and results \\ Linear regression \\ Mixed linear models \\ Generalized linear models \\ Marginal longitudinal data analysis \\ Survival analysis},
	Title = {Robust methods in biostatistics},
	Url = {http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470027266.html},
	Year = {2009},
	Bdsk-Url-1 = {http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470027266.html}}

@inproceedings{Barber:1998,
	Author = {David Barber and Christopher M. Bishop},
	Booktitle = {Neural Networks and Machine Learning},
	Pages = {215--237},
	Publisher = {Springer},
	Title = {Ensemble learning in Bayesian neural networks},
	Year = {1998}}

@techreport{Mallows:1975,
	Author = {Mallows, C. L.},
	Institution = {Bell Telephone Laboratories, Murray Hill},
	Note = {Technical Memorandum},
	Title = {On some topics in robustness},
	Year = {1975}}

@article{Carroll:1993,
	Abstract = {We investigate robustness in the logistic regression model.
       Copas has studied two forms of robust estimator: a robust-resistant
         estimate of Pregibon and an estimate based on a misclassification
         model. He concluded that robust-resistant estimates are much more
         biased in small samples than the usual logistic estimate is and
         recommends a bias-corrected version of the misclassification estimate.
         We show that there are other versions of robust-resistant estimates
         which have bias often approximately the same as and sometimes even less
         than the logistic estimate; these estimates belong to the Mallows
         class. In addition, the corrected misclassification estimate is
         inconsistent at the logistic model; we develop a simple consistent
         modification. The modified estimate is a member of the Mallows class
         but, unlike most robust estimates, it has an interpretable tuning
         constant. The results are illustrated on data sets featuring different
         kinds of outliers.},
	Author = {Carroll, R. J. and Pederson, Shane},
	Copyright = {Copyright {\copyright} 1993 Royal Statistical Society},
	Issn = {00359246},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Jstor_Articletype = {research-article},
	Jstor_Formatteddate = {1993},
	Language = {English},
	Number = {3},
	Pages = {pp. 693-706},
	Publisher = {Blackwell Publishing for the Royal Statistical Society},
	Title = {On Robustness in the Logistic Regression Model},
	Url = {http://www.jstor.org/stable/2345881},
	Volume = {55},
	Year = {1993},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2345881}}

@inproceedings{Doyle:2009,
	Address = {New York, NY, USA},
	Author = {Doyle, Gabriel and Elkan, Charles},
	Booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	Pages = {281--288},
	Publisher = {ACM},
	Series = {ICML '09},
	Title = {Accounting for burstiness in topic models},
	Year = {2009}}

@article{Lange:1989,
	Author = {Lange, Kenneth L and Little, Roderick J A and Taylor, Jeremy M G},
	Journal = {Journal of the American Statistical Association},
	Number = {408},
	Pages = {881},
	Publisher = {JSTOR},
	Title = {Robust Statistical Modeling Using the t Distribution},
	Volume = {84},
	Year = {1989}}

@article{Svensen:2005,
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Svens{\'e}n, Markus and Bishop, Christopher M.},
	Issn = {0925-2312},
	Journal = {Neurocomput.},
	Keywords = {Latent variable model, Model selection, Outliers, Student-t distribution, Variational inference},
	Month = mar,
	Numpages = {18},
	Pages = {235--252},
	Publisher = {Elsevier Science Publishers B. V.},
	Title = {Robust {B}ayesian mixture modelling},
	Volume = {64},
	Year = {2005}}

@article{Peel:2000,
	Address = {Hingham, MA, USA},
	Author = {Peel, D. and McLachlan, G. J.},
	Journal = {Statistics and Computing},
	Number = {4},
	Pages = {339--348},
	Publisher = {Kluwer Academic Publishers},
	Title = {Robust mixture modelling using the t distribution},
	Volume = {10},
	Year = {2000}}

@article{Huber:1964,
	Author = {Huber, Peter J},
	Journal = {The Annals of Mathematical Statistics},
	Number = {1},
	Pages = {73-101},
	Publisher = {Institute of Mathematical Statistics},
	Title = {Robust Estimation of a Location Parameter},
	Volume = {35},
	Year = {1964}}

@article{Tierney:1989,
	Author = {Tierney, L. and Kass, R. and Kadane, J.},
	Journal = {Journal of American Statistical Association},
	Number = {407},
	Publisher = {American Statistical Association},
	Title = {Fully Exponential {L}aplace Approximations to Expectations and Variances of Nonpositive Functions},
	Volume = {84},
	Year = {1989}}

@inproceedings{Honkela:2004,
	Author = {A. Honkela and H. Valpola},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Unsupervised Variational {B}ayesian Learning of Nonlinear Models},
	Year = {2004}}

@inproceedings{Honkela:2008,
	Author = {Honkela, Antti and Tornio, Matti and Raiko, Tapani and Karhunen, Juha},
	Booktitle = {Neural Information Processing},
	Title = {Natural conjugate gradient in variational inference},
	Year = {2008}}

@inproceedings{Knowles:2011,
	Author = {D. Knowles and T. Minka},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Non-conjugate Variational Message Passing for Multinomial and Binary Regression},
	Year = {2011}}

@article{Russell:2008,
	Author = {Bryan C. Russell and Antonio B. Torralba and Kevin P. Murphy and William T. Freeman},
	Journal = {IJCV},
	Number = {1-3},
	Pages = {157-173},
	Title = {Label{M}e: A Database and Web-Based Tool for Image Annotation},
	Volume = {77},
	Year = {2008}}

@inproceedings{Jeon:2003,
	Author = {J. Jeon and V. Lavrenko and R. Manmatha},
	Booktitle = {SIGIR},
	Title = {Automatic image annotation and retrieval using cross-media relevance models},
	Year = {2003}}

@article{Hofmann:2001,
	Author = {Hofmann, Thomas},
	Journal = {Mach. Learn.},
	Number = {1-2},
	Pages = {177--196},
	Title = {Unsupervised Learning by Probabilistic Latent Semantic Analysis},
	Volume = {42},
	Year = {2001}}

@inproceedings{Cao:2007,
	Author = {L. Cao and L. Fei-Fei},
	Booktitle = {CVPR},
	Title = {Spatially coherent latent topic model for concurrent object segmentation and classification},
	Year = {2007}}

@inproceedings{WangY:2007,
	Author = {Wang, Y. and Gong, S.},
	Booktitle = {BMVC},
	Title = {Conditional Random Field for Natural Scene Categorization},
	Year = {2007}}

@inproceedings{ZhouZ:2006,
	Author = {Zhi-Hua Zhou and Min-Ling Zhang},
	Booktitle = {NIPS},
	Title = {Multi-Instance Multi-Label Learning with Application to Scene Classification},
	Year = {2006}}

@article{Chen:2004,
	Author = {Yixin Chen and James Z. Wang},
	Journal = {JMLR},
	Pages = {913--939},
	Title = {Image Categorization by Learning and Reasoning with Regions},
	Volume = {5},
	Year = {2004}}

@inproceedings{Voge:2004,
	Author = {Julia Vogel and Bernt Schiele},
	Booktitle = {DAGM-Symposium},
	Title = {A Semantic Typicality Measure for Natural Scene Categorization},
	Year = {2004}}

@inproceedings{Szummer:1998,
	Author = {Martin Szummer and Rosalind W. Picard},
	Booktitle = {IEEE International Workshop on Content-based Access of Image and Video Databases},
	Title = {Indoor-Outdoor Image Classification},
	Year = {1998}}

@article{Vailaya:2001,
	Author = {Aditya Vailaya and M{\'a}rio A. T. Figueiredo and Anil K. Jain and HongJiang Zhang},
	Journal = {IEEE Trans. on Image Processing},
	Number = {1},
	Pages = {117-130},
	Title = {Image classification for content-based indexing},
	Volume = {10},
	Year = {2001}}

@article{Oliva:2001,
	Author = {Aude Oliva and Antonio B. Torralba},
	Journal = {IJCV},
	Number = {3},
	Pages = {145-175},
	Title = {Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope},
	Volume = {42},
	Year = {2001}}

@inproceedings{Lowe:1999,
	Author = {D. Lowe},
	Booktitle = {ICCV},
	Title = {Object recognition from local scale-invariant features},
	Year = {1999}}

@article{Kadir:2001,
	Author = {Timor Kadir and Michael Brady},
	Journal = {IJCV},
	Number = {2},
	Pages = {83--105},
	Title = {Saliency, Scale and Image Description},
	Volume = {45},
	Year = {2001}}

@inproceedings{Li-Jia:2007,
	Author = {Li, Li-Jia and Fei-Fei, Li},
	Booktitle = {ICCV},
	Title = {What, where and who? {C}lassifying event by scene and object recognition},
	Year = {2007}}

@inproceedings{Hofmann:1999b,
	Author = {Thomas Hofmann},
	Booktitle = {SIGIR},
	Title = {{P}robabilistic Latent Semantic indexing},
	Year = {1999}}

@article{Boutell:2004,
	Author = {M. Boutell and J. Luo and X. Shen and C. Brown},
	Journal = {Pattern Recognition},
	Number = {9},
	Pages = {1757--1771},
	Title = {Learning multi-label scene classification},
	Volume = {37},
	Year = {2004}}

@inproceedings{Elisseeff:2001,
	Author = {A. Elisseeff and J. Weston},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {A kernel method for multi-labelled classification},
	Year = {2001}}

@article{Argyriou:2008,
	Author = {Argyriou, A. and Evgeniou, T. and Pontil, M.},
	Issue = {3},
	Journal = {Maching Learning},
	Month = {December},
	Numpages = {30},
	Pages = {243--272},
	Title = {Convex multi-task feature learning},
	Volume = {73},
	Year = {2008}}

@misc{InferNET10,
	Author = {Minka, T. and Winn, J. and Guiver, J. and Knowles, D.},
	Note = {Microsoft Research Cambridge. http://research.microsoft.com/infernet},
	Title = {{Infer.NET 2.4}},
	Year = 2010}

@article{Wells:2001,
	Author = {Wells, M.},
	Journal = {Journal of American Statistical Association},
	Number = {453},
	Pages = {339-355},
	Title = {Generalized Linear Models: A {B}ayesian Perspective},
	Volume = {96},
	Year = {2001}}

@article{MacKay:1992,
	Address = {Cambridge, MA, USA},
	Author = {MacKay, D.},
	Issue = {3},
	Journal = {Neural Computation},
	Month = {May},
	Numpages = {25},
	Pages = {448--472},
	Publisher = {MIT Press},
	Title = {A practical {B}ayesian framework for backpropagation networks},
	Volume = {4},
	Year = {1992}}

@inproceedings{LimTeh:2007,
	Author = {Y. J. Lim and Y. W. Teh},
	Booktitle = {KDD Cup and Workshop},
	Title = {Variational {B}ayesian Approach to Movie Rating Prediction},
	Year = {2007}}

@article{PitmanYor:1997,
	Author = {Pitman, Jim and Yor, Marc},
	Journal = {The Annals of Probability},
	Number = {2},
	Pages = {855--900},
	Publisher = {Institute of Mathematical Statistics},
	Title = {The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator},
	Volume = {25},
	Year = {1997}}

@inproceedings{Adrian:2001,
	Annote = {EM},
	Author = {Corduneanu, A. and Bishop, C.},
	Booktitle = {International Conference on Artifical Intelligence and Statistics},
	Title = {Variational {B}ayesian Model Selection for Mixture Distributions},
	Year = {2001}}

@inproceedings{Zhu:2011,
	Author = {Jun Zhu and Ning Chen and Eric P. Xing},
	Booktitle = {NIPS},
	Title = {Infinite Latent {SVM} for Classification and Multi-task Learning},
	Year = {2011}}

@inproceedings{Archambeau:2011,
	Author = {C. Archambeau and S. Guo and O. Zoeter},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Sparse {B}ayesian Multi-Task Learning},
	Year = {2011}}

@inproceedings{Khan:2010,
	Author = {M. Khan and B. Marlin and G. Bouchard and K. Murphy},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Variational bounds for mixed-data factor analysis},
	Year = {2010}}

@article{Cappe:2007,
	Author = {Capp\'{e}, Olivier and Moulines, Eric},
	Journal = {Journal of the Royal Statistical Society - Series B: Statistical Methodology},
	Number = {3},
	Pages = {1--21},
	Title = {Online EM Algorithm for Latent Data Models},
	Volume = {71},
	Year = {2007}}

@article{Booth:1999,
	Author = {Booth, J. G. and Hobert, J. P.},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Keywords = {Confidence ellipsoid, Hastings--Metropolis algorithm, Importance sampling, Laplace approximation, Markov chain Monte Carlo method, Rejection sampling, Salamander data, Sandwich variance estimate},
	Number = {1},
	Pages = {265--285},
	Publisher = {Blackwell Publishers Ltd.},
	Title = {Maximizing generalized linear mixed model likelihoods with an automated Monte Carlo EM algorithm},
	Volume = {61},
	Year = {1999}}

@article{Kaban:2007,
	Address = {New York, NY, USA},
	Author = {Kab\'{a}n, Ata},
	Issue = {10},
	Journal = {Pattern Recogn. Lett.},
	Keywords = {Laplace prior, Microarray gene expressions, Predictive features, Shrinkage effect, Sparsity, Variational Bayes},
	Month = {July},
	Numpages = {12},
	Pages = {1271--1282},
	Publisher = {Elsevier Science Inc.},
	Title = {On Bayesian classification with Laplace priors},
	Volume = {28},
	Year = {2007}}

@article{Zhu:2009c,
	Author = {Jun Zhu and Eric P. Xing},
	Ee = {http://doi.acm.org/10.1145/1577069.1755871},
	Journal = {Journal of Machine Learning Research},
	Pages = {2531-2569},
	Title = {Maximum Entropy Discrimination Markov Networks},
	Volume = {10},
	Year = {2009}}

@article{Andrews:1974,
	Author = {Andrews, D. F. and Mallows, C. L.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {1},
	Pages = {99--102},
	Publisher = {Blackwell Publishing for the Royal Statistical Society},
	Title = {Scale Mixtures of Normal Distributions},
	Volume = {36},
	Year = {1974}}

@article{Cawley:2006,
	Author = {Cawley, G. C. and Talbot, N. L. C. and Girolami, M.},
	Editor = {Sch\"{o}lkopf, B. and Platt, J. C. and Hoffmann, T.},
	Journal = {Advances in Neural Information Processing Systems},
	Keywords = {l1, sparse},
	Title = {Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation},
	Volume = {19},
	Year = {2007}}

@inproceedings{Ghahramani:2000,
	Author = {Ghahramani, Zoubin and Beal, Matthew J.},
	Booktitle = {NIPS},
	Title = {Variational Inference for {B}ayesian Mixtures of Factor Analysers},
	Year = {2000}}

@article{Friston:2006,
	Author = {Friston, Karl and Mattout, J\'{e}r\'{e}mie and Trujillo-Barreto, Nelson and Ashburner, John and Penny, Will},
	Journal = {NeuroImage},
	Month = jan,
	Number = {1},
	Pages = {220--234},
	Title = {Variational free energy and the Laplace approximation.},
	Volume = {34},
	Year = {2006}}

@inproceedings{Wang:2004,
	Author = {Wang, Bo and Titterington, DM},
	Booktitle = {Proceedings of the 20th conference on Uncertainty in artificial intelligence},
	Pages = {577--584},
	Publisher = {AUAI Press},
	Title = {{Convergence and asymptotic normality of variational Bayesian approximations for exponential family models with missing values}},
	Year = {2004}}

@inproceedings{Wang:2011a,
	Author = {C. Wang and J. Paisley and D. Blei},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Title = {Online Variational Inference for the Hierarchical {D}irichlet Process},
	Year = {2011}}

@inproceedings{Zhou:2012,
	Author = {Zhou, M. and Hannah, L. and Dunson, D. and Carin, L.},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Title = {Beta Negative Binomial Process and Poisson Factor Analysis},
	Year = {2012}}

@inproceedings{Gerrish:2011,
	Author = {Sean M. Gerrish and David M. Blei},
	Booktitle = {International Conference on Machine Learning},
	Title = {Predicting Legislative Roll Calls from Text},
	Year = {2011}}

@inproceedings{EricWang:2010,
	Author = {Eric Wang and Dehong Liu and Jorge Silva and David Dunson and Lawrence Carin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Joint Analysis of Time-Evolving Binary Matrices and Associated Documents},
	Year = {2010}}

@techreport{Page:1999,
	Abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.},
	Author = {Lawrence Page and Sergey Brin and Rajeev Motwani and Terry Winograd},
	Institution = {Stanford InfoLab},
	Month = {November},
	Note = {Previous number = SIDL-WP-1999-0120},
	Number = {1999-66},
	Publisher = {Stanford InfoLab},
	Title = {The PageRank Citation Ranking: Bringing Order to the Web.},
	Type = {Technical Report},
	Url = {http://ilpubs.stanford.edu:8090/422/},
	Year = {1999},
	Bdsk-Url-1 = {http://ilpubs.stanford.edu:8090/422/}}

@inproceedings{Shan:2010,
	Author = {Shan, Hanhuai and Banerjee, Arindam},
	Booktitle = {IEEE International Conference on Data Mining},
	Title = {Generalized Probabilistic Matrix Factorizations for Collaborative Filtering},
	Year = {2010}}

@inproceedings{Wang:2011,
	Author = {Chong Wang and David M. Blei},
	Booktitle = {ACM International Conference on Knowledge Discovery and Data Mining (KDD)},
	Title = {Collaborative topic modeling for recommending scientific articles.},
	Year = {2011}}

@inproceedings{Xiong:2010,
	Author = {Liang Xiong and Xi Chen and Tzu-Kuo Huang and Jeff Schneider and Jaime G. Carbonell},
	Booktitle = {SIAM International Conference on Data Mining},
	Pages = {211--222},
	Title = {Temporal Collaborative Filtering with Bayesian Probabilistic Tensor Factorization},
	Year = {2010}}

@inproceedings{Koren:2009b,
	Acmid = {1557072},
	Address = {New York, NY, USA},
	Author = {Koren, Yehuda},
	Booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
	Doi = {http://doi.acm.org/10.1145/1557019.1557072},
	Isbn = {978-1-60558-495-9},
	Keywords = {collaborative filtering, concept drift, recommender systems},
	Location = {Paris, France},
	Numpages = {10},
	Pages = {447--456},
	Publisher = {ACM},
	Series = {KDD '09},
	Title = {Collaborative filtering with temporal dynamics},
	Url = {http://doi.acm.org/10.1145/1557019.1557072},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1557019.1557072}}

@inproceedings{Pan:2008,
	Author = {Pan, Rong and Zhou, Yunhong and Cao, Bin and Liu, Nathan N. and Lukose, Rajan and Scholz, Martin and Yang, Qiang},
	Booktitle = {IEEE International Conference on Data Mining},
	Title = {One-Class Collaborative Filtering},
	Year = {2008}}

@incollection{Bottou:2004,
	Address = {Berlin},
	Author = {Bottou, L\'{e}on},
	Booktitle = {Advanced Lectures on Machine Learning},
	Editor = {Bousquet, Olivier and von Luxburg, Ulrike},
	Pages = {146-168},
	Publisher = {Springer Verlag},
	Series = {Lecture Notes in Artificial Intelligence, LNAI~3176},
	Title = {Stochastic Learning},
	Year = {2004}}

@inproceedings{Agarwal:2010,
	Author = {Agarwal, Deepak and Chen, Bee-Chung},
	Booktitle = {ACM International Conference on Web Search and Data Mining},
	Title = {{fLDA}: matrix factorization through latent {D}irichlet allocation},
	Year = {2010}}

@inproceedings{Hensman:2013,
	Author = {Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
	Booktitle = {Conference on Uncertainty in Artificial Intelligence},
	Title = {Gaussian Processes for Big Data},
	Year = {2013}}

@inproceedings{Yu:2005,
	Address = {New York, NY, USA},
	Author = {Yu, Kai and Tresp, Volker and Schwaighofer, Anton},
	Booktitle = {Proceedings of the 22nd international conference on Machine learning},
	Pages = {1012--1019},
	Publisher = {ACM},
	Series = {ICML '05},
	Title = {Learning Gaussian processes from multiple tasks},
	Year = {2005}}

@inproceedings{Li:2010:,
	Address = {New York, NY, USA},
	Author = {Li, Yanen and Hu, Jia and Zhai, ChengXiang and Chen, Ye},
	Booktitle = {Proceedings of the 19th ACM international conference on Information and knowledge management},
	Keywords = {one-class collaborative filtering, recommender systems, rich user information},
	Location = {Toronto, ON, Canada},
	Pages = {959--968},
	Publisher = {ACM},
	Title = {Improving one-class collaborative filtering by incorporating rich user information},
	Year = {2010}}

@inproceedings{Ma:2010,
	Address = {New York, NY, USA},
	Author = {Hao Ma and Dengyong Zhou and Chao Liu and Michael R. Lyu and Irwin King},
	Booktitle = {Proceedings of the ACM 4th Conference on Web Search and Data Mining},
	Publisher = {ACM},
	Title = {Recommender Systems with Social Regularization},
	Year = {2011}}

@inproceedings{Mooney:2000,
	Author = {Mooney, Raymond J. and Roy, Loriene},
	Booktitle = {ACM Conference on Digital Libraries},
	Title = {Content-based book recommending using learning for text categorization},
	Year = {2000}}

@inproceedings{Herlocker:1999,
	Author = {Herlocker, Jonathan L. and Konstan, Joseph A. and Borchers, Al and Riedl, John},
	Booktitle = {ACM International Conference on Research and Development in Information Retrieval},
	Title = {An algorithmic framework for performing collaborative filtering},
	Year = {1999}}

@inproceedings{Melville:2002,
	Author = {Melville, P. and Mooney R. and Nagaraja, R.},
	Booktitle = {American Association for Artificial Intelligence},
	Title = {Content-Boosted Collaborative Filtering for Improved Recommendations},
	Year = {2002}}

@inproceedings{YuKai:2009,
	Author = {Yu, Kai and Lafferty, John and Zhu, Shenghuo and Gong, Yihong},
	Booktitle = {International Conference on Machine Learning},
	Title = {Large-scale collaborative prediction using a nonparametric random effects model},
	Year = {2009}}

@article{Koren:2009,
	Address = {Los Alamitos, CA, USA},
	Author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
	Doi = {http://dx.doi.org/10.1109/MC.2009.263},
	Issn = {0018-9162},
	Journal = {IEEE Computer},
	Number = {8},
	Pages = {30--37},
	Publisher = {IEEE Computer Society Press},
	Title = {Matrix Factorization Techniques for Recommender Systems},
	Volume = {42},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/MC.2009.263}}

@inproceedings{Hu:2008,
	Author = {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
	Booktitle = {IEEE International Conference on Data Mining},
	Title = {Collaborative Filtering for Implicit Feedback Datasets},
	Year = {2008}}

@inproceedings{Agarwal:Chen:2009,
	Author = {Agarwal, Deepak and Chen, Bee-Chung},
	Booktitle = {ACM International Conference on Knowledge Discovery and Data Mining},
	Title = {Regression-based latent factor models},
	Year = {2009}}

@techreport{Rodriguez:2010,
	Author = {Abel Rodriguez},
	Institution = {Department of Applied Mathematics and Statistics, University of California at Santa Cruz},
	Number = {UCSC-SOE-10-27},
	Title = {On-Line Learning for the Infinite Hidden {M}arkov Model},
	Year = {2010}}

@article{Sato:2001,
	Author = {M.A. Sato},
	Journal = {Neural Computation},
	Number = {7},
	Pages = {1649--1681},
	Title = {Online model selection based on the variational {B}ayes},
	Volume = {13},
	Year = {2001}}

@inproceedings{Hoffman:2010,
	Author = {M. Hoffman and D. Blei and F. Bach},
	Booktitle = {Neural Information Processing Systems},
	Title = {Online inference for latent {D}richlet allocation},
	Year = {2010}}

@inproceedings{Liang:2009b,
	Author = {P. Liang and D. Klein},
	Booktitle = {North American Association for Computational Linguistics (NAACL)},
	Title = {Online {EM} for Unsupervised Models},
	Year = {2009}}

@article{Chien:1967,
	Author = {Chien, Y. and Fu, K.},
	Journal = {Systems Science and Cybernetics, IEEE Transactions on},
	Month = {jun.},
	Number = {1},
	Pages = {28 -38},
	Title = {On {B}ayesian Learning and Stochastic Approximation},
	Volume = {3},
	Year = {1967}}

@article{Robbins:1951,
	Author = {H. Robbins and S. Monro},
	Journal = {The Annals of Mathematical Statistics},
	Number = {3},
	Pages = {pp. 400-407},
	Publisher = {Institute of Mathematical Statistics},
	Title = {A Stochastic Approximation Method},
	Volume = {22},
	Year = {1951}}

@techreport{Dahl:2003,
	Author = {David B. Dahl},
	Institution = {Department of Statistics, University of Wisconsin},
	Number = {1086},
	Title = {An improved merge-split sampler for conjugate {D}irichlet process mixture models},
	Year = {2003}}

@book{Nocedal:2006,
	Author = {J. Nocedal and S.J. Wright},
	Publisher = {Springer},
	Title = {Numerical Optimization, Second Edition},
	Year = {2006}}

@book{Moller:2004,
	Author = {Jesper Moller and Rasmus Plenge Waagepetersen},
	Howpublished = {Hardcover},
	Publisher = {Chapman and Hall/CRC},
	Title = {Statistical Inference and Simulation for Spatial Point Processes},
	Year = {2004}}

@article{Robert:1995,
	Author = {Robert, C. P.},
	Journal = {Statist. Comput.},
	Pages = {121--125},
	Title = {Simulation of truncated normal variables},
	Volume = {5},
	Year = {1995}}

@article{Jain:2007,
	Author = {Sonia Jain and Radford Neal},
	Journal = {Bayesian Analysis},
	Pages = {445--472},
	Title = {Splitting and merging components of a nonconjugate {D}irichlet process mixture model (with discussion)},
	Volume = {2},
	Year = {2007}}

@book{Rasmussen:2005,
	Author = {Rasmussen, Carl E. and Williams, Christopher K. I.},
	Publisher = {The MIT Press},
	Title = {Gaussian Processes for Machine Learning},
	Year = {2005}}

@inproceedings{Ranganath:2013,
	Author = {Rajesh Rangaanth and Chong Wang and David M. Blei and Eric P. Xing},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Title = {An adaptive learning rate for stochastic variational inference},
	Year = {2013}}

@book{Spall:2003,
	Author = {Spall, James},
	Publisher = {Wiley},
	Title = {Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control},
	Year = {2003}}

@inproceedings{Sudderth:2008,
	Author = {Erik B. Sudderth and Michael I. Jordan},
	Booktitle = {NIPS},
	Title = {Shared Segmentation of Natural Scenes Using Dependent {P}itman-{Y}or Processes},
	Year = {2008}}

@inproceedings{Williamson:2010,
	Author = {Sinead Williamson and Peter Orbanz and Zoubin Ghahramani},
	Booktitle = {AISTATS},
	Title = {Dependent {I}ndian Buffut Processes},
	Year = {2010}}

@inproceedings{Williamson:2010b,
	Author = {Williamson, Sinead and Wang, Chong and Heller, Katherine A and Blei, David M},
	Booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
	Pages = {1151--1158},
	Title = {The IBP compound Dirichlet process and its application to focused topic modeling},
	Year = {2010}}

@inproceedings{Cohen:2010,
	Author = {S. Cohen and D. Blei and N. Smith},
	Booktitle = {North American Chapter of the Association for Computational Linguistics},
	Title = {Variational Inference for Adaptor Grammars},
	Year = {2010}}

@techreport{Buntine:2009,
	Author = {Wray Buntine},
	Institution = {NICTA and Australian National University},
	Month = {July},
	Number = {NICTA-SML-09-001},
	Title = {Estimating Likelihoods for Topic Models},
	Year = {2009}}

@inproceedings{Hannah:2010,
	Author = {Hannah, L. and Blei, D. and Powell, W.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Dirichlet process mixtures of generalized linear models},
	Year = {2010}}

@inproceedings{Lorbert:2010,
	Author = {Lorbert, A. and Eis, D. and Kostina, V. and Blei, D. and Ramadge, P.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Exploiting Covariate Similarity in Sparse Regression via the Pairwise Elastic Net},
	Year = {2010}}

@article{Gelman:2009a,
	Author = {Gelman, A.},
	Title = {Bayesian Statistics: {T}hen and now},
	Year = {2009}}

@article{White:1982,
	Author = {H. White},
	Journal = {Econometrica},
	Number = {1},
	Pages = {1-25},
	Title = {Maximum Likelihood Estimation of Misspecified Models},
	Volume = {50},
	Year = {1982}}

@article{Gelman:2010,
	Author = {Gelman, A.},
	Journal = {American Journal of Sociology},
	Title = {Causaility and Statistical Learning},
	Year = {2010}}

@article{Lenk:1988,
	Author = {Lenk, P.},
	Journal = {Journal of the American Statistical Association},
	Number = {402},
	Pages = {509--516},
	Title = {The logistic normal distribution for {B}ayesian, nonparametric, predictive densities},
	Volume = {83},
	Year = {1988}}

@book{Kingman:1993,
	Author = {Kingman, J.},
	Publisher = {Oxford University Press, USA},
	Title = {Poisson Processes},
	Year = {1993}}

@book{Bickel:2007,
	Address = {Upper Saddle River, NJ},
	Author = {Bickel, P. and Doksum, K.},
	Edition = {2nd},
	Publisher = {Pearson Prentice Hall},
	Title = {Mathematical Statistics: {B}asic Ideas and Selected Topics},
	Volume = {1},
	Year = 2007}

@inbook{Jordan:2010,
	Author = {Jordan, M.},
	Title = {Hierarchical Models, Nested Models, and Completely Random Measures},
	Year = {2010}}

@article{Flaherty:2005,
	Author = {P. Flaherty and G. Giaever and J. Kumm and M. Jordan and A. Arkin},
	Journal = {Bioinformatics},
	Number = {15},
	Pages = {3286--3293},
	Title = {A latent variable model for chemogenomic profiling},
	Volume = {21},
	Year = {2005}}

@conference{Wallach:2009a,
	Author = {Wallach, H. and Murray, I. and Salakhutdinov, R. and Mimno, D.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Title = {Evaluation methods for topic models},
	Year = {2009}}

@article{Kelly:2004,
	Author = {Kelly, D. and Diaz, F. and Belkin, N.J. and Allan, J.},
	Journal = {Lecture Notes in Computer Science},
	Pages = {27--41},
	Title = {A user-centered approach to evaluating topic models},
	Volume = {2997},
	Year = {2004}}

@article{Kim:1999,
	Author = {Kim, Y.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {562--588},
	Title = {Nonparametric {B}ayesian estimators for counting processes},
	Volume = {27},
	Year = {1999}}

@article{Walker:1997,
	Author = {Walker, S.G. and Mallick, B.K.},
	Journal = {The Canadian Journal of Statistics/La Revue Canadienne de Statistique},
	Number = {4},
	Pages = {473--479},
	Title = {A note on the scale parameter of the Dirichlet process},
	Volume = {25},
	Year = {1997}}

@article{Muliere:1998,
	Author = {Muliere, P. and Walker, S.},
	Journal = {Journal of the Royal Statistical Society. Series B, Statistical Methodology},
	Pages = {175--182},
	Title = {Extending the family of Bayesian bootstraps and exchangeable urn schemes},
	Year = {1998}}

@article{Walker:1997a,
	Author = {Walker, S. and Muliere, P.},
	Journal = {The Annals of Statistics},
	Number = {4},
	Pages = {1762--1780},
	Title = {Beta-Stacy processes and a generalization of the P{\'o}lya-urn scheme},
	Volume = {25},
	Year = {1997}}

@article{Muliere:1998a,
	Author = {Muliere, Pietro and Walker, Stephen},
	Journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	Number = {1},
	Pages = {175--182},
	Title = {Extending the Family of Bayesian Bootstraps and Exchangeable Urn Schemes},
	Volume = {60},
	Year = {1998}}

@article{Adams:2010,
	Author = {Ryan Prescott Adams and Hanna M. Wallach and Zoubin Ghahramani},
	Month = {01},
	Title = {Learning the Structure of Deep Sparse Graphical Models},
	Year = {2010}}

@article{Murray:2010,
	Author = {Iain Murray and Ryan Prescott Adams and David J.C. MacKay},
	Month = {01},
	Title = {Elliptical Slice Sampling},
	Year = {2010}}

@article{Nguyen:2010,
	Author = {XuanLong Nguyen},
	Month = {01},
	Title = {Graphically dependent and spatially varying Dirichlet process mixtures},
	Year = {2010}}

@phdthesis{Frazier:2009,
	Author = {Frazier, P.},
	School = {Princeton University},
	Title = {Knowledge-Gradient Methods for Statistical Learning},
	Year = {2009}}

@inproceedings{Zhu:2009b,
	Address = {New York, NY, USA},
	Author = {Zhu, Jun and Ahmed, Amr and Xing, Eric P.},
	Booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	Pages = {1257--1264},
	Publisher = {ACM},
	Series = {ICML '09},
	Title = {MedLDA: maximum margin supervised topic models for regression and classification},
	Year = {2009}}

@article{Adams:2009,
	Author = {Ryan Prescott Adams and Iain Murray and David J.C. MacKay},
	Month = {12},
	Title = {Nonparametric Bayesian Density Modeling with Gaussian Processes},
	Year = {2009}}

@article{Robert:1998,
	Author = {Robert, Christian P. and Titterington, D. M.},
	Journal = {Statistics and Computing},
	Number = {2},
	Pages = {145--158},
	Title = {Reparameterization strategies for hidden {M}arkov models and {B}ayesian approaches to maximum likelihood estimation},
	Volume = {8},
	Year = {1998}}

@conference{Doshi-Velez:2009b,
	Author = {Doshi-Velez, F. and Miller, K.T. and Van Gael, J. and Teh, Y.W.},
	Booktitle = {Proceedings of the Intl. Conf. on Artificial Intelligence and Statistics},
	Pages = {137--144},
	Title = {Variational inference for the {I}ndian buffet process},
	Year = {2009}}

@article{Berger:1996,
	Author = {Berger, J.O. and Pericchi, L.R.},
	Journal = {Journal of the American Statistical Association},
	Number = {433},
	Pages = {109--122},
	Title = {The intrinsic {B}ayes factor for model selection and prediction},
	Volume = {91},
	Year = {1996}}

@article{Berger:1992,
	Author = {Berger, J.O. and Bernardo, J.M.},
	Journal = {Bayesian statistics},
	Pages = {35--60},
	Title = {On the development of reference priors},
	Volume = {4},
	Year = {1992}}

@conference{Salakhutdinov:2008,
	Author = {Salakhutdinov, R. and Mnih, A.},
	Booktitle = {International Conference on Machine learning},
	Title = {Bayesian probabilistic matrix factorization using {M}arkov chain {M}onte {C}arlo},
	Year = {2008}}

@inproceedings{Salakhutdinov:2008a,
	Author = {Salakhutdinov, R. and Mnih, A.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Probabilistic matrix factorization},
	Year = {2008}}

@article{Ratmann:2009,
	Author = {Ratmann, O. and Andrieu, C. and Wiuf, C. and Richardson, S.},
	Journal = {Proceedings of the National Academy of Sciences},
	Number = {26},
	Pages = {10576},
	Title = {Model criticism based on likelihood-free inference, with an application to protein network evolution},
	Volume = {106},
	Year = {2009}}

@article{Steinbakk:2009,
	Author = {Steinbakk, G.H. and Storvik, G.O. and L{\o}land, A. and Aldrin, M. and H{\\"o}gnad{\'o}ttir Steinbakk, G. and Bang Huseby, R. and L{\o}land, A. and Steinbakk, G.H. and Aldrin, M. and Steinbakk, G.H. and others},
	Journal = {Scandinavian Journal of Statistics},
	Pages = {10},
	Title = {Posterior predictive p-values in {B}ayesian Hierarchical models},
	Volume = {36},
	Year = {2009}}

@article{Hjort:2006,
	Author = {Hjort, N. and Dahl, F.A. and Steinbakk, G.H.},
	Journal = {Journal of the American Statistical Association},
	Number = {475},
	Pages = {1157--1174},
	Title = {Post-processing posterior predictive p values},
	Volume = {101},
	Year = {2006}}

@article{Gneiting:2007,
	Author = {Gneiting, T. and Balabdaoui, F. and Raftery, A.E.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Number = {2},
	Pages = {243},
	Title = {Probabilistic forecasts, calibration and sharpness},
	Volume = {69},
	Year = {2007}}

@incollection{Kim:2009,
	Author = {Gunhee Kim and Antonio Torralba},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {961--969},
	Title = {Unsupervised Detection of Regions of Interest Using Iterative Link Analysis},
	Year = {2009}}

@incollection{Hutter:2009,
	Author = {Marcus Hutter},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {817--825},
	Title = {Discrete MDL Predicts in Total Variation},
	Year = {2009}}

@incollection{Boutsidis:2009,
	Author = {Christos Boutsidis and Michael Mahoney and Petros Drineas},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {153--161},
	Title = {Unsupervised Feature Selection for the $k$-means Clustering Problem},
	Year = {2009}}

@incollection{Honorio:2009,
	Author = {Jean Honorio and Luis Ortiz and Dimitris Samaras and Nikos Paragios and Rita Goldstein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {745--753},
	Title = {Sparse and Locally Constant Gaussian Graphical Models},
	Year = {2009}}

@incollection{Yang:2009,
	Author = {Zhi Yang and Qi Zhao and Edward Keefer and Wentai Liu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2160--2168},
	Title = {Noise Characterization, Modeling, and Reduction for In Vivo Neural Recording},
	Year = {2009}}

@incollection{Zheng:2009,
	Author = {Wenming Zheng and Zhouchen Lin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2268--2276},
	Title = {Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification},
	Year = {2009}}

@incollection{Carbonetto:2009,
	Author = {Peter Carbonetto and Matthew King and Firas Hamze},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {216--224},
	Title = {A Stochastic approximation method for inference in probabilistic graphical models},
	Year = {2009}}

@incollection{Lucke:2009,
	Author = {J\"{o}rg L\"{u}cke and Richard Turner and Maneesh Sahani and Marc Henniges},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1069--1077},
	Title = {Occlusive Components Analysis},
	Year = {2009}}

@incollection{Yang:2009a,
	Author = {Shuang-Hong Yang and Hongyuan Zha and Bao-gang Hu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2143--2150},
	Title = {Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora},
	Year = {2009}}

@incollection{Yu:2009,
	Author = {Yao-Liang Yu and Yuxi Li and Dale Schuurmans and Csaba Szepesvari},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2232--2240},
	Title = {A General Projection Property for Distribution Families},
	Year = {2009}}

@incollection{Chai:2009,
	Author = {Kian Ming Chai},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {279--287},
	Title = {Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes},
	Year = {2009}}

@incollection{Turaga:2009,
	Author = {Srinivas Turaga and Kevin Briggman and Moritz Helmstaedter and Winfried Denk and Sebastian Seung},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1865--1873},
	Title = {Maximin affinity learning of image segmentation},
	Year = {2009}}

@incollection{Malisiewicz:2009,
	Author = {Tomasz Malisiewicz and Alyosha Efros},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1222--1230},
	Title = {Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships},
	Year = {2009}}

@incollection{Vedaldi:2009,
	Author = {Andrea Vedaldi and Andrew Zisserman},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1928--1936},
	Title = {Structured output regression for detection with partial truncation},
	Year = {2009}}

@incollection{Sollich:2009,
	Author = {Peter Sollich and Matthew Urry and Camille Coti},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1723--1731},
	Title = {Kernels and learning curves for Gaussian process regression on random graphs},
	Year = {2009}}

@incollection{Whitehill:2009,
	Author = {Jacob Whitehill and Paul Ruvolo and Ting-fan Wu and Jacob Bergsma and Javier Movellan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2035--2043},
	Title = {Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise},
	Year = {2009}}

@incollection{Wright:2009,
	Author = {John Wright and Arvind Ganesh and Shankar Rao and Yigang Peng and Yi Ma},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2080--2088},
	Title = {Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization},
	Year = {2009}}

@incollection{Petrik:2009,
	Author = {Marek Petrik and Shlomo Zilberstein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1446--1454},
	Title = {Robust Value Function Approximation Using Bilinear Programming},
	Year = {2009}}

@incollection{Dalalyan:2009,
	Author = {Arnak Dalalyan and Renaud Keriven},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {441--449},
	Title = {$L_1$-Penalized Robust Estimation for a Class of Inverse Problems Arising in Multiview Geometry},
	Year = {2009}}

@incollection{Ying:2009,
	Author = {Yiming Ying and Colin Campbell and Mark Girolami},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2205--2213},
	Title = {Analysis of SVM with Indefinite Kernels},
	Year = {2009}}

@incollection{Zhao:2009,
	Author = {Peilin Zhao and Steven Chu-Hong Hoi and Rong Jin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2259--2267},
	Title = {DUOL: A Double Updating Approach for Online Learning},
	Year = {2009}}

@incollection{Fidler:2009,
	Author = {Sanja Fidler and Marko Boben and Ales Leonardis},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {531--539},
	Title = {Evaluating multi-class learning strategies in a generative hierarchical framework for object detection},
	Year = {2009}}

@incollection{Berkes:2009,
	Author = {Pietro Berkes and Ben White and Jozsef Fiser},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {108--116},
	Title = {No evidence for active sparsification in the visual cortex},
	Year = {2009}}

@incollection{Raginsky:2009,
	Author = {Maxim Raginsky and Svetlana Lazebnik},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1509--1517},
	Title = {Locality-sensitive binary codes from shift-invariant kernels},
	Year = {2009}}

@incollection{Xiang:2009,
	Author = {Zhen Xiang and Yongxin Xi and Uri Hasson and Peter Ramadge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2107--2115},
	Title = {Boosting with Spatial Regularization},
	Year = {2009}}

@incollection{Zhu:2009,
	Author = {Long Zhu and Yuanahao Chen and Bill Freeman and Antonio Torralba},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2313--2321},
	Title = {Nonparametric Bayesian Texture Learning and Synthesis},
	Year = {2009}}

@incollection{Hsu:2009,
	Author = {Daniel Hsu and Sham Kakade and John Langford and Tong Zhang},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {772--780},
	Title = {Multi-Label Prediction via Compressed Sensing},
	Year = {2009}}

@incollection{Kemp:2009,
	Author = {Charles Kemp},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {943--951},
	Title = {Quantification and the language of thought},
	Year = {2009}}

@incollection{Kemp:2009a,
	Author = {Charles Kemp and Alan Jern and Fei Xu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {925--933},
	Title = {Individuation, Identification and Object Discovery},
	Year = {2009}}

@incollection{Kemp:2009b,
	Author = {Charles Kemp and Alan Jern},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {934--942},
	Title = {Abstraction and Relational learning},
	Year = {2009}}

@incollection{Kapoor:2009,
	Author = {Ashish Kapoor and Eric Horvitz},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {898--906},
	Title = {Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition},
	Year = {2009}}

@incollection{Jung:2009,
	Author = {Kyomin Jung and Pushmeet Kohli and Devavrat Shah},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {871--879},
	Title = {Local Rules for Global MAP: When Do They Work ?},
	Year = {2009}}

@incollection{Bush:2009,
	Author = {Keith Bush and Joelle Pineau},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {189--197},
	Title = {Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability},
	Year = {2009}}

@incollection{Zhou:2009,
	Author = {Mingyuan Zhou and Haojun Chen and John Paisley and Lu Ren and Guillermo Sapiro and Lawrence Carin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2295--2303},
	Title = {Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations},
	Year = {2009}}

@incollection{Petterson:2009,
	Author = {James Petterson and Tiberio Caetano and Julian McAuley and Jin Yu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1455--1463},
	Title = {Exponential Family Graph Matching and Ranking},
	Year = {2009}}

@incollection{Li:2009,
	Author = {Wu-Jun Li and Dit-Yan Yeung and Zhihua Zhang},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1123--1131},
	Title = {Probabilistic Relational PCA},
	Year = {2009}}

@incollection{Wang:2009d,
	Author = {Liwei Wang},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1999--2007},
	Title = {Sufficient Conditions for Agnostic Active Learnable},
	Year = {2009}}

@incollection{Legenstein:2009,
	Author = {Robert Legenstein and Steven Chase and Andrew Schwartz and Wolfgang Maass},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1105--1113},
	Title = {Functional network reorganization in motor cortex can be explained by reward-modulated Hebbian learning},
	Year = {2009}}

@inproceedings{Wang:2009e,
	Author = {Chong Wang and David Blei},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Variational Inference for the Nested {C}hinese Restaurant Process},
	Year = {2009}}

@incollection{Wang:2009f,
	Author = {Chong Wang and David Blei},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1982--1989},
	Title = {Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process},
	Year = {2009}}

@incollection{Sinz:2009,
	Author = {Fabian Sinz and Eero Simoncelli and Matthias Bethge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1696--1704},
	Title = {Hierarchical Modeling of Local Image Features through $L_p$-Nested Symmetric Distributions},
	Year = {2009}}

@incollection{Vanhatalo:2009,
	Author = {Jarno Vanhatalo and Pasi Jyl\"{a}nki and Aki Vehtari},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1910--1918},
	Title = {Gaussian process regression with Student-t likelihood},
	Year = {2009}}

@incollection{Brasselet:2009,
	Author = {Romain Brasselet and Roland Johansson and Angelo Arleo},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {180--188},
	Title = {Optimal context separation of spiking haptic signals by second-order somatosensory neurons},
	Year = {2009}}

@incollection{Gerwinn:2009,
	Author = {Sebastian Gerwinn and Philipp Berens and Matthias Bethge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {620--628},
	Title = {A joint maximum-entropy model for binary neural population patterns and continuous signals},
	Year = {2009}}

@incollection{Duchi:2009,
	Author = {John Duchi and Yoram Singer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {495--503},
	Title = {Efficient Learning using Forward-Backward Splitting},
	Year = {2009}}

@article{Duchi:2011,
	Acmid = {2021068},
	Author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	Issn = {1532-4435},
	Issue_Date = {2/1/2011},
	Journal = {J. Mach. Learn. Res.},
	Month = jul,
	Numpages = {39},
	Pages = {2121--2159},
	Publisher = {JMLR.org},
	Title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	Url = {http://dl.acm.org/citation.cfm?id=1953048.2021068},
	Volume = {12},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1953048.2021068}}

@incollection{Berens:2009,
	Author = {Philipp Berens and Sebastian Gerwinn and Alexander Ecker and Matthias Bethge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {90--98},
	Title = {Neurometric function analysis of population codes},
	Year = {2009}}

@incollection{Yao:2009,
	Author = {Hengshuai Yao and Rich Sutton and Shalabh Bhatnagar and Dongcui Diao and Csaba Szepesvari},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2187--2195},
	Title = {Multi-Step Dyna Planning for Policy Evaluation and Control},
	Year = {2009}}

@incollection{Cayton:2009,
	Author = {Lawrence Cayton},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {243--251},
	Title = {Efficient Bregman Range Search},
	Year = {2009}}

@incollection{Zhu:2009a,
	Author = {Xiaojin Zhu and Timothy Rogers and Bryan Gibson},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2322--2330},
	Title = {Human Rademacher Complexity},
	Year = {2009}}

@incollection{Iwata:2009,
	Author = {Tomoharu Iwata and Takeshi Yamada and Naonori Ueda},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {835--843},
	Title = {Modeling Social Annotation Data with Content Relevance using a Topic Model},
	Year = {2009}}

@incollection{Coquelin:2009,
	Author = {Pierre-Arnaud Coquelin and Romain Deguest and Remi Munos},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {387--395},
	Title = {Sensitivity analysis in HMMs with application to likelihood maximization},
	Year = {2009}}

@incollection{Goldberger:2009,
	Author = {Jacob Goldberger and Amir Leshem},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {638--645},
	Title = {A Gaussian Tree Approximation for Integer Least-Squares},
	Year = {2009}}

@incollection{Arlot:2009,
	Author = {Sylvain Arlot and Francis Bach},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {46--54},
	Title = {Data-driven calibration of linear estimators with minimal penalties},
	Year = {2009}}

@incollection{Macke:2009,
	Author = {Jakob Macke and Sebastian Gerwinn and Leonard White and Matthias Kaschube and Matthias Bethge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1195--1203},
	Title = {Bayesian estimation of orientation preference maps},
	Year = {2009}}

@incollection{Ye:2009,
	Author = {Nan Ye and Wee Sun Lee and Hai Leong Chieu and Dan Wu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2196--2204},
	Title = {Conditional Random Fields with High-Order Features for Sequence Labeling},
	Year = {2009}}

@incollection{Ying:2009a,
	Author = {Yiming Ying and Kaizhu Huang and Colin Campbell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2214--2222},
	Title = {Sparse Metric Learning via Smooth Optimization},
	Year = {2009}}

@incollection{Jin:2009,
	Author = {Rong Jin and Shijun Wang and Yang Zhou},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {862--870},
	Title = {Regularized Distance Metric Learning:Theory and Algorithm},
	Year = {2009}}

@incollection{Margaritis:2009,
	Author = {Dimitris Margaritis},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1240--1248},
	Title = {Toward Provably Correct Feature Selection in Arbitrary Domains},
	Year = {2009}}

@incollection{Wu:2009,
	Author = {Lei Wu and Rong Jin and Steven Chu-Hong Hoi and Jianke Zhu and Nenghai Yu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2089--2097},
	Title = {Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering},
	Year = {2009}}

@incollection{Clemencon:2009,
	Author = {St\'{e}phan Cl\'{e}men\c{c}on and Nicolas Vayatis and Marine Depecker},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {360--368},
	Title = {AUC optimization and the two-sample problem},
	Year = {2009}}

@incollection{Krishnan:2009,
	Author = {Dilip Krishnan and Rob Fergus},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1033--1041},
	Title = {Fast Image Deconvolution using Hyper-Laplacian Priors},
	Year = {2009}}

@incollection{Valizadegan:2009,
	Author = {Hamed Valizadegan and Rong Jin and Ruofei Zhang and Jianchang Mao},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1883--1891},
	Title = {Learning to Rank by Optimizing NDCG Measure},
	Year = {2009}}

@incollection{Mann:2009,
	Author = {Gideon Mann and Ryan McDonald and Mehryar Mohri and Nathan Silberman and Dan Walker},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1231--1239},
	Title = {Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models},
	Year = {2009}}

@incollection{Kalai:2009,
	Author = {Adam Kalai and Varun Kanade},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {880--888},
	Title = {Potential-Based Agnostic Boosting},
	Year = {2009}}

@incollection{Socher:2009a,
	Author = {Richard Socher and Samuel Gershman and Adler Perotte and Per Sederberg and David Blei and Kenneth Norman},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1714--1722},
	Title = {A Bayesian Analysis of Dynamics in Free Recall},
	Year = {2009}}

@incollection{Schmidt:2009,
	Author = {Mikkel Schmidt},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1624--1632},
	Title = {Linearly constrained Bayesian matrix factorization for blind source separation},
	Year = {2009}}

@incollection{Arora:2009,
	Author = {Raman Arora},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {55--63},
	Title = {On Learning Rotations},
	Year = {2009}}

@incollection{Keshavan:2009,
	Author = {Raghunandan Keshavan and Andrea Montanari and Sewoong Oh},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {952--960},
	Title = {Matrix Completion from Noisy Entries},
	Year = {2009}}

@incollection{Gerven:2009,
	Author = {Marcel Van Gerven and Botond Cseke and Robert Oostenveld and Tom Heskes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1901--1909},
	Title = {Bayesian Source Localization with the Multivariate Laplace Prior},
	Year = {2009}}

@incollection{Lanctot:2009,
	Author = {Marc Lanctot and Kevin Waugh and Martin Zinkevich and Michael Bowling},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1078--1086},
	Title = {Monte Carlo Sampling for Regret Minimization in Extensive Games},
	Year = {2009}}

@incollection{Campbell:2009,
	Author = {William Campbell and Zahi Karam and Douglas Sturim},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {207--215},
	Title = {Speaker Comparison with Inner Product Discriminant Functions},
	Year = {2009}}

@incollection{Kao:2009,
	Author = {Yi-hao Kao and Benjamin Van Roy and Xiang Yan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {889--897},
	Title = {Directed Regression},
	Year = {2009}}

@incollection{Shani:2009,
	Author = {Guy Shani and Christopher Meek},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1642--1650},
	Title = {Improving Existing Fault Recovery Policies},
	Year = {2009}}

@incollection{Palatucci:2009,
	Author = {Mark Palatucci and Dean Pomerleau and Geoffrey Hinton and Tom Mitchell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1410--1418},
	Title = {Zero-shot Learning with Semantic Output Codes},
	Year = {2009}}

@incollection{Fritz:2009,
	Author = {Mario Fritz and Michael Black and Gary Bradski and Sergey Karayev and Trevor Darrell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {558--566},
	Title = {An Additive Latent Feature Model for Transparent Object Recognition},
	Year = {2009}}

@incollection{Watanabe:2009,
	Author = {Yusuke Watanabe and Kenji Fukumizu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2017--2025},
	Title = {Graph Zeta Function in the Bethe Free Energy and Loopy Belief Propagation},
	Year = {2009}}

@incollection{Streeter:2009,
	Author = {Matthew Streeter and Daniel Golovin and Andreas Krause},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1794--1802},
	Title = {Online Learning of Assignments},
	Year = {2009}}

@incollection{Du:2009,
	Author = {Lan Du and Lu Ren and David Dunson and Lawrence Carin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {486--494},
	Title = {A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation},
	Year = {2009}}

@incollection{Kumar:2009,
	Author = {Sanjiv Kumar and Mehryar Mohri and Ameet Talwalkar},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1060--1068},
	Title = {Ensemble Nystrom Method},
	Year = {2009}}

@incollection{Ram:2009,
	Author = {Parikshit Ram and Dongryeol Lee and Hua Ouyang and Alexander Gray},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1536--1544},
	Title = {Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions},
	Year = {2009}}

@incollection{Ram:2009a,
	Author = {Parikshit Ram and Dongryeol Lee and William March and Alexander Gray},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1527--1535},
	Title = {Linear-time Algorithms for Pairwise Statistical Problems},
	Year = {2009}}

@incollection{Fergus:2009,
	Author = {Rob Fergus and Yair Weiss and Antonio Torralba},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {522--530},
	Title = {Semi-Supervised Learning in Gigantic Image Collections},
	Year = {2009}}

@incollection{Singh-Miller:2009,
	Author = {Natasha Singh-Miller and Michael Collins},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1678--1686},
	Title = {Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition},
	Year = {2009}}

@incollection{Germain:2009,
	Author = {Pascal Germain and Alexandre Lacasse and Francois Laviolette and Mario Marchand and Sara Shanian},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {603--610},
	Title = {From PAC-Bayes Bounds to KL Regularization},
	Year = {2009}}

@incollection{Farias:2009,
	Author = {Vivek Farias and Srikanth Jagabathula and Devavrat Shah},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {504--512},
	Title = {A Data-Driven Approach to Modeling Choice},
	Year = {2009}}

@incollection{Goodfellow:2009,
	Author = {Ian Goodfellow and Quoc Le and Andrew Saxe and Andrew Ng},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {646--654},
	Title = {Measuring Invariances in Deep Networks},
	Year = {2009}}

@incollection{Teh:2009,
	Author = {Yee Whye Teh and Dilan Gorur},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1838--1846},
	Title = {Indian Buffet Processes with Power-law Behavior},
	Year = {2009}}

@incollection{Nadler:2009,
	Author = {Boaz Nadler and Nathan Srebro and Xueyuan Zhou},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1330--1338},
	Title = {Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data},
	Year = {2009}}

@incollection{Hazan:2009,
	Author = {Elad Hazan and Satyen Kale},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {709--717},
	Title = {On Stochastic and Worst-case Models for Investing},
	Year = {2009}}

@incollection{Hazan:2009a,
	Author = {Elad Hazan and Satyen Kale},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {700--708},
	Title = {Beyond Convexity: Online Submodular Minimization},
	Year = {2009}}

@incollection{Bian:2009,
	Author = {Wei Bian and Dacheng Tao},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {117--125},
	Title = {Manifold Regularization for SIR with Rate Root-n Convergence},
	Year = {2009}}

@incollection{Chen:2009,
	Author = {Wei Chen and Tie-Yan Liu and Yanyan Lan and Zhi-Ming Ma and Hang Li},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {315--323},
	Title = {Ranking Measures and Loss Functions in Learning to Rank},
	Year = {2009}}

@incollection{Chin:2009,
	Author = {Tat-Jun Chin and Hanzi Wang and David Suter},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {333--341},
	Title = {The Ordered Residual Kernel for Robust Motion Subspace Clustering},
	Year = {2009}}

@incollection{Veness:2009,
	Author = {Joel Veness and David Silver and William Uther and Alan Blair},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1937--1945},
	Title = {Bootstrapping from Game Tree Search},
	Year = {2009}}

@incollection{Pillow:2009,
	Author = {Jonathan Pillow},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1473--1481},
	Title = {Time-rescaling methods for the estimation and assessment of non-Poisson neural encoding models},
	Year = {2009}}

@incollection{Doshi-Velez:2009,
	Author = {Finale Doshi-Velez},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {477--485},
	Title = {The Infinite Partially Observable Markov Decision Process},
	Year = {2009}}

@incollection{Ouyang:2009,
	Author = {Tom Ouyang and Randall Davis},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1401--1409},
	Title = {Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition},
	Year = {2009}}

@incollection{Quadrianto:2009,
	Author = {Novi Quadrianto and James Petterson and Alex Smola},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1500--1508},
	Title = {Distribution Matching for Transduction},
	Year = {2009}}

@incollection{Xia:2009,
	Author = {Fen Xia and Tie-Yan Liu and Hang Li},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2098--2106},
	Title = {Statistical Consistency of Top-k Ranking},
	Year = {2009}}

@incollection{Zoran:2009,
	Author = {Daniel Zoran and Yair Weiss},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2340--2348},
	Title = {The "tree-dependent components" of natural scenes are edge filters},
	Year = {2009}}

@incollection{Shervashidze:2009,
	Author = {Nino Shervashidze and Karsten Borgwardt},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1660--1668},
	Title = {Fast subtree kernels on graphs},
	Year = {2009}}

@incollection{Bruckner:2009,
	Author = {Michael Br\"{u}ckner and Tobias Scheffer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {171--179},
	Title = {Nash Equilibria of Static Prediction Games},
	Year = {2009}}

@incollection{Lazaro-Gredilla:2009,
	Author = {Miguel Lazaro-Gredilla and Anibal Figueiras-Vidal},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1087--1095},
	Title = {Inter-domain Gaussian Processes for Sparse Inference using Inducing Features},
	Year = {2009}}

@incollection{Kolar:2009,
	Author = {Mladen Kolar and Le Song and Eric Xing},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1006--1014},
	Title = {Sparsistent Learning of Varying-coefficient Models with Structural Changes},
	Year = {2009}}

@incollection{Yan:2009,
	Author = {Feng Yan and Ningyi Xu and Yuan Qi},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2134--2142},
	Title = {Parallel Inference for Latent {D}irichlet Allocation on Graphics Processing Units},
	Year = {2009}}

@incollection{Chen:2009a,
	Author = {Ye Chen and Michael Kapralov and Dmitry Pavlov and John Canny},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {324--332},
	Title = {Factor Modeling for Advertisement Targeting},
	Year = {2009}}

@incollection{Caron:2009,
	Author = {Francois Caron and Arnaud Doucet},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {225--233},
	Title = {Bayesian Nonparametric Models on Decomposable Graphs},
	Year = {2009}}

@incollection{Yao:2009a,
	Author = {Bangpeng Yao and Dirk Walther and Diane Beck and Li Fei-Fei},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2178--2186},
	Title = {Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions},
	Year = {2009}}

@incollection{Karasuyama:2009,
	Author = {Masayuki Karasuyama and Ichiro Takeuchi},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {907--915},
	Title = {Multiple Incremental Decremental Learning of Support Vector Machines},
	Year = {2009}}

@incollection{Gould:2009,
	Author = {Stephen Gould and Tianshi Gao and Daphne Koller},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {655--663},
	Title = {Region-based Segmentation and Object Detection},
	Year = {2009}}

@incollection{Kawahara:2009,
	Author = {Yoshinobu Kawahara and Kiyohito Nagano and Koji Tsuda and Jeff Bilmes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {916--924},
	Title = {Submodularity Cuts and Applications},
	Year = {2009}}

@incollection{Sprekeler:2009,
	Author = {Henning Sprekeler and Guillaume Hennequin and Wulfram Gerstner},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1741--1749},
	Title = {Code-specific policy gradient rules for spiking neurons},
	Year = {2009}}

@incollection{Klampfl:2009,
	Author = {Stefan Klampfl and Wolfgang Maass},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {988--996},
	Title = {Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks},
	Year = {2009}}

@incollection{Jern:2009,
	Author = {Alan Jern and Kai-min Chang and Charles Kemp},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {853--861},
	Title = {Bayesian Belief Polarization},
	Year = {2009}}

@incollection{Jagarlapudi:2009,
	Author = {Saketha Nath Jagarlapudi and Dinesh G and Raman S and Chiranjib Bhattacharyya and Aharon Ben-Tal and Ramakrishnan K.R.},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {844--852},
	Title = {On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation},
	Year = {2009}}

@incollection{Zhao:2009a,
	Author = {Manqi Zhao and Venkatesh Saligrama},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2250--2258},
	Title = {Anomaly Detection with Score functions based on Nearest Neighbor Graphs},
	Year = {2009}}

@incollection{Gao:2009,
	Author = {Jing Gao and Feng Liang and Wei Fan and Yizhou Sun and Jiawei Han},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {585--593},
	Title = {Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models},
	Year = {2009}}

@incollection{Crammer:2009,
	Author = {Koby Crammer and Alex Kulesza and Mark Dredze},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {414--422},
	Title = {Adaptive Regularization of Weight Vectors},
	Year = {2009}}

@incollection{Durme:2009,
	Author = {Benjamin Van Durme and Ashwin Lall},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1892--1900},
	Title = {Streaming Pointwise Mutual Information},
	Year = {2009}}

@incollection{Shen:2009,
	Author = {Chunhua Shen and Junae Kim and Lei Wang and Anton van den Hengel},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1651--1659},
	Title = {Positive Semidefinite Metric Learning with Boosting},
	Year = {2009}}

@incollection{Steyvers:2009,
	Author = {Mark Steyvers and Michael Lee and Brent Miller and Pernille Hemmer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1785--1793},
	Title = {The Wisdom of Crowds in the Recollection of Order Information},
	Year = {2009}}

@incollection{Hsu:2009a,
	Author = {Anne Hsu and Thomas Griffiths},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {754--762},
	Title = {Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning},
	Year = {2009}}

@incollection{Henao:2009,
	Author = {Ricardo Henao and Ole Winther},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {736--744},
	Title = {Bayesian Sparse Factor Models and DAGs Inference and Comparison},
	Year = {2009}}

@incollection{Grzegorczyk:2009,
	Author = {Marco Grzegorczyk and Dirk Husmeier},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {682--690},
	Title = {Non-stationary continuous dynamic Bayesian networks},
	Year = {2009}}

@incollection{Anati:2009,
	Author = {Roy Anati and Kostas Daniilidis},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {37--45},
	Title = {Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection},
	Year = {2009}}

@incollection{Meng:2009,
	Author = {Yicong Meng and Bertram Shi},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1267--1275},
	Title = {Extending Phase Mechanism to Differential Motion Opponency for Motion Pop-out},
	Year = {2009}}

@incollection{Coen-Cagli:2009,
	Author = {Ruben Coen-Cagli and Peter Dayan and Odelia Schwartz},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {369--377},
	Title = {Statistical Models of Linear and Nonlinear Contextual Interactions in Early Visual Processing},
	Year = {2009}}

@incollection{Yang:2009b,
	Author = {Zhirong Yang and Irwin King and Zenglin Xu and Erkki Oja},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2169--2177},
	Title = {Heavy-Tailed Symmetric Stochastic Neighbor Embedding},
	Year = {2009}}

@incollection{Conroy:2009,
	Author = {Bryan Conroy and Ben Singer and James Haxby and Peter Ramadge},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {378--386},
	Title = {fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity},
	Year = {2009}}

@incollection{Perina:2009,
	Author = {Alessandro Perina and Marco Cristani and Umberto Castellani and Vittorio Murino and Nebojsa Jojic},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1428--1436},
	Title = {Free energy score space},
	Year = {2009}}

@incollection{Nowak:2009,
	Author = {Rob Nowak},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1366--1374},
	Title = {Noisy Generalized Binary Search},
	Year = {2009}}

@incollection{Amini:2009,
	Author = {Massih Amini and Nicolas Usunier and Cyril Goutte},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {28--36},
	Title = {Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization},
	Year = {2009}}

@incollection{Pfister:2009,
	Author = {Jean-Pascal Pfister and Peter Dayan and Mate Lengyel},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1464--1472},
	Title = {Know Thy Neighbour: A Normative Theory of Synaptic Depression},
	Year = {2009}}

@incollection{Liu:2009,
	Author = {Han Liu and Xi Chen},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1141--1149},
	Title = {Nonparametric Greedy Algorithms for the Sparse Learning Problem},
	Year = {2009}}

@incollection{Xu:2009,
	Author = {Zenglin Xu and Rong Jin and Jianke Zhu and Irwin King and Michael Lyu and Zhirong Yang},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2125--2133},
	Title = {Adaptive Regularization for Transductive Support Vector Machine},
	Year = {2009}}

@incollection{Zhou:2009a,
	Author = {Chunxiao Zhou and Huixia Judy Wang and Yongmei Michelle Wang},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2277--2285},
	Title = {Efficient Moments-based Permutation Tests},
	Year = {2009}}

@incollection{Wang:2009g,
	Author = {Yang Wang and Gholamreza Haffari and Shaojun Wang and Greg Mori},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2008--2016},
	Title = {A Rate Distortion Approach for Semi-Supervised Conditional Random Fields},
	Year = {2009}}

@incollection{Dietz:2009,
	Author = {Laura Dietz and Valentin Dallmeier and Andreas Zeller and Tobias Scheffer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {468--476},
	Title = {Localizing Bugs in Program Executions with Graphical Models},
	Year = {2009}}

@incollection{Luttinen:2009,
	Author = {Jaakko Luttinen and Alexander Ilin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1177--1185},
	Title = {Variational Gaussian-process factor analysis for modeling spatio-temporal data},
	Year = {2009}}

@incollection{Fromer:2009,
	Author = {Menachem Fromer and Amir Globerson},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {567--575},
	Title = {An LP View of the M-best MAP problem},
	Year = {2009}}

@incollection{Cortes:2009,
	Author = {Corinna Cortes and Mehryar Mohri and Afshin Rostamizadeh},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {396--404},
	Title = {Learning Non-Linear Combinations of Kernels},
	Year = {2009}}

@incollection{Cecchi:2009,
	Author = {Guillermo Cecchi and Irina Rish and Benjamin Thyreau and Bertrand Thirion and Marion Plaze and Marie-Laure Paillere-Martinot and Catherine Martelli and Jean-Luc Martinot and Jean-Baptiste Poline},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {252--260},
	Title = {Discriminative Network Models of Schizophrenia},
	Year = {2009}}

@incollection{Yu:2009a,
	Author = {Kai Yu and Tong Zhang and Yihong Gong},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2223--2231},
	Title = {Nonlinear Learning using Local Coordinate Coding},
	Year = {2009}}

@incollection{Cho:2009,
	Author = {Youngmin Cho and Lawrence Saul},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {342--350},
	Title = {Kernel Methods for Deep Learning},
	Year = {2009}}

@incollection{Cavagnaro:2009,
	Author = {Daniel Cavagnaro and Mark Pitt and Jay Myung},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {234--242},
	Title = {Adaptive Design Optimization in Experiments with People},
	Year = {2009}}

@incollection{Mozer:2009,
	Author = {Michael Mozer and Harold Pashler and Nicholas Cepeda and Robert Lindsey and Ed Vul},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1321--1329},
	Title = {Predicting the Optimal Spacing of Study: A Multiscale Context Model of Memory},
	Year = {2009}}

@incollection{Nessler:2009,
	Author = {Bernhard Nessler and Michael Pfeiffer and Wolfgang Maass},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1357--1365},
	Title = {STDP enables spiking neurons to detect hidden causes of their inputs},
	Year = {2009}}

@incollection{Rao:2009,
	Author = {Vinayak Rao and Yee Whye Teh},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1554--1562},
	Title = {Spatial Normalized Gamma Processes},
	Year = {2009}}

@incollection{Bejan:2009,
	Author = {Cosmin Bejan and Matthew Titsworth and Andrew Hickl and Sanda Harabagiu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {73--81},
	Title = {Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution},
	Year = {2009}}

@incollection{Ghebreab:2009,
	Author = {Sennay Ghebreab and Steven Scholte and Victor Lamme and Arnold Smeulders},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {629--637},
	Title = {A Biologically Plausible Model for Rapid Natural Scene Identification},
	Year = {2009}}

@incollection{Zhou:2009b,
	Author = {Feng Zhou and Fernando De la Torre},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2286--2294},
	Title = {Canonical Time Warping for Alignment of Human Behavior},
	Year = {2009}}

@incollection{Onken:2009,
	Author = {Arno Onken and Steffen Gr\"{u}new\"{a}lder and Klaus Obermayer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1383--1391},
	Title = {Correlation Coefficients are Insufficient for Analyzing Spike Count Dependencies},
	Year = {2009}}

@incollection{Salakhutdinov:2009,
	Author = {Ruslan Salakhutdinov},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1598--1606},
	Title = {Learning in Markov Random Fields using Tempered Transitions},
	Year = {2009}}

@incollection{Kim:2009a,
	Author = {Jong Kyoung Kim and Seungjin Choi},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {970--978},
	Title = {Clustering sequence sets for motif discovery},
	Year = {2009}}

@incollection{Zhang:2009,
	Author = {Zhihua Zhang and Guang Dai},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2241--2249},
	Title = {Optimal Scoring for Unsupervised Learning},
	Year = {2009}}

@incollection{Fox:2009,
	Author = {Emily Fox and Erik Sudderth and Michael Jordan and Alan Willsky},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {549--557},
	Title = {Sharing Features among Dynamical Systems with Beta Processes},
	Year = {2009}}

@incollection{WU:2009a,
	Author = {Xiao-Ming WU and Anthony Man-Cho So and Zhenguo Li and Shuo-Yen Robert Li},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1964--1972},
	Title = {Fast Graph Laplacian Regularized Kernel Learning via Semidefinite--Quadratic--Linear Programming},
	Year = {2009}}

@incollection{Huang:2009,
	Author = {Shuai Huang and Jing Li and Liang Sun and Jun Liu and Teresa Wu and Kewei Chen and Adam Fleisher and Eric Reiman and Jieping Ye},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {808--816},
	Title = {Learning Brain Connectivity of Alzheimer's Disease from Neuroimaging Data},
	Year = {2009}}

@incollection{Fujiwara:2009,
	Author = {Yusuke Fujiwara and Yoichi Miyawaki and Yukiyasu Kamitani},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {576--584},
	Title = {Estimating image bases for visual image reconstruction from human brain activity},
	Year = {2009}}

@incollection{Nair:2009,
	Author = {Vinod Nair and Geoffrey Hinton},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1339--1347},
	Title = {3D Object Recognition with Deep Belief Nets},
	Year = {2009}}

@incollection{Venkataraman:2009,
	Author = {Shobha Venkataraman and Avrim Blum and Dawn Song and Subhabrata Sen and Oliver Spatscheck},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1946--1954},
	Title = {Tracking Dynamic Sources of Malicious Activity at Internet Scale},
	Year = {2009}}

@incollection{Konidaris:2009,
	Author = {George Konidaris and Andrew Barto},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1015--1023},
	Title = {Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining},
	Year = {2009}}

@incollection{Liang:2009a,
	Author = {Percy Liang and Francis Bach and Guillaume Bouchard and Michael Jordan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1132--1140},
	Title = {Asymptotically Optimal Regularization in Smooth Parametric Models},
	Year = {2009}}

@incollection{Salakhutdinov:2009a,
	Author = {Ruslan Salakhutdinov and Geoffrey Hinton},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1607--1614},
	Title = {Replicated Softmax: an Undirected Topic Model},
	Year = {2009}}

@incollection{Kumar:2009a,
	Author = {M. Pawan Kumar and Daphne Koller},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1051--1059},
	Title = {Learning a Small Mixture of Trees},
	Year = {2009}}

@incollection{Perkins:2009,
	Author = {Theodore Perkins},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1437--1445},
	Title = {Maximum likelihood trajectories for continuous-time Markov chains},
	Year = {2009}}

@incollection{Waugh:2009,
	Author = {Kevin Waugh and Nolan Bard and Michael Bowling},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2026--2034},
	Title = {Strategy Grafting in Extensive Games},
	Year = {2009}}

@incollection{Quadrianto:2009a,
	Author = {Novi Quadrianto and Tiberio Caetano and John Lim and Dale Schuurmans},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1491--1499},
	Title = {Convex Relaxation of Mixture Regression with Efficient Algorithms},
	Year = {2009}}

@incollection{Hu:2009,
	Author = {Tao Hu and Anthony Leonardo and Dmitri Chklovskii},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {790--798},
	Title = {Reconstruction of Sparse Circuits Using Multi-neuronal Excitation (RESCUME)},
	Year = {2009}}

@incollection{Chechik:2009,
	Author = {Gal Chechik and Uri Shalit and Varun Sharma and Samy Bengio},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {306--314},
	Title = {An Online Algorithm for Large Scale Image Similarity Learning},
	Year = {2009}}

@incollection{Kim:2009b,
	Author = {Kwang In Kim and Florian Steinke and Matthias Hein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {979--987},
	Title = {Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction},
	Year = {2009}}

@incollection{Zhou:2009c,
	Author = {Shuheng Zhou},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2304--2312},
	Title = {Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation},
	Year = {2009}}

@incollection{McCallum:2009,
	Author = {Andrew McCallum and Karl Schultz and Sameer Singh},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1249--1257},
	Title = {FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs},
	Year = {2009}}

@incollection{Song:2009,
	Author = {Le Song and Mladen Kolar and Eric Xing},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1732--1740},
	Title = {Time-Varying Dynamic Bayesian Networks},
	Year = {2009}}

@incollection{Ihler:2009,
	Author = {Alexander Ihler and Andrew Frank and Padhraic Smyth},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {826--834},
	Title = {Particle-based Variational Inference for Continuous Systems},
	Year = {2009}}

@incollection{Meka:2009,
	Author = {Raghu Meka and Prateek Jain and Inderjit Dhillon},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1258--1266},
	Title = {Matrix Completion from Power-Law Distributed Samples},
	Year = {2009}}

@incollection{Bengio:2009,
	Author = {Samy Bengio and Fernando Pereira and Yoram Singer and Dennis Strelow},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {82--89},
	Title = {Group Sparse Coding},
	Year = {2009}}

@incollection{Lozano:2009,
	Author = {Aurelie Lozano and Grzegorz Swirszcz and Naoki Abe},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1150--1158},
	Title = {Grouped Orthogonal Matching Pursuit for Variable Selection and Prediction},
	Year = {2009}}

@incollection{Montanari:2009,
	Author = {Andrea Montanari and Jose Ayres Pereira},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1303--1311},
	Title = {Which graphical models are difficult to learn?},
	Year = {2009}}

@incollection{Kloft:2009,
	Author = {Marius Kloft and Ulf Brefeld and Soeren Sonnenburg and Pavel Laskov and Klaus-Robert M\"{u}ller and Alexander Zien},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {997--1005},
	Title = {Efficient and Accurate Lp-Norm Multiple Kernel Learning},
	Year = {2009}}

@incollection{Doshi-Velez:2009a,
	Author = {Finale Doshi-Velez and David Knowles and Shakir Mohamed and Zoubin Ghahramani},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1294--1302},
	Title = {Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process},
	Year = {2009}}

@incollection{Bai:2009,
	Author = {Bing Bai and Jason Weston and David Grangier and Ronan Collobert and Kunihiko Sadamasa and Yanjun Qi and Corinna Cortes and Mehryar Mohri},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {64--72},
	Title = {Polynomial Semantic Indexing},
	Year = {2009}}

@incollection{Bulo:2009,
	Author = {Samuel Rota Bul\`{o} and Marcello Pelillo},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1571--1579},
	Title = {A Game-Theoretic Approach to Hypergraph Clustering},
	Year = {2009}}

@incollection{Schlecht:2009,
	Author = {Joseph Schlecht and Kobus Barnard},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1615--1623},
	Title = {Learning models of object structure},
	Year = {2009}}

@incollection{Choi:2009,
	Author = {Arthur Choi and Adnan Darwiche},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {351--359},
	Title = {Approximating MAP by Compensating for Structural Relaxations},
	Year = {2009}}

@incollection{Sriperumbudur:2009,
	Author = {Bharath Sriperumbudur and Kenji Fukumizu and Arthur Gretton and Gert Lanckriet and Bernhard Schoelkopf},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1750--1758},
	Title = {Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions},
	Year = {2009}}

@incollection{Garcia:2009,
	Author = {Eric Garcia and Maya Gupta},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {594--602},
	Title = {Lattice Regression},
	Year = {2009}}

@incollection{Sutskever:2009,
	Author = {Ilya Sutskever and Ruslan Salakhutdinov and Joshua Tenenbaum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1821--1828},
	Title = {Modelling Relational Data using Bayesian Clustered Tensor Factorization},
	Year = {2009}}

@incollection{Maillard:2009,
	Author = {Odalric Maillard and Remi Munos},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1213--1221},
	Title = {Compressed Least-Squares Regression},
	Year = {2009}}

@incollection{Morimura:2009,
	Author = {Tetsuro Morimura and Eiji Uchibe and Junichiro Yoshimoto and Kenji Doya},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1312--1320},
	Title = {A Generalized Natural Actor-Critic Algorithm},
	Year = {2009}}

@incollection{Orbanz:2009,
	Author = {Peter Orbanz},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1392--1400},
	Title = {Construction of Nonparametric Bayesian Models from Parametric Bayes Equations},
	Year = {2009}}

@incollection{Wick:2009,
	Author = {Michael Wick and Khashayar Rohanimanesh and Sameer Singh and Andrew McCallum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2044--2052},
	Title = {Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference},
	Year = {2009}}

@incollection{Sriperumbudur:2009a,
	Author = {Bharath Sriperumbudur and Gert Lanckriet},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1759--1767},
	Title = {On the Convergence of the Concave-Convex Procedure},
	Year = {2009}}

@incollection{Wilson:2009,
	Author = {Robert Wilson and Leif Finkel},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2062--2070},
	Title = {A Neural Implementation of the Kalman Filter},
	Year = {2009}}

@incollection{Wallach:2009,
	Author = {Hanna Wallach and David Mimno and Andrew McCallum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1973--1981},
	Title = {Rethinking LDA: Why Priors Matter},
	Year = {2009}}

@incollection{Bergstra:2009,
	Author = {James Bergstra and Yoshua Bengio},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {99--107},
	Title = {Slow, Decorrelated Features for Pretraining Complex Cell-like Networks},
	Year = {2009}}

@incollection{Bo:2009,
	Author = {Liefeng Bo and Cristian Sminchisescu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {135--143},
	Title = {Efficient Match Kernel between Sets of Features for Visual Recognition},
	Year = {2009}}

@incollection{Peng:2009,
	Author = {Jian Peng and Liefeng Bo and Jinbo Xu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1419--1427},
	Title = {Conditional Neural Fields},
	Year = {2009}}

@incollection{Guillory:2009,
	Author = {Andrew Guillory and Jeff Bilmes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {691--699},
	Title = {Label Selection on Graphs},
	Year = {2009}}

@incollection{Fletcher:2009,
	Author = {Alyson Fletcher and Sundeep Rangan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {540--548},
	Title = {Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis},
	Year = {2009}}

@incollection{Zinkevich:2009,
	Author = {Martin Zinkevich and Alex Smola and John Langford},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2331--2339},
	Title = {Slow Learners are Fast},
	Year = {2009}}

@incollection{Blaschko:2009,
	Author = {Mathew Blaschko and Jacquelyn Shelton and Andreas Bartels},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {126--134},
	Title = {Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity},
	Year = {2009}}

@inproceedings{Miller:2009,
	Author = {Kurt Miller and Thomas Griffiths and Michael Jordan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1276--1284},
	Title = {Nonparametric Latent Feature Models for Link Prediction},
	Year = {2009}}

@incollection{Dekel:2009,
	Author = {Ofer Dekel},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {450--458},
	Title = {Distribution-Calibrated Hierarchical Classification},
	Year = {2009}}

@incollection{Cevher:2009,
	Author = {Volkan Cevher},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {261--269},
	Title = {Learning with Compressible Priors},
	Year = {2009}}

@incollection{Wipf:2009,
	Author = {David Wipf and Srikantan Nagarajan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2071--2079},
	Title = {Sparse Estimation Using General Likelihoods and Non-Factorial Priors},
	Year = {2009}}

@incollection{Huang:2009a,
	Author = {Jonathan Huang and Carlos Guestrin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {799--807},
	Title = {Riffled Independence for Ranked Data},
	Year = {2009}}

@incollection{Kulis:2009,
	Author = {Brian Kulis and Trevor Darrell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1042--1050},
	Title = {Learning to Hash with Binary Reconstructive Embeddings},
	Year = {2009}}

@incollection{Hein:2009,
	Author = {Matthias Hein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {718--726},
	Title = {Robust Nonparametric Regression with Metric-Space Valued Output},
	Year = {2009}}

@incollection{Bouvrie:2009,
	Author = {Jake Bouvrie and Lorenzo Rosasco and Tomaso Poggio},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {162--170},
	Title = {On Invariance in Hierarchical Models},
	Year = {2009}}

@incollection{Vul:2009,
	Author = {Ed Vul and Michael Frank and George Alvarez and Joshua Tenenbaum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1955--1963},
	Title = {Explaining human multiple object tracking as resource-constrained approximate inference in a dynamic probabilistic model},
	Year = {2009}}

@incollection{Allen:2009,
	Author = {Martin Allen and Shlomo Zilberstein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {19--27},
	Title = {Complexity of Decentralized Control: Special Cases},
	Year = {2009}}

@incollection{Syed:2009,
	Author = {Umar Syed and Aleksandrs Slivkins and Nina Mishra},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1829--1837},
	Title = {Adapting to the Shifting Intent of Search Queries},
	Year = {2009}}

@incollection{Gershman:2009,
	Author = {Samuel Gershman and Ed Vul and Joshua Tenenbaum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {611--619},
	Title = {Perceptual Multistability as Markov Chain Monte Carlo Inference},
	Year = {2009}}

@incollection{Hu:2009a,
	Author = {Chonghai Hu and James Kwok and Weike Pan},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {781--789},
	Title = {Accelerated Gradient Methods for Stochastic Optimization and Online Learning},
	Year = {2009}}

@incollection{Russell:2009,
	Author = {Bryan Russell and Alyosha Efros and Josef Sivic and Bill Freeman and Andrew Zisserman},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1580--1588},
	Title = {Segmenting Scenes by Matching Image Composites},
	Year = {2009}}

@incollection{Agarwal:2009,
	Author = {Alekh Agarwal and Peter Bartlett and Pradeep Ravikumar and Martin Wainwright},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1--9},
	Title = {Information-theoretic lower bounds on the oracle complexity of convex optimization},
	Year = {2009}}

@incollection{Gretton:2009,
	Author = {Arthur Gretton and Kenji Fukumizu and Zaid Harchaoui and Bharath Sriperumbudur},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {673--681},
	Title = {A Fast, Consistent Kernel Two-Sample Test},
	Year = {2009}}

@incollection{Desai:2009,
	Author = {Vijay Desai and Vivek Farias and Ciamac Moallemi},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {459--467},
	Title = {A Smoothed Approximate Linear Program},
	Year = {2009}}

@incollection{Kpotufe:2009,
	Author = {Samory Kpotufe},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1024--1032},
	Title = {Fast, smooth and adaptive regression in metric spaces},
	Year = {2009}}

@incollection{Lu:2009,
	Author = {Hongjing Lu and Matthew Weiden and Alan Yuille},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1159--1167},
	Title = {Modeling the spacing effect in sequential category learning},
	Year = {2009}}

@incollection{Subramanya:2009,
	Author = {Amarnag Subramanya and Jeff Bilmes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1803--1811},
	Title = {Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification},
	Year = {2009}}

@incollection{Sinha:2009,
	Author = {Kaushik Sinha and Mikhail Belkin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1687--1695},
	Title = {Semi-supervised Learning using Sparse Eigenfunction Bases},
	Year = {2009}}

@incollection{Bouchard-Cote:2009,
	Author = {Alexandre Bouchard-C\^{o}t\'{e} and Slav Petrov and Dan Klein},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {144--152},
	Title = {Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs},
	Year = {2009}}

@incollection{Rangan:2009,
	Author = {Sundeep Rangan and Alyson Fletcher and Vivek Goyal},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1545--1553},
	Title = {Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing},
	Year = {2009}}

@incollection{Tillman:2009,
	Author = {Robert Tillman and Arthur Gretton and Peter Spirtes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1847--1855},
	Title = {Nonlinear directed acyclic structure learning with weakly additive noise models},
	Year = {2009}}

@incollection{Seeger:2009,
	Author = {Matthias Seeger},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1633--1641},
	Title = {Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing},
	Year = {2009}}

@incollection{Xiao:2009,
	Author = {Lin Xiao},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2116--2124},
	Title = {Dual Averaging Method for Regularized Stochastic Learning and Online Optimization},
	Year = {2009}}

@incollection{Yang:2009c,
	Author = {Xiaolin Yang and Seyoung Kim and Eric Xing},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2151--2159},
	Title = {Heterogeneous multitask learning with joint sparsity constraints},
	Year = {2009}}

@incollection{Sun:2009,
	Author = {Liang Sun and Jun Liu and Jianhui Chen and Jieping Ye},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1812--1820},
	Title = {Efficient Recovery of Jointly Sparse Vectors},
	Year = {2009}}

@incollection{Steinwart:2009,
	Author = {Ingo Steinwart and Andreas Christmann},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1768--1776},
	Title = {Fast Learning from Non-i.i.d. Observations},
	Year = {2009}}

@incollection{Leordeanu:2009,
	Author = {Marius Leordeanu and Martial Hebert and Rahul Sukthankar},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1114--1122},
	Title = {An Integer Projected Fixed Point Method for Graph Matching and MAP Inference},
	Year = {2009}}

@incollection{Negahban:2009,
	Author = {Sahand Negahban and Pradeep Ravikumar and Martin Wainwright and Bin Yu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1348--1356},
	Title = {A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers},
	Year = {2009}}

@incollection{Moghaddam:2009,
	Author = {Baback Moghaddam and Benjamin Marlin and Emtiyaz Khan and Kevin Murphy},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1285--1293},
	Title = {Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models},
	Year = {2009}}

@incollection{Fazli:2009,
	Author = {Siamac Fazli and Cristian Grozea and Marton Danoczy and Benjamin Blankertz and Florin Popescu and Klaus-Robert Muller},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {513--521},
	Title = {Subject independent EEG-based BCI decoding},
	Year = {2009}}

@incollection{Wilder:2009,
	Author = {Matthew Wilder and Matt Jones and Michael Mozer},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {2053--2061},
	Title = {Sequential effects reflect parallel learning of multiple environmental regularities},
	Year = {2009}}

@incollection{Heller:2009,
	Author = {Katherine Heller and Adam Sanborn and Nick Chater},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {727--735},
	Title = {Hierarchical Learning of Dimensional Biases in Human Categorization},
	Year = {2009}}

@incollection{Ailon:2009,
	Author = {Nir Ailon and Ragesh Jaiswal and Claire Monteleoni},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {10--18},
	Title = {Streaming k-means approximation},
	Year = {2009}}

@incollection{Raskutti:2009,
	Author = {Garvesh Raskutti and Martin Wainwright and Bin Yu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1563--1570},
	Title = {Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness},
	Year = {2009}}

@incollection{Shi:2009,
	Author = {Lei Shi and Thomas Griffiths},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1669--1677},
	Title = {Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling},
	Year = {2009}}

@incollection{Courville:2009,
	Author = {Aaron Courville and Douglas Eck and Yoshua Bengio},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {405--413},
	Title = {An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism},
	Year = {2009}}

@incollection{Cai:2009,
	Author = {Chenghui Cai and Xuejun Liao and Lawrence Carin},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {198--206},
	Title = {Learning to Explore and Exploit in POMDPs},
	Year = {2009}}

@incollection{Graca:2009,
	Author = {Joao Graca and Kuzman Ganchev and Ben Taskar and Fernando Pereira},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {664--672},
	Title = {Posterior vs Parameter Sparsity in Latent Variable Models},
	Year = {2009}}

@incollection{Chaudhuri:2009,
	Author = {Kamalika Chaudhuri and Yoav Freund and Daniel Hsu},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {297--305},
	Title = {A Parameter-free Hedging Algorithm},
	Year = {2009}}

@incollection{Smaragdis:2009,
	Author = {Paris Smaragdis and Madhusudana Shashanka and Bhiksha Raj},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1705--1713},
	Title = {A Sparse Non-Parametric Approach for Single Channel Separation of Known Sounds},
	Year = {2009}}

@incollection{Maei:2009,
	Author = {Hamid Maei and Csaba Szepesvari and Shalabh Bhatnagar and Doina Precup and David Silver and Rich Sutton},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1204--1212},
	Title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
	Year = {2009}}

@incollection{Chai:2009a,
	Author = {Barry Chai and Dirk Walther and Diane Beck and Li Fei-Fei},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {270--278},
	Title = {Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis},
	Year = {2009}}

@incollection{Saenko:2009,
	Author = {Kate Saenko and Trevor Darrell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1589--1597},
	Title = {Filtering Abstract Senses From Image Search Results},
	Year = {2009}}

@incollection{Culpepper:2009,
	Author = {Benjamin Culpepper and Bruno Olshausen},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {423--431},
	Title = {Learning transport operators for image manifolds},
	Year = {2009}}

@incollection{Rai:2009,
	Author = {Piyush Rai and Hal Daume},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1518--1526},
	Title = {Multi-Label Prediction via Sparse Infinite CCA},
	Year = {2009}}

@incollection{Stevenson:2009,
	Author = {Ian Stevenson and Konrad Koerding},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1777--1784},
	Title = {Structural inference affects depth perception in the context of potential occlusion},
	Year = {2009}}

@incollection{Luo:2009,
	Author = {Jie Luo and Barbara Caputo and Vittorio Ferrari},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1168--1176},
	Title = {Who's Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation},
	Year = {2009}}

@incollection{Hsu:2009b,
	Author = {Chun-Nan Hsu and Yu-Ming Chang and Hanshen Huang and Yuh-Jye Lee},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {763--771},
	Title = {Periodic Step Size Adaptation for Single Pass On-line Learning},
	Year = {2009}}

@incollection{Todorov:2009,
	Author = {Emanuel Todorov},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1856--1864},
	Title = {Compositionality of optimal control laws},
	Year = {2009}}

@incollection{Lee:2009,
	Author = {Honglak Lee and Peter Pham and Yan Largman and Andrew Ng},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1096--1104},
	Title = {Unsupervised feature learning for audio classification using convolutional deep belief networks},
	Year = {2009}}

@incollection{OZAKIN:2009,
	Author = {ARKADAS OZAKIN and Alexander Gray},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1375--1382},
	Title = {Submanifold density estimation},
	Year = {2009}}

@incollection{Dermed:2009,
	Author = {Liam Mac Dermed and Charles Isbell},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1186--1194},
	Title = {Solving Stochastic Games},
	Year = {2009}}

@incollection{Ullman:2009,
	Author = {Tomer Ullman and Chris Baker and Owen Macindoe and Owain Evans and Noah Goodman and Joshua Tenenbaum},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1874--1882},
	Title = {Help or Hinder: Bayesian Models of Social Goal Inference},
	Year = {2009}}

@incollection{Cuturi:2009,
	Author = {Marco Cuturi and Jean-Philippe Vert and Alexandre D'Aspremont},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {432--440},
	Title = {White Functionals for Anomaly Detection in Dynamical Systems},
	Year = {2009}}

@incollection{Pirsiavash:2009,
	Author = {Hamed Pirsiavash and Deva Ramanan and Charless Fowlkes},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1482--1490},
	Title = {Bilinear classifiers for visual recognition},
	Year = {2009}}

@incollection{Vanpaemel:2009,
	Author = {Wolf Vanpaemel},
	Booktitle = {Advances in Neural Information Processing Systems 22},
	Editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
	Pages = {1919--1927},
	Title = {Measuring model complexity with the prior predictive},
	Year = {2009}}

@unpublished{Savir:2009,
	Author = {Savir, N.},
	Month = {May},
	Title = {Supervised Topic Models with Multiple Response Functions},
	Year = {2009}}

@techreport{Griffin:2009,
	Author = {Griffin, J and Steel, M},
	Institution = {Technical Report 09-05, CRiSM},
	Title = {Time-Dependent Stick-Breaking Processes},
	Year = {2009}}

@conference{Karlgred:2008,
	Author = {Karlgred, J. and Holst, A. and Sahlgren, M.},
	Booktitle = {ECIR},
	Title = {Filaments of Meaning in Word Space},
	Year = {2008}}

@conference{Ramage:2009,
	Author = {Ramage, D. and Hall, D. and Nallapati, R. and Manning, C.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {Labeled {LDA}: {A} supervised topic model for credit attribution in muli-labeled corpora},
	Year = {2009}}

@article{Raftery:2005,
	Author = {Raftery, A.E. and Gneiting, T. and Balabdaoui, F. and Polakowski, M.},
	Journal = {monthly Weather Review},
	Number = {5},
	Pages = {1155--1174},
	Title = {Using {B}ayesian model averaging to calibrate forecast ensembles},
	Volume = {133},
	Year = {2005}}

@unpublished{Wickham:2009a,
	Author = {Wickham, H.},
	Month = {May},
	Title = {The split-apply-combine strategy for data analysis},
	Year = {2009}}

@article{Janzing:2009,
	Author = {Dominik Janzing and Patrik O. Hoyer and Bernhard Schoelkopf},
	Month = {09},
	Title = {Telling cause from effect based on high-dimensional observations},
	Year = {2009}}

@article{Adler:2009,
	Author = {Robert Adler and John Ewing and Peter Taylor},
	Journal = {Statistical Science},
	Month = {10},
	Number = {1},
	Pages = {1--14},
	Title = {Citation Statistics},
	Volume = {24},
	Year = {2009}}

@unpublished{Grimmer:2009,
	Author = {Grimmer},
	Title = {A {B}ayesian Hierarchical Topic Model for Political Texts: {M}easuring Expressed Agendas in Senate Press Releases},
	Year = {2009}}

@conference{Martin:2001,
	Author = {Martin, A. and Quinn, K.},
	Booktitle = {Midwest Political Science Association Annual Meeting},
	Title = {The Dimensions of Supreme Court Decision Making: {A}gain Revisiting The Judicial Mind},
	Year = {2001}}

@article{Varoquaux:2009,
	Author = {Ga{\"e}l Varoquaux and Sepideh Sadaghiani and Jean Baptiste Poline and Bertrand Thirion},
	Journal = {Medical Image Computing and Computer Aided Intervention, London : United Kingdom (2009)},
	Month = {11},
	Title = {CanICA: Model-based extraction of reproducible group-level ICA patterns from fMRI time series},
	Year = {2009}}

@article{Norets:2010,
	Author = {Norets, A.},
	Journal = {Annals of Statistics},
	Title = {Approximation of Conditional Densities by Smooth Mixtures of Regressions},
	Year = {to appear}}

@unpublished{Norets:2009,
	Author = {Norets, A. and Pelenis, J.},
	Month = {June},
	Title = {Bayesian modeling of joint and conditional distributions},
	Year = {2009}}

@article{Griffin:2010,
	Author = {Griffin, J.},
	Journal = {Bayesian Analysis},
	Number = {1},
	Pages = {847--866},
	Title = {Default priors for density estimation with mixture models},
	Volume = {5},
	Year = {2010}}

@article{Kingman:1967,
	Author = {Kingman, J.},
	Journal = {Pacific Journal of Mathematics},
	Number = {1},
	Title = {Completely random measures},
	Volume = {21},
	Year = {1967}}

@article{Chang:2010,
	Author = {Chang, J. and Blei, D.},
	Journal = {Annals of Applied Statistics},
	Title = {Hierarchical relational models for document networks},
	Year = {2010}}

@article{Bafumi:2005,
	Author = {Bafumi, J. and Gelman, A. and Park, D. and Kaplan, N.},
	Journal = {Political Analysis},
	Pages = {171--187},
	Title = {Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation},
	Volume = {13},
	Year = {2005}}

@article{Krnjajic:2008,
	Author = {Krnjaji{\'c}, M. and Kottas, A. and Draper, D.},
	Journal = {Computational Statistics and Data Analysis},
	Number = {4},
	Pages = {2110--2128},
	Title = {{Parametric and nonparametric Bayesian model specification: A case study involving models for count data}},
	Volume = {52},
	Year = {2008}}

@book{Findlay:2000,
	Author = {Findlay, C.},
	Publisher = {National Academy Press},
	Title = {Enhancing the Postdoctoral Experience for Scientists and Engineers: {A} Guide for Postdoctoral Scholars, Advisers, Institutions, Funding Organizations, and Disciplinary Societies},
	Year = {2000}}

@article{Jackman:2001,
	Author = {Jackman, S.},
	Journal = {Political Analysis},
	Number = {3},
	Title = {Multidimensional analysis of roll call data via {B}ayesian simulation: {I}dentification, estimation, inference, and model checking},
	Volume = {9},
	Year = {2001}}

@conference{Blei:2010a,
	Author = {Blei, D. and Frazier, P.},
	Booktitle = {ICML},
	Title = {Distance dependent {C}hinese restaurant processes},
	Year = {2010}}

@conference{Wang:2006a,
	Author = {Wang, X. and McCallum, A.},
	Booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	Organization = {ACM},
	Pages = {433--443},
	Title = {Topics over time: {A} non-markov continuous-time model of topical trends},
	Year = {2006}}

@unpublished{NSF:2009,
	Author = {NSF},
	Title = {Guide for Proposals},
	Year = {2009}}

@article{Bayarri:2007,
	Author = {Bayarri, M. and Castellanos, M.},
	Journal = {Statistical Science},
	Pages = {322--343},
	Title = {Bayesian Checking of the Second Levels of Hierarchical Models},
	Volume = {22},
	Year = {2007}}

@article{Larsen:2007,
	Author = {Larsen, M. and Lu, L.},
	Journal = {Statistical Science},
	Pages = {359--362},
	Title = {Comment: {B}ayesian Checking of the Second Level of Hierarchical Models: {C}ross-Validated Posterior Predictive Checks Using Discrepancy Measures},
	Volume = {22},
	Year = {2007}}

@article{Robert:2009b,
	Author = {Robert, C. and Mengersen, K. and Chen, C.},
	Journal = {arXiv},
	Number = {0909.5673.v2},
	Title = {Model choice versus model criticism},
	Year = {2009}}

@article{Broderick:2013,
	Author = {Broderick, T. and Mackey, L. and Paisley, J. and Jordan, M.},
	Journal = {arXiv},
	Number = {1111.1802},
	Title = {Combinatorial clustering and the beta negative binomial process},
	Year = {2013}}

@article{Gopalan:2013,
	Author = {Gopalan, P. and Hoffman, J. and Blei, D.},
	Journal = {arXiv},
	Number = {1311.1704},
	Title = {Scalable Recommendation with Poisson Factorization},
	Year = {2013}}

@article{Rubin:1984,
	Author = {Rubin, D.},
	Journal = {The Annals of Statistics},
	Number = {4},
	Pages = {1151--1172},
	Title = {Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician},
	Volume = {12},
	Year = {1984}}

@article{Hill:1990,
	Author = {Hill, J.},
	Journal = {Biometrika},
	Pages = {115--126},
	Title = {A General Framework for Model-Based Statistics},
	Volume = {77},
	Year = {1990}}

@article{Draper:1995,
	Author = {Draper, D.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Pages = {45--97},
	Title = {Assessment and Propagation of Model Uncertainty},
	Volume = {57},
	Year = {1995}}

@article{Draper:1993,
	Author = {Draper, D. and Hodges, J. and Mallows, C. and Pregibon, D.},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Pages = {9--37},
	Title = {Exchangeability and Data Analysis},
	Volume = {156},
	Year = {1993}}

@unpublished{Breiman:2002,
	Author = {Breiman, L.},
	Title = {Looking Inside the Black Box},
	Year = {2002}}

@article{Gelman:1996,
	Author = {Gelman, A. and Meng, X. and Stern, H.},
	Journal = {Statistica Sinica},
	Pages = {733--807},
	Title = {Posterior Predictive Assessment of Model Fitness Via Realized Discrepancies},
	Volume = {6},
	Year = {1996}}

@book{Jaynes:2003,
	Author = {Jaynes, E. T.},
	Publisher = {Cambridge University Press},
	Title = {Probability Theory: {T}he Logic Of Science},
	Year = {2003}}

@book{Claeskens:2008,
	Author = {Claeskens, G. and Hjort, N.},
	Publisher = {Cambridge University Press},
	Title = {Model Selection and Model Averaging},
	Year = {2008}}

@article{Rubin:1990,
	Author = {Rubin, D.},
	Journal = {Statistical Science},
	Pages = {472--479},
	Title = {Neyman (1923) and Causal Inference in Experiments and Observational Studies},
	Year = {1990}}

@article{Pearl:2009,
	Author = {Pearl, J.},
	Journal = {Statistical Surveys},
	Title = {Causal Inference in Statistics: {A}n Overview},
	Year = {2009}}

@article{Martin:2002,
	Author = {Martin, A. and Quinn, K.},
	Journal = {Political Analysis},
	Number = {2},
	Pages = {134--153},
	Title = {Dynamic Ideal Point Estimation via {M}arkov Chain {M}onte {C}arlo for the {U.S.} {S}upreme {C}ourt, 1953--1999},
	Volume = {10},
	Year = {2002}}

@article{Blei:2010,
	Author = {Blei, D. and Griffiths, T. and Jordan, M.},
	Journal = {Journal of the ACM},
	Number = {2},
	Pages = {1--30},
	Title = {The nested {C}hinese restaurant process and {B}ayesian nonparametric inference of topic hierarchies},
	Volume = {57},
	Year = {2010}}

@article{Gershman:2010,
	Author = {Gershman, S. and Blei, D. and Niv, Y.},
	Journal = {Psychological Review},
	Number = {1},
	Pages = {197--209},
	Title = {Context, Learning and Extinction},
	Volume = {117},
	Year = {2010}}

@inproceedings{Hoffman:2009b,
	Author = {M. Hoffman and P. Cook and D. Blei},
	Booktitle = {International Computer Music Conference},
	Title = {Bayesian Spectral Matching: {T}urning Young {MC} into {MC} Hammer via {MCMC} Sampling},
	Year = {2009}}

@inproceedings{Hoffman:2009a,
	Author = {M. Hoffman and D. Blei and P. Cook},
	Booktitle = {International Conference on Music Information Retrieval},
	Title = {Easy as {CBA}: {A} Simple Probabilistic Model for Tagging Music},
	Year = {2009}}

@inproceedings{Hoffman:2009,
	Author = {M. Hoffman and D. Blei and P. Cook},
	Booktitle = {International Conference on Digital Audio Effects},
	Title = {Finding Latent Sources in Recorded Music With a Shift-Invariant {HDP}},
	Year = {2009}}

@inproceedings{Socher:2009,
	Author = {Socher, R. and Gershman, S. and Perotte, A. and Sederberg, P. and Blei, D. and Norman, K.},
	Booktitle = {Neural Information Processing Systems},
	Title = {A {B}ayesian Analysis of Dynamics in Free Recall},
	Year = {2009}}

@inproceedings{Chang:2009b,
	Author = {Chang, J. and Boyd-Graber, J. and Wang, C. and Gerrish, S. and Blei, D.},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Reading Tea Leaves: {H}ow Humans Interpret Topic Models},
	Year = {2009}}

@inproceedings{Wang:2009b,
	Author = {Wang, C. and Blei, D.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Decoupling Sparsity and Smoothness in the Discrete Hierarchical {D}irichlet Process},
	Year = {2009}}

@article{Bhattacharya:2009,
	Author = {Bhattacharya, A. and Dunson, D.},
	Title = {Nonparametric {B}ayesian Density Estimation on Manifolds with Applications to Planar Shapes},
	Year = {2009}}

@article{Bigelow:2007,
	Author = {Bigelow, J. and Dunson, D.},
	Journal = {Biometrics},
	Number = {3},
	Pages = {724--732},
	Title = {Bayesian adaptive regression splines for hierarchical data},
	Volume = {63},
	Year = {2007}}

@article{Bigelow:2009,
	Author = {Bigelow, J. and Dunson, D.},
	Journal = {Journal of the American Statistical Association},
	Number = {485},
	Pages = {26--36},
	Title = {Bayesian semiparametric joint models for functional predictors},
	Volume = {104},
	Year = {2009}}

@article{Lee:2008,
	Author = {Lee, J. and Quintana, F. and Muller, P. and Trippa, L.},
	Title = {Defining Predictive Probability Functions for Species Sampling Models},
	Year = {2008}}

@article{Wood:2007,
	Author = {Wood, S. and Kohn, R. and Cottet, R. and Jiang, W. and Tanner, M.},
	Title = {Locally Adaptive Nonparametric Binary Regression},
	Year = {2007}}

@article{Rodriguez:2009a,
	Author = {Rodriguez, A. and Dunson, D. and Gelfand, A.},
	Journal = {Journal of the American Statistical Association},
	Title = {Latent Stick-Breaking Processes},
	Year = {2009}}

@article{Rodriguez:2009,
	Author = {Rodriguez, A. and Dunson, D. Gelfand, A.},
	Journal = {Biometrika},
	Pages = {149--162},
	Title = {Bayesian nonparametric functional data analysis through density estimation},
	Volume = {96},
	Year = {2009}}

@techreport{Park:2007,
	Author = {Park, J. and Dunson, D.},
	Institution = {Tech. rep., Duke University},
	Title = {Bayesian generalized product partition model},
	Year = {2007}}

@article{Newman:2009,
	Author = {M. Newman},
	Journal = {Europhys. Lett.},
	Pages = {68001},
	Title = {The first-mover advantage in scientific publication},
	Volume = {86},
	Year = {2009}}

@inproceedings{Dahl:2008gd,
	Author = {Dahl, D.},
	Booktitle = {JSM},
	Title = {Distance-Based Probability Distribution for Set Partitions with Applications to Bayesian Nonparametrics},
	Year = {2008}}

@article{Lin:2009,
	Author = {Lin, S. and Sturmfels, B. and Xu, Z.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1611--1631},
	Title = {Marginal Likelihood Integrals for Mixtures of Independence Models},
	Volume = {10},
	Year = {2009}}

@article{Muller:2008,
	Author = {Muller, P. and Quintana, F.},
	Title = {Random Partition Models with Regression on Covariates},
	Year = {2008}}

@article{Muller:2009,
	Author = {Muller, P. and Quintana, F. and Rosner, G.},
	Title = {Bayesian Clustering with Regression},
	Year = {2009}}

@article{Bubeck:2009,
	Author = {Bubeck, S. and Meila, M. and von Luxborg, U.},
	Journal = {arXiv},
	Number = {0907.5494v1},
	Title = {How the initialization affects the stability of the $k$-means algorithm},
	Year = {2009}}

@article{Robert:2009a,
	Author = {Robert, C. and Wraith, D.},
	Journal = {arXiv},
	Number = {0907.5123v1},
	Title = {Computational Methods for {B}ayesian Model Choice},
	Year = {2009}}

@article{Anonymous:2009,
	Author = {Anonymous},
	Title = {Estimation in Dirichlet Random Effects Models},
	Year = {2009}}

@book{Feller:1968,
	Author = {Feller, W.},
	Publisher = {John Wiley \& Sons Ltd.},
	Title = {An Introduction to Probability Theory and its Applications},
	Year = {1968}}

@article{Swayna:2006,
	Author = {Swayna, D.},
	Title = {{GGobi} manual},
	Year = {2006}}

@book{Vivekananda:1893,
	Author = {Vivekananda, P.},
	Title = {Vedanta philosophy},
	Year = {1893}}

@inproceedings{Finkel:2009,
	Author = {Finkel, J. and Manning, C.},
	Booktitle = {Human Language Technologies},
	Title = {Hierarchical {B}ayesian Domain Adaptation},
	Year = {2009}}

@article{Kivinen:2007a,
	Author = {Kivinen, J. and Sudderth, E. and Jordan, M.},
	Title = {Image Denoising with Nonparametric Hidden {M}arkov Trees},
	Year = {2007}}

@article{Daume:2009,
	Author = {Daume, H.},
	Title = {Bayesian Multitask Learning with Latent Hierarchies},
	Year = {2009}}

@article{Gelman:2009,
	Author = {Gelman, A. and Hill, J. and Yajima, M.},
	Journal = {arXiv},
	Number = {0907.2478v1},
	Title = {Why we (usually) don't have to worry about multiple comparisons},
	Year = {2009}}

@article{Brewer:2009,
	Author = {Brewer, B. and Francis, M.},
	Journal = {arXiv},
	Number = {0906.5609v1},
	Title = {Entropic Priors and Bayesian Model Selection},
	Year = {2009}}

@article{Sato:2009,
	Author = {Sato, I. and Kurihara, K. and Tanaka, S. and Nakagawa, H. and Miyashita, S.},
	Journal = {arXiv},
	Number = {0905.3528v3},
	Title = {Quantum annealing for variational {B}ayes inference},
	Year = {2009}}

@article{Quinn:2008,
	Author = {Quinn, K. and Monroe, B. and Colaresi, M. and Crespin, M.},
	Title = {How to Analyze Political Attention with Minimal Assumptions and Costs},
	Year = {2008}}

@article{Lindquist:2008,
	Author = {Lindquist, M.},
	Journal = {Statistical Science},
	Number = {4},
	Pages = {439--464},
	Title = {The Statistical Analysis of f{MRI} Data},
	Volume = {23},
	Year = {2008}}

@article{Gomley:2009,
	Author = {Gomley, I. and Murphy, T.},
	Journal = {Bayesian Analysis},
	Number = {2},
	Pages = {265--296},
	Title = {A Grade of Membership Model for Rank Data},
	Volume = {4},
	Year = {2009}}

@article{Van-De-Ville:2006,
	Author = {Van De Ville, D. and Blu, T. and Unser, M.},
	Journal = {IEEE Engineering in Medicine and Biology},
	Title = {Surfing the Brain},
	Year = {2006}}

@article{Quinn:2006,
	Author = {Quinn, K. and Park, J. and Martin, A.},
	Title = {Improving Judicial Ideal Point Estimates with a More Realistic Model of Opinion Content},
	Year = {2006}}

@article{Aldous:2004,
	Author = {Aldous, D. and Miermont, G. and Pitman, J.},
	Journal = {Electronic Journal of Probability},
	Number = {3},
	Pages = {37--56},
	Title = {Brownian Bridge Asymptotics for Random p-Mappings},
	Volume = {9},
	Year = {2004}}

@inproceedings{Opper:2007,
	Author = {Opper, M. and Sanguinetti, G.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Variational inference for {M}arkov jump processes},
	Year = {2007}}

@inproceedings{Archambeau:2007,
	Author = {Archambeau, C. and Opper, M. and Shen, Y. and Cornford, D. and Shawe-Taylor, J.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Variational Inference for Diffusion Processes},
	Year = {2007}}

@article{Paquet:2009,
	Author = {Paquet, U. and Winther, O. and Opper, M.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1263--1304},
	Title = {Perturbation Corrections in Approximate Inference: {M}ixture Modelling Applications},
	Volume = {10},
	Year = {2009}}

@article{Silva:2009,
	Author = {Silva, R. and Ghahramani, Z.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1187--1238},
	Title = {The hidden life of latent variables: {B}ayesian learning with mixed graph models},
	Volume = {10},
	Year = {2009}}

@inproceedings{Boyd-Graber:2009b,
	Author = {Boyd-Graber, J. and Blei, D.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Multilingual topic models for unaligned text},
	Year = {2009}}

@article{Blei:2009a,
	Author = {Blei, D. and Lafferty, J.},
	Journal = {arXiv},
	Number = {0907.1013v1},
	Title = {Visualizing Topics with Multi-Word Expressions},
	Year = {2009}}

@inproceedings{Asuncion:2009,
	Author = {Asuncion, A. and Welling, M. and Smyth, P. and Teh, Y.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {On Smoothing and Inference for Topic Models},
	Year = {2009}}

@inproceedings{Chang:2009a,
	Author = {Chang, J. and Boyd-Graber, J. and Blei, D.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Title = {Connections between the lines: {A}ugmenting Social Networks with Text},
	Year = {2009}}

@inproceedings{Wood:2009,
	Author = {Wood, F. and Archambeau, C. and Gasthaus, J. and James, L. and Teh, Y.},
	Booktitle = {International Conference on Machine Learning},
	Title = {A Stochastic Memoizer for Sequence Data},
	Year = {2009}}

@inproceedings{Hoffman:2010b,
	Author = {Hoffman, M. and Blei, D. and Cook, P.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Bayesian nonparametric factorization for recorded music},
	Year = {2010}}

@article{Clinton:2004,
	Author = {Clinton, J. and Jackman, S. and Rivers, D.},
	Journal = {American Political Science Review},
	Number = {2},
	Pages = {355--370},
	Title = {The Statistical Analysis of Roll Call Data},
	Volume = {98},
	Year = {2004}}

@book{Wickham:2009,
	Author = {Wickham, H.},
	Publisher = {Springer},
	Title = {{GGPlot2}: {E}legant Graphics for Data Analysis},
	Year = {2009}}

@inproceedings{Liang:2009,
	Author = {Liang, P. and Jordan, M. and Klein, D.},
	Booktitle = {Association of Computational Linguisitics},
	Title = {Learning Semantic Correspondences with Less Supervision},
	Year = {2009}}

@inproceedings{Snyder:2008,
	Author = {Snyder, B. and Naseem, T. and Eisenstein, J. and Barzilay, R.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {Unsupervised Multilingual Learning for {POS} Tagging},
	Year = {2008}}

@article{Papasiliopoulos:2008,
	Author = {Papasiliopoulos, O. and Roberts, G.},
	Journal = {Biometrika},
	Pages = {169--186},
	Title = {Retrospective {M}arkov chain {M}onte {C}arlo methods for {D}irichlet process hierarchical models},
	Volume = {95},
	Year = {2008}}

@article{Iacus:2008,
	Author = {Iacus, S. and King, G. and Porro, G.},
	Title = {Matching for Causal Inference without Balance Checking},
	Year = {2008}}

@article{King:2001,
	Author = {King, G. and Zeng, L.},
	Title = {Logistic Regression in Rare Events Data},
	Year = {2001}}

@article{King:2007,
	Author = {King, G. and Zeng, L.},
	Journal = {International Studies Quarterly},
	Pages = {183--210},
	Title = {When Can History Be Our Guide? {T}he Pitfalls of Counterfactual Inference},
	Volume = {51},
	Year = {2007}}

@article{Ho:2007,
	Author = {Ho, D. and Imai, K. and King, G. and Stuart, E.},
	Journal = {Political Analysis},
	Pages = {199--236},
	Title = {Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference},
	Volume = {15},
	Year = {2007}}

@article{Imai:2008,
	Author = {Imai, K. and King, G. and Stuart, E.},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Pages = {481--502},
	Title = {Misunderstandings between Experimentalists and Observationalists about Causal Inference},
	Volume = {171},
	Year = {2008}}

@incollection{Howard:2005,
	Author = {Howard, M. and Addis, K. and Jing, B. and Kahana, M.},
	Booktitle = {{LSA}: A Road Toward Meaning},
	Title = {Semantic Structure and Episodic Memory},
	Year = {2005}}

@article{Sterman:1999,
	Author = {Sterman, J. and Wittenberg, J.},
	Journal = {Organization Science},
	Pages = {322--341},
	Title = {Path Dependence, Competition, and Succession in the Dynamics of Scientific Revolution},
	Volume = {10},
	Year = {1999}}

@article{Wray:2005,
	Author = {Wray, K.},
	Journal = {Social Studies of Science},
	Pages = {151--164},
	Title = {Rethinking Scientific Specialization},
	Volume = {35},
	Year = {2005}}

@article{Waal:2008,
	Author = {de Waal, A. and Barnard, E.},
	Title = {Evaluating Topic Models with Stability},
	Year = {2008}}

@article{Polatkan:2009,
	Author = {Polatkan, G. and Jafarpour, S. and Brasoveanu, A. and Hughes, S. and Daubechies, I.},
	Title = {Detection of Forgery in Paintings Using Supervised Learning},
	Year = {2009}}

@article{Jafarpour:2009,
	Author = {Jafarpour, S. and Polatkan, G. and Brevedo, E. and Hughes, S. and Brasoveanu, A. and Daubechies, I.},
	Title = {Stylistic Analysis of Painting Using Complex Wavelets and Random Forest Learning Algorithm},
	Year = {2009}}

@article{Liang:2007b,
	Author = {Liang, P. and Klein, D.},
	Title = {Structured {B}ayesian Nonparametric Models with Variational Inference},
	Year = {2007}}

@inproceedings{Canini:2009,
	Author = {Canini, K. and Shi, L. and Griffiths, T.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Online Inference of Topics with Latent {D}irichlet Allocation},
	Year = {2009}}

@inproceedings{Rao:2007,
	Author = {Rao, V. and Howard, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Retrieved Context and the Discovery of Semantic Structure},
	Year = {2007}}

@article{Sederberg:2009,
	Author = {Sederberg, P. and Howard, M. and Kahana, M.},
	Title = {A Context-based Theory of Recency and Contiguity in Free Recall},
	Year = {2009}}

@inproceedings{Paisley:2009,
	Author = {Paisley, B. and Carin, L.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Nonparametric Factor Analysis with Beta Process Priors},
	Year = {2009}}

@article{Friedman:2008,
	Author = {Friedman, J. and Hastie, T. and Tibshirani, R.},
	Title = {Regularization Paths for Generized Linear Models via Coordinate Descent},
	Year = {2008}}

@article{Harris:1976a,
	Author = {Harris, Z.},
	Journal = {The Journal of Philosophy},
	Pages = {253--276},
	Title = {On a Theory of Language},
	Volume = {73},
	Year = {1976}}

@inproceedings{Alvarez:2009,
	Author = {Alvarez, M. and Luengo, D. and Lawrence, N.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Latent Force Models},
	Year = {2009}}

@article{Daubechies:2009,
	Author = {Daubechies, I.},
	Title = {{ICA} for brain f{MRI} does {NOT} select for independence},
	Year = {2009}}

@article{Harris:1976,
	Author = {Harris, Z.},
	Journal = {American Philosophical Quarterly},
	Title = {A Theory of Language Structure},
	Year = {1976}}

@inproceedings{Teh:2007b,
	Author = {Teh, Y. and Kurihara, K. and Welling, M.},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Collapsed Variational Inference for {HDP}},
	Year = {2007}}

@article{Unknown:2009,
	Author = {Unknown},
	Title = {How to Work Better},
	Year = {2009}}

@article{Ghosh:1992,
	Author = {Ghosh, J. and Mukerjee, R.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Pages = {867--875},
	Title = {Bayesian and Frequentist {B}artlett Corrections for Likelihood Ratio and Conditional Likelihood Ratio Tests},
	Volume = {54},
	Year = {1992}}

@inproceedings{Titov:2008,
	Author = {Titov, I. and McDonald, R.},
	Booktitle = {World Wide Web},
	Title = {Modeling Online Reviews with Multi-grain Topic Models},
	Year = {2008}}

@article{OHara:2009,
	Author = {O'Hara, R. and Sillanpaa, M.},
	Journal = {Bayesian Analysis},
	Pages = {85--118},
	Title = {A Review of {B}ayesian Variable Selection Methods: {W}hat, How, and Which},
	Volume = {4},
	Year = {2009}}

@article{Dahl:2009,
	Author = {Dahl, D.},
	Journal = {Bayesian Analysis},
	Pages = {243--264},
	Title = {Modal Clustering in a Class of Product Partition Models},
	Volume = {4},
	Year = {2009}}

@article{Presser:2008,
	Author = {Presser, A. and Elowitz, M. and Kellis, M. and Kishony, R.},
	Journal = {Proceedings of the National Academy of Science},
	Pages = {950--954},
	Title = {The evolutionary dynamics of the {S}accharomyce cerevisiae protein interaction network after duplication},
	Volume = {105},
	Year = {2008}}

@article{King:2006,
	Author = {King, G. and Zeng, L.},
	Journal = {Political Analysis},
	Pages = {131--159},
	Title = {The Dangers of Extreme Counterfactuals},
	Volume = {14},
	Year = {2006}}

@article{Behrens:2009,
	Author = {Behrens, T. and Hunt, L. and Rushworth, M.},
	Journal = {Science},
	Pages = {1160--1164},
	Title = {The Computation of Social Behavior},
	Year = {2009}}

@article{Rogers:2005a,
	Author = {Rogers, S. and Girolami, M.},
	Journal = {Bioinformatics},
	Pages = {3131--3137},
	Title = {A {B}ayesian regression approach to the inference of regulatory networks from gene expression data},
	Volume = {21},
	Year = {2005}}

@article{Harris:1988,
	Author = {Harris, Z. and Mattick Jr., P.},
	Journal = {Annals of the American Academy of Political and Social Science},
	Pages = {73--83},
	Title = {Science Sublanguages and the Prospects for a Global Language of Science},
	Volume = {495},
	Year = {1988}}

@article{Herrera:2009,
	Author = {Herrera, M. and Roberts, D. and Gulbahce, N.},
	Journal = {arXiv},
	Number = {0904.1234v1},
	Title = {Mapping the Evolution of Scientific Ideas},
	Year = {2009}}

@article{Robert:2009,
	Author = {Robert, C. and Chopin, N. and Rousseau, J.},
	Journal = {arXiv},
	Number = {0804.3173v5},
	Title = {Harold {J}effreys' Theory of Probability Revisited},
	Year = {2009}}

@article{Dawid:1973,
	Author = {Dawid, A.},
	Title = {Posterior Expectations for Large Observations},
	Year = {1973}}

@article{Agarawal:2001,
	Author = {Agarawal, D. and Gelfand, A.},
	Title = {Slice {G}ibbs Sampling for Simulation Based Fitting of Spatial Data Models},
	Year = {2001}}

@inproceedings{Tarlow:2008,
	Author = {Tarlow, D. and Zemel, R. and Frey, B.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Flexible Priors for Exemplar-based Clustering},
	Year = {2008}}

@inproceedings{Wang:2009a,
	Author = {Wang, C. and Blei, D. and Li, F.},
	Booktitle = {Computer Vision and Pattern Recognition},
	Title = {Simultaneous Image Classification and Annotation},
	Year = {2009}}

@article{Landauer:1998,
	Author = {Landauer, T. and Foltz, P. and Laham, D.},
	Journal = {Discourse processes},
	Pages = {259--284},
	Title = {An Introduction to Latent Semantic Analysis},
	Volume = {25},
	Year = {1998}}

@book{Cox:1980,
	Author = {Cox, D. R. and Isham, V.},
	Publisher = {Chapman Hall},
	Title = {Point Processes},
	Year = {1980}}

@book{Cinlar:2011,
	Author = {Cinlar, E.},
	Publisher = {Springer.},
	Title = {Probability and Stochastics},
	Year = {2011}}

@book{Cox:1979,
	Author = {Cox, D. R. and Hinkley, D.V.},
	Publisher = {Chapman and Hall},
	Title = {Theoretical Statistics},
	Year = {1979}}

@book{Cover:2006,
	Author = {Cover, T. and Thomas, J.},
	Publisher = {Wiley-Interscience},
	Title = {Elements of Information Theory},
	Year = {2006}}

@article{Dagan:1999,
	Author = {Dagan, I. and Lee, L. and Pereira, F.},
	Journal = {Machine Learning},
	Pages = {43--69},
	Title = {Similarity-Based Models of Word Cooccurrence Probabilities},
	Volume = {34},
	Year = {1999}}

@book{Michalski:1985,
	Author = {Michalski, R. and Carbonell, J. and Mitchell, T.},
	Publisher = {Morgan Kaufmann},
	Title = {Machine Learning: An Artificial Intelligence Approach},
	Year = {1985}}

@article{Cohn:1994,
	Author = {Cohn, D. and Atlas, L. and Ladner, R.},
	Journal = {Machine Learning},
	Number = {2},
	Pages = {201--221},
	Title = {Improving generalization with active learning},
	Volume = {15},
	Year = {1994}}

@article{Schapire:1997,
	Author = {Schapire, R. and Freund, Y.},
	Journal = {J Comput Syst Sci},
	Pages = {119--139},
	Title = {A decision theoretic generalization of on-line learning and an application to boosting},
	Volume = {55},
	Year = {1997}}

@article{Harris:1952,
	Author = {Harris, Z.},
	Journal = {Language},
	Number = {1},
	Pages = {1--30},
	Title = {Discourse Analysis},
	Volume = {28},
	Year = {1952}}

@article{editor:1999,
	Author = {editor},
	Journal = {Language},
	Title = {Zellig Sabbettai Harris},
	Year = {1999}}

@article{Harris:1957,
	Author = {Harris, Z.},
	Journal = {Language},
	Number = {3},
	Pages = {283--340},
	Title = {Co-Occurrence and Transformation in Linguistic Structure},
	Volume = {33},
	Year = {1957}}

@unpublished{Gelman:2008,
	Author = {Gelman, A. and Jakulin, A. and Pittau, M. and Su, Y.},
	Month = {June},
	Title = {A Weakly Informative Default Distribution for Logistic and Other regression Models},
	Year = {2008}}

@inproceedings{Mei:2008,
	Author = {Mei, Q. and Cai, D. and Zhang, D. and Zhai, C.},
	Booktitle = {World Wide Web},
	Title = {Topic Modeling with Network Regularization},
	Year = {2008}}

@inproceedings{Leskovec:2008,
	Author = {Leskovec, J. and Horvitz, E.},
	Booktitle = {World Wide Web},
	Title = {Planetary-Scale Views on a Large Instant-Messaging Network},
	Year = {2008}}

@article{Gold:1967,
	Author = {Gold, E.},
	Journal = {Information and Control},
	Pages = {447--474},
	Title = {Language Identification in the Limit},
	Volume = {10},
	Year = {1967}}

@inproceedings{Jaakkola:1999,
	Author = {Jaakkola, T. and Meila, M. and Jebara, T.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Maximum Entropy Discrimination},
	Year = {1999}}

@article{Box:1980,
	Author = {Box, G.},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Number = {4},
	Pages = {383--430},
	Title = {Sampling and {B}ayes' Inference in Scientific Modeling and Robustness},
	Volume = {143},
	Year = {1980}}

@unpublished{Glynn:2007,
	Author = {Glynn, A. and Quinn, K.},
	Month = {July},
	Title = {Non-parametric Mechanisms and Causal Modeling},
	Year = {2007}}

@article{Box:1979,
	Author = {Box, G.},
	Journal = {Journal of the American Statistical Association},
	Number = {365},
	Pages = {1--4},
	Title = {Some Problems of Statistics and Everyday Life},
	Volume = {74},
	Year = {1979}}

@article{Box:1976,
	Author = {Box, G.},
	Journal = {Journal of the American Statistical Association},
	Number = {356},
	Pages = {791--799},
	Title = {Science and Statistics},
	Volume = {71},
	Year = {1976}}

@article{Box:1966,
	Author = {Box, G.},
	Journal = {Technometrics},
	Number = {4},
	Pages = {625--629},
	Title = {Use and Abuse of Regression},
	Volume = {8},
	Year = {1966}}

@inproceedings{Bradley:2008,
	Author = {Bradley, D. and Bagnell, J.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Differentiable Sparse Coding},
	Year = {2008}}

@book{Banerjee:2004,
	Author = {Banerjee, S. and Carlin, B. and Gelfand, A.},
	Publisher = {Chapman \& Hall/CRC},
	Title = {Hierarchical modeling and analysis for spatial data},
	Year = {2004}}

@article{Ishwaran:2005,
	Author = {Ishwaran, Hemant and Rao, J. Sunil},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {730--773},
	Title = {Spike and Slab Variable Selection: {F}requentist and {B}ayesian Strategies},
	Volume = {33},
	Year = {2005}}

@inproceedings{Zhou:2011,
	Author = {Zhou, Mingyuan and Yang, Hongxia and Sapiro, Guillermo and Dunson, David B and Carin, Lawrence},
	Booktitle = {International conference on artificial intelligence and statistics},
	Pages = {883--891},
	Title = {Dependent hierarchical beta process for image interpolation and denoising},
	Year = {2011}}

@inproceedings{Boyd-Graber:2009a,
	Author = {Boyd-Graber, J. and Blei, D.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Syntactic Topic Models (Supplement)},
	Year = {2009}}

@conference{Ren:2008,
	Author = {Ren, L. and Dunson, D. and Carin, L.},
	Booktitle = {International Conference on Machine Learning},
	Organization = {ACM New York, NY, USA},
	Pages = {824--831},
	Title = {The Dynamic Hierarchical {D}irichlet process},
	Year = {2008}}

@book{Box:1990,
	Author = {Box, G. and Jenkins, G.},
	Publisher = {Holden-Day, Incorporated},
	Title = {Time Series Analysis, Forecasting and Control},
	Year = {1990}}

@article{Doucet:2008,
	Author = {Doucet, A. and Johansen, A.},
	Title = {A Tutorial on Particle Filtering and Smoothing: {F}ifteen years Later},
	Year = {2008}}

@inproceedings{Caron:2007,
	Author = {Caron, F. and Davy, M. and Doucet, A.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Generalized {P}oly Urn for Time-varying {D}irichlet Process Mixtures},
	Year = {2007}}

@article{MacKay:2000,
	Author = {MacKay, R. and Oldford, R.},
	Journal = {Statistical Science},
	Number = {3},
	Title = {Scientific Method, Statistical Method, and the Speed of Light},
	Volume = {15},
	Year = {2000}}

@article{Chubin:1976,
	Author = {Chubin, D.},
	Journal = {The Sociological Quarterly},
	Pages = {448--476},
	Title = {The Conceptualizaation of Scientific Specialties},
	Year = {1976}}

@article{Enfield:1991,
	Author = {Enfield, P.},
	Journal = {Philosophy of Science},
	Number = {3},
	Title = {Empiricism and the Scientific Revolutions},
	Volume = {58},
	Year = {1991}}

@inproceedings{Kuhn:1990,
	Author = {Kuhn, T.},
	Booktitle = {Proceedings of the Biennial Meeting of the Philosophy of Science Association},
	Pages = {3--13},
	Title = {The Road Since Structure},
	Year = {1990}}

@article{Stanfield:1974,
	Author = {Stanfield, R.},
	Journal = {Journal of Economic Issues},
	Number = {1},
	Pages = {97--109},
	Title = {Kuhnian Scientific Revolutios and the Keynesian Revolution},
	Volume = {8},
	Year = {1974}}

@article{Kuhn:1962,
	Author = {Kuhn, T.},
	Journal = {Science},
	Number = {3518},
	Title = {Historical Structure of Scientific Discovery},
	Volume = {136},
	Year = {1962}}

@unpublished{Donahue:2008,
	Author = {Donahue, R.},
	Month = {July},
	Title = {Fundamental Statistical Concepts in Presenting Data},
	Year = {2008}}

@inproceedings{Chang:2009,
	Author = {Chang, J. and Blei, D.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Relational Topic Models for Document Networks},
	Year = {2009}}

@inproceedings{Wang:2009,
	Author = {Wang, C. and Thiesson, B. and Meek, C. and Blei, D.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Markov Topic Models},
	Year = {2009}}

@inproceedings{Ho:2008,
	Author = {Ho, D. and Quinn, K.},
	Booktitle = {Quarterly Journal of Political Science},
	Pages = {353--377},
	Title = {Measuring Explicit Political Positions of Media},
	Volume = {3},
	Year = {2008}}

@inproceedings{Fox:2008,
	Author = {Fox, E. and Sudderth, E. and Jordan, M. and Willsky, A.},
	Booktitle = {International Conference on Machine Learning},
	Title = {An {HDP-HMM} for Systems with State Persistence},
	Year = {2008}}

@inproceedings{Sanborn:2008,
	Author = {Sanborn, A. and Griffiths, T. and Navarro, D.},
	Booktitle = {Cognitive Science},
	Title = {A More Rational Model of Categorization},
	Year = {2008}}

@article{Fearnhead:2004,
	Author = {Fearnhead, P.},
	Journal = {Statistics and Computing},
	Title = {Particle Filters for Mixture Models with an Unknown Number of Components},
	Year = {2004}}

@techreport{Carvalho:2008,
	Author = {Carvalho, C. and Johanes, M. and Lopes, H. and Polson, N.},
	Institution = {University of Chicago},
	Title = {Particle Learning and Smoothing},
	Year = {2008}}

@article{Rosvall:2008,
	Author = {Rosvall, M. and Bergstrom, C.},
	Journal = {arXiv},
	Number = {12.1242v1},
	Title = {Mapping Change in Large Networks},
	Year = {2008}}

@inproceedings{Lacoste-Julien:2009,
	Author = {Lacoste-Julien, S. and Sha, F. and Jordan, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Disc{LDA}: {D}iscriminative Learning for Dimensionality Reduction and Classification},
	Year = {2009}}

@inproceedings{Daume:2007,
	Address = {San Juan, Puerto Rico},
	Author = {Daume, H.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Fast search for Dirichlet process mixture models},
	Year = {2007}}

@inproceedings{Liang:2007a,
	Author = {Liang, P. and Jordan, M. and Taskar, B.},
	Booktitle = {ICML},
	Title = {A permutation-augmented sampler for {DP} mixture models},
	Year = {2007}}

@techreport{Zhu:2005,
	Author = {Zhu, X. and Ghahramani, Z. and Lafferty, J.},
	Institution = {Carnegie Mellon University},
	Number = {CMU-CALD-05-104},
	Title = {Time-Sensitive {D}irichlet Process Mixture Models},
	Year = {2005}}

@inproceedings{Ahmed:2008,
	Author = {Ahmed, A. and Xing, E.},
	Booktitle = {International Conference on Data Mining},
	Title = {Dynamic Non-Parametric Mixture Models and the Recurrent {C}hinese Restaurant Process with applications to evolutionary clustering},
	Year = {2008}}

@article{Ritter:1992,
	Author = {Ritter, C. and Tanner, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {419},
	Pages = {861--868},
	Title = {Facilitating the {G}ibbs sampler: {T}he {G}ibbs stopper and the {G}riddy-{G}ibbs sampler},
	Volume = {87},
	Year = {1992}}

@article{Geyer:1992,
	Author = {Geyer, C. and Thompson, E.},
	Journal = {Journal of the American Statistical Association},
	Number = {657--699},
	Title = {Constrained {M}onte {C}arlo maximum likelihood for dependent data},
	Volume = {54},
	Year = {1992}}

@inproceedings{Bosch:2006,
	Author = {Bosch, A. and Zisserman, A. and Munoz, X.},
	Booktitle = {ECCV},
	Title = {Scene Classification via p{LSA}},
	Year = {2006}}

@inproceedings{Zhang:2004,
	Author = {Zhang, J. and Ghahramani, Z. and Yang, Y.},
	Booktitle = {Neural Information Processing Systems},
	Title = {A Probabilistic Model for Online Document Clustering with Application to Novelty Detection},
	Year = {2004}}

@inproceedings{Raftery:2007,
	Author = {Raftery, A. and Newton, M. and Satagopan, J. and Krivitsky, P.},
	Booktitle = {Bayesian Statistics 8},
	Pages = {1--45},
	Title = {Estimating the Integrated Likelihood via Posterior Simulation Using the Harmonic Mean Identity},
	Year = {2007}}

@article{Meng:1996,
	Author = {Meng, X. and Wong, W.},
	Journal = {Statistica Sinica},
	Pages = {831--860},
	Title = {Simulating Ratios of Normalizing Constants via a Simple Identity: {A} Theoretical Exploration},
	Volume = {6},
	Year = {1996}}

@article{Meng:1998,
	Author = {Meng, X. and Gelman, A.},
	Journal = {Statistical Science},
	Number = {2},
	Pages = {163--185},
	Title = {Simulating Normalizing Constants: {F}rom Importance Sampling to Bridge Sampling to Path Sampling},
	Volume = {13},
	Year = {1998}}

@article{Wiggins:2008,
	Author = {Wiggins, C. and Hofman, J.},
	Journal = {Physical Review Letters},
	Number = {25},
	Title = {Bayesian approach to network modularity},
	Volume = {100},
	Year = {2008}}

@unpublished{Jordan:2009,
	Author = {Jordan, M.},
	Title = {An Introduction to Probabilistic Graphical Models},
	Year = {2009}}

@article{MacKay:1994,
	Author = {MacKay, D. and Peto, L.},
	Journal = {Natural Language Engineering},
	Title = {A hierarchical {D}irichlet language model},
	Year = {1994}}

@article{Dunson:2006,
	Author = {Dunson, D.},
	Journal = {Biostatistics},
	Title = {Bayesian dynamic modeling of latent trait distributions},
	Year = {2006}}

@article{Blitzstein:2006,
	Author = {Blitzstein, J. and Diaconis, P.},
	Title = {A Sequential Importance Sampling Algorithm for Generating Random Graphs with Prescribed Degrees},
	Year = {2006}}

@incollection{Diaconis:2001,
	Author = {Diaconis, P. and Graham, R. and Holmes, S.},
	Booktitle = {State of the art in probability and statistics: Festschrift for Willem R. van Zwet, Papers from the symposium held at the University of Leiden, Leiden, March 23--26, 1999},
	Editor = {de Gunst, M. and Klaasen, C. and van der Vaart, A.},
	Publisher = {Institute of Mathematical Statistics},
	Title = {Statistical Problems Involving Permutations with Restricted Positions},
	Year = {2001}}

@article{Opper:2005,
	Author = {Opper, M. and Winther, O.},
	Journal = {Journal of Machine Learning Research},
	Pages = {2177--2204},
	Title = {Expectation Consistent Approximate Inference},
	Volume = {6},
	Year = {2005}}

@incollection{Blei:2009,
	Author = {Blei, D. and Lafferty, J.},
	Booktitle = {Text Mining: Theory and Applications},
	Editor = {Srivastava, A. and Sahami, M.},
	Publisher = {Taylor and Francis},
	Title = {Topic Models},
	Year = {2009}}

@inproceedings{Airoldi:2009,
	Author = {Airoldi, E. and Blei, D. and Fienberg, S. and Xing, E.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Mixed Membership Stochastic Blockmodels},
	Year = {2009}}

@inproceedings{Boyd-Graber:2009,
	Author = {Boyd-Graber, J. and Blei, D.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Syntactic Topic Models},
	Year = {2009}}

@inproceedings{Mukherjee:2009,
	Author = {Mukherjee, I. and Blei, D.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Relative Performance Guarantees for Approximate Inference in Latent {D}irichlet Allocation},
	Year = {2009}}

@inproceedings{Hall:2008,
	Author = {Hall, D. and Jurafsky, D. and Manning, C.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {Studying the History of Ideas Using Topic Models},
	Year = {2008}}

@inbook{Steyvers:2008,
	Author = {Steyvers, M. and Griffiths, T.},
	Chapter = {Rational Analysis as a Link between Human Memory and Information Retrieval},
	Publisher = {Oxford University Press},
	Title = {The Probabilistic Mind: {P}rospects from Rational Models of Cognition},
	Year = {2008}}

@article{Pang:2008,
	Author = {Pang, B. and Lee, L.},
	Journal = {Foundations and Trends in Information Retrieval},
	Number = {1--2},
	Title = {Opinion Mining and Sentiment Analysis},
	Volume = {2},
	Year = {2008}}

@article{Hsu:2008,
	Author = {Hsu, D. and Kakade, S. and Zhang, T.},
	Journal = {arXiv},
	Number = {11.4413v2},
	Title = {A Spectral Algorithm for Learning Hidden Markov Models},
	Year = {2008}}

@inproceedings{Kakade:2008,
	Author = {Kakade, S. and Shalev-Shwartz, S.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Mind the Duality Gap: {L}ogarithmic Regret Algorithms for Online Optimization},
	Year = {2008}}

@article{Kaban:2006,
	Author = {Kaban, A. and Bingham, E. and Hirismaki, T.},
	Journal = {arXiv},
	Title = {Learning to Read Between the Lines: {T}he Aspect {B}ernoulli Model},
	Year = {2006}}

@article{Feng:1996,
	Author = {Feng, Z. and McCulloch, C.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {3},
	Pages = {609--617},
	Title = {Using Bootstrap Likelihood Ratios in Finite Mixture Models},
	Volume = {58},
	Year = {1996}}

@article{Shapere:1964,
	Author = {Shapere, D.},
	Journal = {Philosophical Review},
	Number = {3},
	Title = {The Structure of Scientific Revolutions},
	Volume = {73},
	Year = {1964}}

@inproceedings{Tang:1984,
	Author = {Tang, P.},
	Booktitle = {Proceedings of the Biennial Meeting of the Philosophy of Science Association},
	Title = {Paradigm Shifts, Scientific Revolutions, and the Unit of Scientific Change: Towards a Post-Kuhnian Theory of Types of Scientific Development},
	Year = {1984}}

@article{Marriot:2002,
	Author = {Marriot, P.},
	Journal = {Biometrika},
	Number = {1},
	Title = {On the Local Geometry of Mixture Models},
	Volume = {89},
	Year = {2002}}

@article{Kemp:2008,
	Author = {Kemp, C. and Tenenbaum, J.},
	Journal = {Proceedings of the National Academy of Science},
	Number = {31},
	Pages = {10687--10692},
	Title = {The Discovery of Structural Form},
	Volume = {5},
	Year = {2008}}

@article{Zhu:2008,
	Author = {Zhu, X. and Goldberg, A. and Rabbat, A. and Nowak, R.},
	Title = {Learning Bigrams from Unigrams},
	Year = {2008}}

@article{Pedersen:2008,
	Author = {Pedersen, T.},
	Journal = {Computational Linguistics},
	Title = {Empiricism is Not a Matter of Faith},
	Year = {2008}}

@article{Freedman:2000,
	Author = {Freedman, D.},
	Journal = {Chance},
	Title = {Oasis or Mirage},
	Year = {2000}}

@techreport{Krivitsky:2007,
	Author = {Krivitsky, P. and Handcock, M. and Raftery, A.},
	Institution = {University of Washington},
	Title = {Representing Degree Distributions, Clustering, and Homophily in Social Networks with Latent Cluster Random Effects Models},
	Year = {2007}}

@inproceedings{Collins:2002,
	Author = {Collins, M. and Dasgupta, S. and Schapire, R.},
	Booktitle = {Neural Information Processing Systems},
	Title = {A Generalization of Principal Component Analysis to the Exponential Family},
	Year = {2002}}

@article{Friedman:2007,
	Author = {Friedman, J. and Hastie, T. and Hofling, H. and Tibshirani, R.},
	Journal = {Annals of Applied Statistics},
	Number = {2},
	Pages = {302--332},
	Title = {Pathwise Coordinate Optimization},
	Volume = {1},
	Year = {2007}}

@article{Witten:2008,
	Author = {Witten, D. and Tibshirani, R.},
	Journal = {Annals of Applied Statistics},
	Title = {Testing Significance of Features by Lassoed Principal Components},
	Year = {2008}}

@article{Rubin:2008,
	Author = {Rubin, D.},
	Journal = {Annals of Applied Statistics},
	Title = {For Objective Causal Inference, Design Trumps Analysis},
	Year = {2008}}

@article{Diaconis:2008,
	Author = {Diaconis, P. and Goel, S. and Holmes, S.},
	Journal = {Annals of Applied Statistics},
	Title = {Horshoes in Multidimensional Scaling and Local Kernel Methods},
	Year = {2008}}

@article{Johnstone:2004,
	Author = {Johnstone, I. and Lu, A.},
	Title = {Sparse Principal Components Analysis},
	Year = {2004}}

@unpublished{Stone:2008,
	Author = {Stone, M.},
	Title = {Expert Color Choices for Presenting Data},
	Year = {2008}}

@inproceedings{Lazebnik:2006,
	Author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
	Booktitle = {CVPR},
	Title = {Beyond Bags of Features: {S}patial Pyramid Matching for Recognizing Natural Scene Categories},
	Year = {2006}}

@inproceedings{Zhao:2007,
	Author = {Zhao, B. and Xing, E.},
	Booktitle = {Neural Information Processing Systems},
	Title = {HM-BiTAM: {B}ilingual Topic Exploration, Word Alignment, and Translation},
	Year = {2007}}

@article{Braun:2010,
	Author = {Braun, M. and McAuliffe, J.},
	Journal = {Journal of American Statistical Association},
	Number = {489},
	Title = {Variational inference for large-scale models of discrete choice},
	Volume = {105},
	Year = {2007}}

@techreport{Weber:2008,
	Author = {Weber, M. and Osherson, D.},
	Institution = {Princeton University},
	Title = {Similarity and Induction},
	Year = {2008}}

@incollection{Teh:2010a,
	Author = {Y. W. Teh and M. I. Jordan},
	Booktitle = {Bayesian Nonparametrics: Principles and Practice},
	Editor = {N. Hjort and C. Holmes and P. M{\"u}ller and S. Walker},
	Publisher = {Cambridge University Press},
	Title = {Hierarchical {B}ayesian Nonparametric Models with Applications},
	Year = {2010}}

@inproceedings{Rish:2008,
	Address = {New York, NY, USA},
	Author = {Rish, I. and Grabarnik, G. and Cecchi, G. and Pereira, F. and Gordon, G.},
	Booktitle = {ICML},
	Pages = {832--839},
	Publisher = {ACM},
	Title = {Closed-form supervised dimensionality reduction with generalized linear models},
	Year = {2008}}

@book{Harvey:1991,
	Author = {Harvey, A.},
	Publisher = {Cambridge University Press},
	Title = {Forecasting, Structural Time Series Models and the {K}alman Filter},
	Year = {1991}}

@book{Shumway:2000,
	Author = {Shumway, R. and Stoffer, D.},
	Publisher = {Springer},
	Series = {Springer Texts in Statistics},
	Title = {Time Series Analysis and its Applications},
	Year = {2000}}

@inproceedings{Mimno:2008,
	Author = {Mimno, D. and McCallum, A.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Topic Models Conditioned on Arbitrary Features with {D}irichlet-multinomial Regression},
	Year = {2008}}

@article{Airoldi:2008,
	Author = {Airoldi, E. and Blei, D. and Fienberg, S. and Xing, E.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1981--2014},
	Title = {Mixed Membership Stochastic Blockmodels},
	Volume = {9},
	Year = {2008}}

@article{Hui:2008,
	Author = {Hui, S. and Huang, Y. and George, E.},
	Journal = {Bayesian Analysis},
	Number = {1},
	Pages = {1--34},
	Title = {Model-based Analysis of Concept Maps},
	Volume = {3},
	Year = {2008}}

@article{Robert:2008,
	Author = {Robert, C. and Marin, J.},
	Journal = {Bayesian Analysis},
	Number = {2},
	Pages = {427--442},
	Title = {On Some Difficulties with a Posterior Probability Approximation Technique},
	Volume = {3},
	Year = {2008}}

@inproceedings{Liang:2008,
	Author = {Liang, P. and Jordan, M.},
	Booktitle = {International Conference on Machine Learning},
	Title = {An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators},
	Year = {2008}}

@inproceedings{Qi:2006,
	Author = {Qi, Y. and Jaakkola, T.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Parameter Expanded Variational Bayesian Methods},
	Year = {2006}}

@inproceedings{Ahmed:2007,
	Author = {Ahmed, A. and Xing, E.},
	Booktitle = {International Conference on Artifical Intelligence and Statistics},
	Title = {On Tight Approximate Inference of the Logistic Normal Topic Admixture Model},
	Year = {2007}}

@article{Stromsten:2007,
	Author = {Stromsten, S.},
	Title = {Discovering Regions and Activity Patterns from Geolocated Event Data},
	Year = {2007}}

@inproceedings{Pedersen:1996a,
	Author = {Pedersen, T.},
	Booktitle = {Proceedings of the South Central SAS Users Group},
	Title = {Fishing for Exactness},
	Year = {1996}}

@inproceedings{Ackermann:2008,
	Author = {Ackermann, M. and Blomer, J. and Sohler, C.},
	Title = {Clustering for Metric and Non-Metric Distance Measures},
	Year = {2008}}

@inproceedings{Xue:2007,
	Author = {Xue, Y. and Dunson, D. and Carin, L.},
	Booktitle = {International Conference on Machine Learning},
	Title = {The Matrix Stick-Breaking Process for Flexible Multi-Task Learning},
	Year = {2007}}

@inproceedings{Hoffman:2008a,
	Author = {Hoffman, M. and Blei, D. and Cook, P.},
	Booktitle = {International Conference on Music Information Retrieval},
	Title = {Content-Based Musical Similarity Computation Using the Hierarchical {D}irichlet Process},
	Year = {2008}}

@inproceedings{Hoffman:2008,
	Author = {Hoffman, M. and Cook, P. and Blei, D.},
	Booktitle = {International Computer Music Conference},
	Title = {Data-driven Recomposition Using the Hierarchical {D}irichlet Process Hidden {M}arkov Model},
	Year = {2008}}

@unpublished{McCallum:2005,
	Author = {Mc{C}allum, A.},
	Title = {http://Rexa.info},
	Year = {2005}}

@inproceedings{Moore:2004,
	Author = {Moore, R.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {On Log-Likelihood-Ratios and the Significance of Rare Events},
	Year = {2004}}

@article{Pitman:1937,
	Author = {Pitman, E.},
	Journal = {Journal of the Royal Statistical Society},
	Number = {1},
	Title = {Significance Tests Which May be Applied to Samples from Any Population},
	Volume = {4},
	Year = {1937}}

@book{Good:2000,
	Author = {Good, P.},
	Publisher = {Springer},
	Title = {Permutation Tests: {A} Practical Guide to Resampling Methods for Testing Hypotheses},
	Year = {2000}}

@inproceedings{Seymore:1996,
	Author = {Seymore, K. and Rosenfeld, R.},
	Booktitle = {International Conference on Spoken Language},
	Title = {Scalable Back-off Language Models},
	Year = {1996}}

@article{Katz:1987,
	Author = {Katz, S.},
	Journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	Number = {3},
	Title = {Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer},
	Volume = {35},
	Year = {1987}}

@article{Ney:1995,
	Author = {Ney, H. and Essen, U. and Knesser, R.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {12},
	Title = {On the estimation of 'small' probabilities by leaving-one-out},
	Volume = {17},
	Year = {1995}}

@inproceedings{Stolcke:1998,
	Author = {Stolcke, A.},
	Title = {Entropy-based Prining of Backoff Language Models},
	Volume = {Proc. DARPA Broadcast News Transcription and Understanding Workshop},
	Year = {1998}}

@inproceedings{Wang:2007,
	Author = {Wang, X. and Mc{C}allum, A. and Wei, X.},
	Booktitle = {International Conference on Data Mining},
	Title = {Topical {N}-grams: {P}hrase and Topic Discovery, with an Application to Information Retrieval},
	Year = {2007}}

@article{Dunning:1993,
	Author = {Dunning, T.},
	Journal = {Computational Linguistics},
	Number = {1},
	Title = {Accurate Methods for the Statistics of Surprise and Coincidence},
	Volume = {19},
	Year = {1993}}

@inproceedings{Pedersen:1996,
	Author = {Pedersen, T. and Kayaalp, M. and Bruce, R.},
	Booktitle = {AAAI Conference on Artificial Intelligence},
	Title = {Significant Lexical Relationships},
	Year = {1996}}

@inproceedings{Marlin:2003,
	Author = {Marlin, B.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Modeling User Rating Profiles for Collaborative Filtering},
	Year = {2003}}

@article{Sinkkonen:2008,
	Author = {Sinkkonen, J. and Aukia, J. and Kaski, S.},
	Journal = {arXiv},
	Number = {0803.1628v1},
	Title = {Component Models for Large Networks},
	Year = {2008}}

@inproceedings{Balcan:2008,
	Author = {Balcan, M. and Blum, A. and Vempala, S.},
	Booktitle = {STOC},
	Title = {A Discrimative Framework for Clustering via Similarity Functions},
	Year = {2008}}

@article{Palla:2005,
	Author = {Palla, G. and Dereny, I. and Farkas, I. and Vicsek, T.},
	Journal = {arXiv},
	Title = {Uncovering the overlapping community structure of complex networks in society and nature},
	Volume = {0506133v1},
	Year = {2005}}

@article{Newman:2007a,
	Author = {Newman, M. and Leicht, E.},
	Journal = {arXiv},
	Number = {0611158v3},
	Title = {Mixture Models and Exploratory Analysis in Networks},
	Year = {2007}}

@article{Leicht:2007,
	Author = {Leicht, E. and Newman, M.},
	Journal = {arXiv},
	Number = {0709.4500v1},
	Title = {Community Structure in Directed Networks},
	Year = {2007}}

@techreport{Gentzkow:2006,
	Author = {Gentzkow, M. and Shapiro, J.},
	Institution = {National Bureau of Economic Research},
	Number = {12707},
	Title = {What Drives Media Slant? {E}vidence from {U.S.} Daily Newspapers},
	Year = {2006}}

@article{Amari:2001,
	Author = {Amari, S.},
	Journal = {IEEE Transactions on Information Theory},
	Number = {5},
	Pages = {1701--1711},
	Title = {Information Geometry on Hierarchy of Probability Distributions},
	Volume = {47},
	Year = {2001}}

@article{Lindsay:1983a,
	Author = {Lindsay, B.},
	Journal = {Annals of Statistics},
	Number = {1},
	Title = {The Geometry of Mixture Likelihoods: {A} General Theory},
	Volume = {11},
	Year = {1983}}

@article{Lindsay:1983,
	Author = {Lindsay, B.},
	Journal = {Annals of Statistics},
	Number = {3},
	Title = {The Geometry of Mixture Likelihoods, Part II: {T}he Exponential Family},
	Volume = {11},
	Year = {1983}}

@inproceedings{Wang:2008,
	Author = {Wang, C. and Blei, D. and Heckerman, D.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Continuous Time Dynamic Topic Models},
	Year = {2008}}

@book{Cinlar:2006b,
	Author = {Cinlar, E.},
	Title = {Lecture Notes in Probability Theory},
	Year = {2006}}

@article{Lethem:2006,
	Author = {Lethem, J.},
	Journal = {Rolling Stone},
	Title = {The Genius of Bob Dylan},
	Year = {2006}}

@phdthesis{Lawrence:2000,
	Author = {Lawrence, N.},
	Title = {Variational Inference in Probabilistic Models},
	Year = {2000}}

@inproceedings{Sontag:2007,
	Author = {Sontag, D. and Jaakkola, T.},
	Booktitle = {Neural Information Processing Systems},
	Title = {New Outer Bounds on the Marginal Polytope},
	Year = {2007}}

@techreport{Zhu:2006a,
	Author = {Zhu, X. and Blei, D. and Lafferty, J.},
	Institution = {University of Wisconsin, Computer Science Department},
	Title = {Tag{LDA}: {B}ringing Document Structure Knowledge Into Topic Models},
	Year = {2006}}

@inproceedings{Mei:2007a,
	Author = {Mei, Q. and Ling, X. and Wondra, M. and Su, H. and Zhai, C.},
	Booktitle = {World Wide Web},
	Title = {Topic Sentiment Mixture: {M}odeling Facets and Opinions in Weblogs},
	Year = {2007}}

@phdthesis{Sudderth:2006,
	Author = {Sudderth, E.},
	Title = {Graphical Models for Visual Object Recognition and Tracking},
	Year = {2006}}

@inproceedings{Snow:2004,
	Author = {Snow, R. and Jurafsky, D. and Ng, A.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Learning Syntactic Patterns for Automatic Hypernym Discovery},
	Year = {2004}}

@article{Gelman:2005a,
	Author = {Gelman, A.},
	Journal = {Bayesian Analysis},
	Number = {2},
	Pages = {1--19},
	Title = {Prior Distributions for Variance Parameters in Hierarchical Models},
	Volume = {1},
	Year = {2005}}

@article{Ishwaran:2003a,
	Author = {Ishwaran, H. and James, L.},
	Title = {Some Further Developments for Stick-Breaking Priors: {F}inite and Infinite Clustering and Classification},
	Year = {2003}}

@unpublished{Lancia:2005,
	Author = {Lancia, F.},
	Title = {Word Co-Occurrence and the Theory of Meaning},
	Year = {2005}}

@unpublished{Minka:2000a,
	Author = {Minka, T.},
	Title = {Visualization Talk},
	Year = {2000}}

@article{Nelson:1985,
	Author = {Nelson, J.},
	Journal = {Journal of the American Statistical Association},
	Number = {392},
	Pages = {828--834},
	Title = {Multivariate {G}ama-{P}oisson Models},
	Volume = {80},
	Year = {1985}}

@inproceedings{Rennie:2003,
	Author = {Rennie, J. and Shih, L. and Teevan, J. and Karger, D.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Tacking the Poor Assumptions of Naive Bayes Text Classifiers},
	Year = {2003}}

@article{Burschtein:1992,
	Author = {Burschtein, D. and Della Pietra, V. and Kanevsky, D. and Nadas, A.},
	Journal = {Annals of Statistics},
	Number = {3},
	Pages = {1637--1646},
	Title = {Minimum Impurity Partitions},
	Volume = {20},
	Year = {1992}}

@inproceedings{Adler:2007,
	Author = {Adler, B. and Alfaro, L.},
	Booktitle = {World Wide Web},
	Title = {A Content-Driven Reputation System for the Wikipedia},
	Year = {2007}}

@inproceedings{Amanatidis:2007,
	Author = {Amanatidis, C. and Sideri, M. and Karp, R. and Papadimitriou, C.},
	Booktitle = {SODA '07: Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms},
	Title = {Linked Decompositions of Networks and the Power of Choice in {P}olya Urns},
	Year = {2007}}

@book{Dobson:2007,
	Author = {Dobson, A.},
	Publisher = {Chapman \& Hall},
	Title = {Generalized Linear Models},
	Year = {2007}}

@inproceedings{Bouchard-Cote:2007,
	Author = {Bouchard-Cote, A. and Liang, P. and Griffiths, T. and Klein, D.},
	Booktitle = {Neural Information Processing Systems},
	Title = {A Probabilistic Approach to Language Change},
	Year = {2007}}

@article{Tieu:2004,
	Author = {Tieu, K. and Viola, P.},
	Journal = {International Journal of Computer Vision},
	Pages = {17--36},
	Title = {Boosting Image Retrieval},
	Volume = {56},
	Year = {2004}}

@inproceedings{Newman:2007,
	Author = {Newman, D. and Asuncion, A. and Smyth, P. and Welling, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Distributed inference for Latent {D}irichlet Allocation},
	Year = {2007}}

@inproceedings{Buntine:2002,
	Author = {Buntine, W.},
	Booktitle = {European Conference on Machine Learning},
	Title = {Variational extentions to {EM} and multinomial {PCA}},
	Year = {2002}}

@inproceedings{Toutanova:2007,
	Author = {Toutanova, K. and Johnson, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {A {B}ayesian {LDA}-based model for semi-supervised part-of-speech tagging},
	Year = {2007}}

@inproceedings{Smith:2005,
	Author = {Smith, N. and Eisner, J.},
	Booktitle = {Association of Computational Linguisitics},
	Title = {Contrastive Estimation: {T}raining Log-Linear Models on Unlabeled Data},
	Year = {2005}}

@article{Pantel:2001,
	Author = {Pantel, P. and Lin, D.},
	Title = {Discovering Word Senses from Text},
	Year = {2001}}

@article{Blevins:1999,
	Author = {Blevins, J.},
	Journal = {Transactions of the Philological Society},
	Number = {2},
	Title = {Morphological Paradigms},
	Volume = {99},
	Year = {1999}}

@unpublished{Saul:1995,
	Author = {Saul, L. and Jordan, M.},
	Title = {Attractor Dynamics in Feedfoward Neural Networks},
	Year = {1995}}

@techreport{Buntine:2004a,
	Author = {Buntine, W. and Perttu, S. and Tuulos, V.},
	Institution = {Information Technology Society Program},
	Title = {Using Discrete {PCA} on Web Pages},
	Year = {2004}}

@inproceedings{Buntine:2003,
	Author = {Buntine, W. and Perttu, S.},
	Booktitle = {Artificial Intelligence and Statistics},
	Editor = {Bishop, C. and Frey, B.},
	Pages = {300--307},
	Title = {Is Multinomial {PCA} Multi-faceted Clustering or Dimensionality Reduction?},
	Year = {2003}}

@article{Hastie:1987,
	Author = {Hastie, T.},
	Journal = {The American Statistician},
	Number = {1},
	Pages = {16--20},
	Title = {A Closer Look at the Deviance},
	Volume = {41},
	Year = {1987}}

@article{Kass:1989a,
	Author = {Kass, R.},
	Journal = {Statistical Science},
	Number = {3},
	Pages = {188--219},
	Title = {The Geometry of Asymptotic Inference},
	Volume = {4},
	Year = {1989}}

@article{Barndorff-Nielsen:1986,
	Author = {Barndorff-Nielsen, O. and Cox, D. and Reid, N.},
	Journal = {International Statistical Review},
	Number = {1},
	Pages = {83--96},
	Title = {The Role of Differential Geometry in Statistical Theory},
	Volume = {54},
	Year = {1986}}

@article{Schapire:2000,
	Author = {Schapire, R. and Singer, Y.},
	Journal = {Machine Learning},
	Pages = {135--168},
	Title = {Boos{T}exter: {A} Boosting-based System for Text Categorization},
	Volume = {39},
	Year = {2000}}

@book{Durrett:1999,
	Author = {Durrett, R.},
	Publisher = {Springer},
	Title = {Essentials of Stochastic Processes},
	Year = {1999}}

@inproceedings{Blei:2006d,
	Author = {Blei, D. and Lafferty, J.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Dynamic topic models},
	Year = {2006}}

@inproceedings{Elkan:2006,
	Author = {Elkan, C.},
	Booktitle = {International Conference on Machine Learning},
	Pages = {289--296},
	Title = {Clustering documents with an exponential-family approximation of the {D}irichlet-compound multinomial},
	Year = {2006}}

@book{Tufte:1983,
	Address = {Box 430, Cheshire, CT 06410, USA},
	Author = {Tufte, E.},
	Publisher = {Graphics Press},
	Title = {The Visual Display of Quantitative Information},
	Year = {1983}}

@book{Duda:2000,
	Author = {Duda, R. and Hart, P. and Stork, D.},
	Publisher = {Wiley-Interscience Publication},
	Title = {Pattern Classification},
	Year = {2000}}

@inproceedings{Heller:2005,
	Author = {Heller, K. and Ghahramani, Z.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Bayesian Hierarchical Clustering},
	Year = {2005}}

@article{Cimiano:2005,
	Author = {Cimiano, P. and Hotho, A. and Staab, S.},
	Journal = {Journal of Artificial Intelligence Research},
	Number = {305--339},
	Title = {Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis},
	Year = {2005}}

@inproceedings{Vaithyanathan:2000,
	Address = {San Francisco, CA, USA},
	Author = {Vaithyanathan, Shivakumar and Dom, Byron},
	Booktitle = {Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence},
	Pages = {599--608},
	Publisher = {Morgan Kaufmann publishers Inc.},
	Title = {Model-Based Hierarchical Clustering},
	Year = {2000}}

@inproceedings{Dumais:2000,
	Author = {Dumais, S. and Chen, H.},
	Booktitle = {ACM SIGIR},
	Pages = {256--263},
	Title = {Hierarchical classification of web content},
	Year = {2000}}

@inproceedings{Goldberg:1986,
	Address = {New York, NY, USA},
	Author = {Goldberg, A. and Tarjan, R.},
	Booktitle = {STOC 1986: Proceedings of the 18th annual ACM symposium on Theory of computing},
	Pages = {136--146},
	Publisher = {ACM},
	Title = {A new approach to the maximum flow problem},
	Year = {1986}}

@article{Chakrabarti:1998,
	Author = {Chakrabarti, S. and Dom, B. and Agrawal, R. and Raghavan, P.},
	Journal = {The VLDB journal},
	Pages = {163--178},
	Title = {Scalable feature selection, classification and signature generation for organizing large text databases into hierarchical topic taxonomies},
	Volume = {7},
	Year = {1998}}

@inproceedings{Sanderson:1999,
	Address = {New York, NY, USA},
	Author = {Sanderson, M. and Croft, B.},
	Booktitle = {SIGIR '99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval},
	Pages = {206--213},
	Publisher = {ACM},
	Title = {Deriving concept hierarchies from text},
	Year = {1999}}

@inproceedings{Zamir:1998,
	Author = {Zamir, Oren and Etzioni, Oren},
	Booktitle = {Research and Development in Information Retrieval},
	Pages = {46-54},
	Title = {Web Document Clustering: A Feasibility Demonstration},
	Year = {1998}}

@inproceedings{Larsen:1999,
	Address = {New York, NY, USA},
	Author = {Larsen, B. and Aone, C.},
	Booktitle = {KDD '99: Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining},
	Pages = {16--22},
	Publisher = {ACM},
	Title = {Fast and effective text mining using linear-time document clustering},
	Year = {1999}}

@inproceedings{Koller:1997,
	Address = {San Francisco, CA, USA},
	Author = {Koller, Daphne and Sahami, Mehran},
	Booktitle = {ICML '97: Proceedings of the Fourteenth International Conference on Machine Learning},
	Pages = {170--178},
	Publisher = {Morgan Kaufmann publishers Inc.},
	Title = {Hierarchically Classifying Documents Using Very Few Words},
	Year = {1997}}

@book{Sutton:1998,
	Address = {Cambridge, MA},
	Author = {Sutton, R.S. and Barto, A.G.},
	Publisher = {MIT Press},
	Title = {Reinforcement Learning: An Introduction},
	Year = {1998}}

@article{Efron:1978,
	Author = {Efron, B.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {362--376},
	Title = {The Geometry of Exponential Families},
	Volume = {6},
	Year = {1978}}

@inproceedings{Arthur:2007,
	Author = {Arthur, D. and Vassilvitskii, S.},
	Booktitle = {SODA '07: Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms},
	Pages = {1027--1035},
	Title = {K-means++: {T}he Advantages of Careful Seeding},
	Year = {2007}}

@article{Hoff:2010,
	Author = {Hoff, P.},
	Journal = {Computational and Mathematical Organization Theory},
	Title = {Multiplicative latent factor models for description and prediction of social networks},
	Year = {to appear}}

@inproceedings{Stoica:2004,
	Author = {Stoica, E. and Hearst, M.},
	Booktitle = {HLT-NAACL},
	Title = {Nearly-Automated Metadata Hierarchy Creation},
	Year = {2004}}

@article{Ledoit:2004,
	Author = {Ledoit, O. and Wolf, M.},
	Journal = {Journal of Multivariate Analysis},
	Pages = {365--411},
	Title = {A well-conditioned estimator for large-dimensional covariance matrices},
	Volume = {88},
	Year = {2004}}

@techreport{Ledoit:2003,
	Author = {Ledoit, O. and Wolf, M.},
	Title = {Honey, I Shrunk the Sample Covariance Matrix},
	Year = {2003}}

@techreport{Fienberg:2007a,
	Author = {Fienberg, S. and Hersh, P. and Rinaldo, A. and Zhou, Y.},
	Title = {Maximum Likelihood Estimation in Latent Class Models for Contigency Table Data},
	Year = {2007}}

@techreport{Collins:2007,
	Author = {Collins, C.},
	Institution = {Knowledge Media Design Institute},
	Number = {KMDI-TR-2007-1},
	Title = {{D}ocu{B}urst: {R}adial Space-Filling Visualization of Document Content},
	Year = {2007}}

@inproceedings{Mei:2007,
	Author = {Mei, Q. and Shen, X. and Zhai, C.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Title = {Automatic Labeling of Multionomial Topic Models},
	Year = {2007}}

@inproceedings{Dietz:2007,
	Author = {Dietz, L. and Bickel, S. and Scheffer, T.},
	Booktitle = {International Conference on Machine Learning},
	Title = {Unsupervised Prediction of Citation Influences},
	Year = {2007}}

@article{Freedman:1967,
	Author = {Freedman, D.},
	Journal = {The Annals of Mathematical Statistics},
	Number = {4},
	Pages = {1281--1283},
	Title = {Timid Play is Optimal},
	Volume = {38},
	Year = {1967}}

@article{Freedman:1994,
	Author = {Freedman, D.},
	Journal = {Foundations of Science},
	Title = {Some Issues on the Foundation of Statistics},
	Year = {1994}}

@article{Fienberg:2007,
	Author = {Fienberg, S.},
	Journal = {Statisica Sinica},
	Pages = {1251--1272},
	Title = {Expanding the Statistical Toolkit with Algebraic Statistics},
	Volume = {17},
	Year = {2007}}

@inbook{Cinlar:2006a,
	Author = {Cinlar, E.},
	Chapter = {2},
	Title = {Lecture Notes in Probability Theory},
	Year = {2006}}

@inbook{Cinlar:2006,
	Author = {Cinlar, E.},
	Chapter = {1},
	Title = {Lecture Notes in Probability Theory},
	Year = {2006}}

@article{Lerman:2006,
	Author = {Lerman, K.},
	Journal = {arXiv},
	Title = {Social Networks and Social Information Filtering on {D}igg},
	Year = {2006}}

@article{Hoff:2006a,
	Author = {Hoff, P.},
	Journal = {arXiv},
	Number = {0609042v1},
	Title = {Model Averaging and Dimension Selection for Singular Value Decomposition},
	Year = {2006}}

@article{Hofman:2007,
	Author = {Hofman, J. and Wiggins, C.},
	Journal = {arXiv},
	Month = {September},
	Number = {0709.3512v2},
	Title = {A {B}ayesian Approach to Network Modularity},
	Year = {2007}}

@techreport{Freedman:2003,
	Author = {Freedman, D. and Stark, P.},
	Institution = {U.C. Berkeley Department of Statistics},
	Number = {511},
	Title = {What is the Chance of an Earthquake?},
	Year = {2003}}

@unpublished{Freedman:2002,
	Author = {Freedman, D.},
	Month = {January},
	Title = {From Association to Causation: {S}ome Remarks on the History of Statistics},
	Year = {2002}}

@article{Frey:2007,
	Author = {Frey, B. and Dueck, D.},
	Journal = {Science},
	Number = {972--976},
	Title = {On-line Supplement to Clustering by Passing Messages Between Data Points},
	Volume = {315},
	Year = {2007}}

@article{Blackwell:1973a,
	Author = {Blackwell, D.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {356--358},
	Title = {Discreteness of {F}erguson Selections},
	Volume = {1},
	Year = {1973}}

@article{Fan:2006,
	Author = {Fan, J. and Lv, J.},
	Journal = {arXiv},
	Title = {Sure Independence Screening for Ultra-High Dimensional Feature Space},
	Year = {2006}}

@inproceedings{Kivinen:2007,
	Author = {Kivinen, J. and Sudderth, E. and Jordan, M.},
	Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	Title = {Learning Multiscale Representations of Natural Scenes Using {D}irichlet Processes},
	Year = {2007}}

@techreport{Fox:2007,
	Author = {Fox, E. and Sudderth, E. and Jordan, M. and Willsky, A.},
	Institution = {MIT Laboratory for Information and Decision Systems},
	Title = {Developing a tempered {HDP-HMM} for systems with state persistence},
	Year = {2007}}

@inproceedings{Boyd-Graber:2007,
	Author = {Boyd-Graber, J. and Blei, D. and Zhu, X.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {A Topic Model for Word Sense Disambiguation},
	Year = {2007}}

@article{Blei:2007c,
	Author = {Blei, D. and Griffiths, T. and Jordan, M.},
	Journal = {arXiv},
	Title = {The Nested {C}hinese Restaurant Process and Hierarchical Topic Models},
	Year = {2007}}

@article{Crandall:1899,
	Author = {Crandall, C.},
	Journal = {Science},
	Number = {212},
	Pages = {115--116},
	Title = {The Storing of Pamphlets},
	Volume = {9},
	Year = {1899}}

@article{Salton:1991,
	Author = {Salton, G. and Buckley, C.},
	Journal = {Science},
	Number = {5023},
	Pages = {1012--1015},
	Title = {Global Text Matching for Information Retrieval},
	Volume = {253},
	Year = {1991}}

@article{Thoma:1962,
	Author = {Thoma, J.},
	Journal = {Science},
	Number = {3526},
	Pages = {278--279},
	Title = {Simple and Rapid Method for the Coding of Punched Cards},
	Volume = {137},
	Year = {1962}}

@article{Minot:1898,
	Author = {Minot, C.},
	Journal = {Science},
	Number = {209},
	Pages = {944--945},
	Title = {The Storing of Pamphlets},
	Volume = {8},
	Year = {1898}}

@book{Ghosh:2003,
	Author = {Ghosh, J. and Ramamoorthi, R.},
	Publisher = {Springer},
	Title = {Bayesian Nonparametrics},
	Year = {2003}}

@techreport{Bach:2003,
	Author = {Bach, F. and Jordan, M.},
	Institution = {U.C. Berkeley Computer Science Division},
	Title = {Learning Spectral Clustering},
	Year = {2003}}

@article{Gutierrez-Pena:2004,
	Author = {Gutierrez-Pena, E. and Muliere, P.},
	Journal = {Scand. J. Statistics},
	Pages = {235--246},
	Title = {Conjugate Priors Represent Strong Pre-Experimental Assumptions},
	Volume = {3},
	Year = {2004}}

@book{Manning:2007,
	Author = {Manning, C. and Raghavan, P. and Sch\"{u}tze, H},
	Publisher = {Cambridge University Press},
	Title = {An Introduction to Information Retrieval},
	Year = {2007}}

@inproceedings{Teh:2006a,
	Author = {Teh, Y.},
	Booktitle = {Proceedings of the Association of Computational Linguistics},
	Title = {A Hierarchical {B}ayesian Language Model Based on {P}itman-{Y}or Processes},
	Year = {2006}}

@article{Gnedin:2007,
	Author = {Gnedin, A. and Hansen, B. and Pitman, J.},
	Journal = {Probability Surveys},
	Title = {Notes on the occupancy problem with infinitely many boxes: {G}eneral asymptotics and power laws},
	Volume = {4},
	Year = {2007}}

@article{Gnedin:2004a,
	Author = {Gnedin, A. and Pitman, J.},
	Journal = {arXiv},
	Title = {Exchangeable {G}ibbs partitions and {S}tirling triangles},
	Year = {2004}}

@article{Gnedin:2004,
	Author = {Gnedin, A. and Pitman, J.},
	Journal = {arXiv},
	Title = {Regenerative Compositional Structures},
	Year = {2004}}

@article{Pitman:2002b,
	Author = {Pitman, J.},
	Journal = {arXiv},
	Title = {Poisson-{K}ingman Partitions},
	Year = {2002}}

@article{Lee:1999,
	Author = {Lee, D. and Seung, H.},
	Journal = {Nature},
	Month = {October},
	Number = {6755},
	Pages = {788--791},
	Title = {Learning the parts of objects by non-negative matrix factorization.},
	Volume = {401},
	Year = {1999}}

@inproceedings{Kaplan:2007,
	Author = {Kaplan, D. and Blei, D.},
	Booktitle = {IEEE Conference on Data Mining},
	Title = {A Computational Approach to Style in {A}merican Poetry},
	Year = {2007}}

@inproceedings{Blei:2007b,
	Author = {Blei, D. and McAuliffe, J.},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Supervised Topic Models},
	Year = {2007}}

@book{Tang:2005,
	Author = {Tang, Z. and MacLennan, J.},
	Publisher = {Wiley},
	Title = {Data Mining with {SQL} Server 2005},
	Year = {2005}}

@article{Muller:2004,
	Author = {Muller, P. and Quintana, F.},
	Journal = {Statistical Science},
	Number = {1},
	Pages = {95--110},
	Title = {Nonparametric {B}ayesian Data Analysis},
	Volume = {19},
	Year = {2004}}

@article{Kingman:1975,
	Author = {Kingman, J.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {1},
	Title = {Random Discrete Distributions},
	Volume = {37},
	Year = {1975}}

@book{Blei:2001a,
	Author = {Blei, R.},
	Publisher = {Cambridge University Press},
	Title = {Analysis in Integer and Fractional Dimensions},
	Year = {2001}}

@article{Smith:1988,
	Author = {Smith, T. and Brunsdon, T.},
	Title = {The Times Series Analysis of Compositional Data},
	Year = {1988}}

@inproceedings{Brandt:1999,
	Address = {Bloomington, Indiana},
	Author = {Brandt, P. and Monroe, B. and Williams, J.},
	Booktitle = {Workshop in Political Theory and Policy Analysis},
	Title = {Time Series Models for Compositional Data},
	Year = {1999}}

@article{Holloway:2005,
	Author = {Holloway, T. and Bozlicevic, M. and Borner, K.},
	Title = {Analyzing and Visualizing the Semantic Coverage of Wikipedia and Its authors},
	Year = {2005}}

@article{Selcer:2005,
	Author = {Selcer, D.},
	Title = {The Uninterrupted Ocean: {L}eibniz and the Encyclopedic Imagination},
	Year = {2005}}

@inproceedings{Wang:2005,
	Author = {Wang, X. and Mohanty, N. and Mc{C}allum, A.},
	Booktitle = {Proceedings of Link-KDD},
	Title = {Group and Topic Discovery from Relations and Text},
	Year = {2005}}

@inbook{Blei:2004b,
	Author = {Blei, D.},
	Chapter = {Graphical models and approximate posterior inference},
	Title = {Probabilistic Models of Text and Images},
	Year = {2004}}

@inproceedings{Barzilay:2004,
	Author = {Barzilay, R. and Lee, L.},
	Booktitle = {North American Computational Linguistics},
	Pages = {113--120},
	Title = {Catching the Drift: {P}robabilistic Content Models, with Applications to Generation and Summarization},
	Year = {2004}}

@article{Krantz:2007,
	Author = {Krantz, D. and Kunreuther, H.},
	Journal = {Judgement and Decision Makeing},
	Number = {3},
	Pages = {137--168},
	Title = {Goals and Plans in Decision Making},
	Volume = {2},
	Year = {2007}}

@article{Phillips:1970,
	Author = {Phillips, G. and Taylor, P.},
	Journal = {BIT},
	Title = {Approximation of Convex Data},
	Year = {1970}}

@article{Dudik:2007a,
	Author = {Dudik, M. and Phillips, S. and Schapire, R.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1217--1260},
	Title = {Maximum Entropy Density Estimation with Generalized Regularization and an Application to Species Distribution Modeling},
	Volume = {8},
	Year = {2007}}

@techreport{Shahbaba:2007a,
	Author = {Shahbaba, B. and Neal, R.},
	Institution = {Department of Statistics, University of Toronto},
	Number = {0707},
	Title = {Nonlinear Models Using Dirichlet Process Mixtures},
	Year = {2007}}

@inproceedings{Tishby:1999,
	Author = {Tishby, N. and Pereira, F. and Bialek, W.},
	Booktitle = {Proceedings of the 37-th Annual Allerton Conference on Communication, Control and Computing},
	Pages = {368--377},
	Title = {The information bottleneck method},
	Year = {1999}}

@inproceedings{Slonim:2000,
	Address = {New York, NY, USA},
	Author = {Slonim, N. and Tishby, N.},
	Booktitle = {Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
	Pages = {208--215},
	Publisher = {ACM Press},
	Title = {Document clustering using word clusters via the information bottleneck method},
	Year = {2000}}

@inproceedings{Li:2005,
	Author = {Li, W. and McCallum, A.},
	Booktitle = {AAAI Conference on Artificial Intelligence},
	Title = {Semi-Supervised Sequence Modeling with Syntactic Topic Models},
	Year = {2005}}

@inproceedings{Andrzejewski:2007,
	Author = {Andrzejewski, D. and Mulhern, A. and Liblit, B. and Zhu, X.},
	Booktitle = {European Conference on Machine Learning},
	Title = {Statistical Debugging Using Latent Topic Models},
	Year = {2007}}

@inproceedings{Wallach:2006,
	Author = {Wallach, H.},
	Booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
	Title = {Topic Modeling: {B}eyond Bag of Words},
	Year = {2006}}

@book{Chapelle:2006,
	Address = {Cambridge, MA},
	Editor = {Chapelle, O. and Sch\"{o}lkopf, B. and Zien, A.},
	Publisher = {MIT Press},
	Title = {Semi-Supervised Learning},
	Year = {2006}}

@inproceedings{McCallum:1999,
	Author = {McCallum, A. and Nigam, K. and Rennie, J. and Seymore, K.},
	Booktitle = {AAAI Conference on Artificial Intelligence},
	Title = {Building Domain-Specific Search Engines with Machine Learning Techniques},
	Year = {1999}}

@inproceedings{Craven:1998,
	Author = {Craven, M. and DiPasquo, D. and Freitag, D. and Mc{C}allum, A. and Mitchell, T. and Nigam, K. and Slattery, S.},
	Booktitle = {AAAI Conference on Artificial Intelligence},
	Pages = {509--516},
	Title = {Learning to extract symbolic knowledge from the world wide web},
	Year = {1998}}

@inproceedings{Fast:2005,
	Author = {Fast, A. and Jensen, D. and Levine, B.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Pages = {568--573},
	Title = {Creating Social Networks to Improve Peer-to-Peer Networking},
	Year = {2005}}

@inproceedings{Gehler:2006,
	Author = {Gehler, P. and Holub, A. and Welling, M.},
	Booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
	Pages = {337--344},
	Title = {The Rate Adapting {P}oisson Model for Information Retrieval and Object Recognition},
	Year = {2006}}

@inproceedings{Zhou:2006,
	Author = {Zhou, D. and Manavoglu, E. and Li, J. and Giles, C. and Zha, H.},
	Booktitle = {Proceedings of the International World Wide Web Conference},
	Pages = {173--182},
	Title = {Probabilistic Models for Discovering E-Communities},
	Year = {2006}}

@article{Rogers:2005,
	Author = {Rogers, S. and Girolami, M. and Campbell, C. and Breitling, R.},
	Journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
	Number = {2},
	Pages = {143--156},
	Title = {The Latent Process Decomposition of {cDNA} Microarray Data Sets},
	Volume = {2},
	Year = {2005}}

@inproceedings{Newman:2005a,
	Author = {Newman, D. and Asuncion, A. and Chemudugunta, C. and Kumar, V. and Smyth, P. and Steyvers, M.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Title = {Exploring Large Document Collections Using Statistical Topic Models},
	Year = {2005}}

@inproceedings{Bhattacharya:2006a,
	Author = {Bhattacharya, I. and Getoor, L.},
	Booktitle = {SIAM Conference on Data Mining},
	Month = {April},
	Title = {A Latent {D}irichlet Model for Unsupervised Entity Resolution},
	Year = {2006}}

@inproceedings{Jin:2005,
	Author = {Jin, X. and Zhou, Y. and Mobasher, B.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Title = {A Maximum Entropy Web Recommendation System: {C}ombining Collaborative and Content Features},
	Year = {2005}}

@book{Norman:2002,
	Author = {Norman, D.},
	Publisher = {Basic Books},
	Title = {The Design of Everyday Things},
	Year = {2002}}

@book{Raskin:2000,
	Author = {Raskin, J.},
	Publisher = {Addison-Wesley Professional},
	Title = {The Humane Interface: {N}ew DIrections for Designing Systems},
	Year = {2000}}

@book{Nielsen:1994,
	Author = {Nielsen, J.},
	Publisher = {Morgan Kaufmann publishers},
	Title = {Usability Engineering},
	Year = {1994}}

@book{Airoldi:2007c,
	Editor = {Airoldi, E. and Blei, D. and Fienberg, S. and Goldenberg, A. and Xing, E. and Zheng, A.},
	Publisher = {Springer-Verlag},
	Series = {Lecture Notes in Computer Science},
	Title = {Statistical Network Analysis: Models, Issues and New Directions},
	Year = {2007}}

@article{Blei:2007a,
	Author = {Blei, D. and Fienberg, S.},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Pages = {332},
	Title = {Discussion of Model-based clustering for social networks},
	Volume = {170},
	Year = {2007}}

@article{Burges:1998,
	Author = {Burges, C.},
	Journal = {Data Mining and Knowledge Discovery},
	Pages = {121--167},
	Title = {A Tutorial on Support Vector Machines for Pattern Recognition},
	Volume = {2},
	Year = {1998}}

@article{Storey:2003,
	Author = {Storey, J.},
	Journal = {The Annals of Statistics},
	Number = {6},
	Pages = {2013--2035},
	Title = {The Positive False Discovery Rate: {A} {B}ayesian Interpretation and the $q$-Value},
	Volume = {31},
	Year = {2003}}

@article{Burda:2001,
	Author = {Burda, Z. and Correia, J. and Krzywicki, A.},
	Journal = {arXiv},
	Number = {0104155},
	Title = {Statistical ensemble of scale-free random graphs},
	Year = {2001}}

@inproceedings{Lin:1995,
	Author = {Lin, D.},
	Title = {An Information-Theoretic Definition of Similarity},
	Year = {1995}}

@article{Shahbaba:2007,
	Author = {Shahbaba, B. and Neal, R.},
	Journal = {Bayesian Analysis},
	Number = {1},
	Pages = {221--238},
	Title = {Improving classification when a class hierarchy is available using a hierarchy-based prior},
	Volume = {2},
	Year = {2007}}

@article{Mazieres:2003,
	Author = {Mazieres, D. and Kohler, E.},
	Title = {Get Me Off Your Fucking Mailing List},
	Year = {2003}}

@article{Rayens:1994,
	Author = {Rayens, W. and Srinivasan, C.},
	Journal = {Journal of the American Statistical Association},
	Number = {428},
	Pages = {1465--1470},
	Title = {Dependence Properties of Generalized {L}iouville Distributions on the Simplex},
	Volume = {89},
	Year = {1994}}

@inproceedings{Finkel:2007,
	Author = {Finkel, J. and Grenager, T. and Manning, C.},
	Booktitle = {Proceedings of Empirical Methods in Natural Language Processing},
	Title = {The Infinite Tree},
	Year = {2007}}

@inproceedings{Poole:2007,
	Author = {Poole, D.},
	Booktitle = {22nd AAAI Conference on Artificial Intelligence},
	Title = {Logical Generative Models for Probabilistic Reasoning about Existence, Roles and Identity},
	Year = {2007}}

@inproceedings{Pasula:2001,
	Author = {Pasula, H. and Russell, S.},
	Booktitle = {International Joint Conferences on Artificial Intelligence},
	Pages = {741--748},
	Title = {Approximate Inference for First-Order Probabilistic Languages},
	Year = {2001}}

@inproceedings{Milch:2005,
	Author = {Milch, B. and Marthi, B. and Sontag, D. and Ong, D. and Kobolov, A.},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Approximate Inference for Infinite Contingent {B}ayesian Networks},
	Year = {2005}}

@book{Titterington:1985,
	Address = {Chichester},
	Author = {Titterington, D. and Smith, A. and Makov, E.},
	Publisher = {Wiley},
	Title = {Statistical Analysis of Finite Mixture Distributions},
	Year = {1985}}

@inproceedings{Russell:2006,
	Author = {Russell, B. and Efros, A. and Sivic, J. and Freeman, W. and Zisserman, A.},
	Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	Pages = {1605--1614},
	Title = {Using Multiple Segmentations to Discover Objects and their Extent in Image Collections},
	Year = {2006}}

@inproceedings{Liang:2007,
	Author = {Liang, P. and Petrov, S. and Klein, D. and Jordan, M.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {The Infinite {PCFG} Using Hierarchical {D}irichlet Processes},
	Year = {2007}}

@misc{Donoho:2000,
	Author = {Donoho, D.},
	Title = {Mathematical Challenges of the 21st Century},
	Year = {2000}}

@article{Sigman:2002,
	Author = {Sigman, M. and Cecchi, G.},
	Journal = {Proceedings of the National Academy of Science},
	Pages = {1742--1747},
	Title = {Global organization of the {W}ordnet lexicon},
	Volume = {99},
	Year = {2002}}

@article{Bhattacharya:2004,
	Author = {Bhattacharya, I. and Getoor, L. and Bengio, Y.},
	Title = {Unsupervised Sense Disambiguation Using Bilingual Probabilistic Models},
	Year = {2004?}}

@inproceedings{Pang:2004,
	Author = {Pang, B. and Lee, L.},
	Booktitle = {Proceedings of the Association of Computational Linguistics},
	Title = {A Sentimental Education: {S}entiment Analysis Using Summarization Based on Minimum Cuts},
	Year = {2004}}

@inproceedings{Chemudugunta:2006,
	Author = {Chemudugunta, C. and Smyth, P. and Steyvers, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model},
	Year = {2006}}

@article{Airoldi:2007b,
	Author = {Airoldi, E. and Blei, D. and Fienberg, S. and Xing, E.},
	Journal = {arXiv},
	Month = {May},
	Number = {0705.4485},
	Title = {Mixed Membership Stochastic Blockmodels},
	Year = {2007}}

@inproceedings{Mimno:2007,
	Author = {Mimno, D. and McCallum, A.},
	Booktitle = {Joint Conference on Digital Libraries},
	Title = {Organizing the {OCA}: {L}earning faceted subjects from a library of digital books},
	Year = {2007}}

@article{Ionnidis:2005,
	Author = {Ionnidis, J.},
	Journal = {Public Library of Science Medicine},
	Number = {8},
	Title = {Why Most Published Research Findings are False},
	Volume = {2},
	Year = {2005}}

@inproceedings{Teh:2007a,
	Author = {Teh, Y. and Gorur, D. and Ghahramani, Z.},
	Booktitle = {International Conference on Artifical Intelligence and Statistics (AISTATS)},
	Title = {Stick-breaking Construction for the {I}ndian Buffet Process},
	Year = {2007}}

@inproceedings{Thibaux:2007,
	Author = {Thibaux, R. and Jordan, M.},
	Booktitle = {11th Conference on Artificial Intelligence and Statistics},
	Title = {Hierarchical Beta Processes and the {I}ndian Buffet Process},
	Year = {2007}}

@inproceedings{Li:2007,
	Author = {Li, W. and Blei, D. and McCallum, A.},
	Booktitle = {The 23rd Conference on Uncertainty in Artificial Intelligence},
	Title = {Nonparametric {B}ayes pachinko allocation},
	Year = {2007}}

@article{Xing:2007,
	Author = {Xing, E. and Jordan, M. and Sharan, R.},
	Journal = {Journal of Computational Biology},
	Number = {3},
	Pages = {267--284},
	Title = {Bayesian Haplotype Inference via the {D}irichlet Process},
	Volume = {14},
	Year = {2007}}

@book{Joachims:2002,
	Address = {Boston, MA},
	Author = {Joachims, T.},
	Publisher = {Kluwer Academic publishers},
	Title = {Learning to Classify Text Using Support Vector Machines},
	Year = {2002}}

@inproceedings{Ng:2002,
	Author = {Ng, A. and Jordan, M.},
	Booktitle = {Advances in Neural Information Processing Systems 14},
	Title = {On Discriminative versus Generative Classifiers: {A} comparison of logistic regression and naive {B}ayes},
	Year = {2002}}

@inproceedings{Johnson:2007,
	Address = {Cambridge, MA},
	Author = {Johnson, M. and Griffiths, T. and S., Goldwater},
	Booktitle = {Advances in Neural Information Processing Systems 19},
	Editor = {Sch\"{o}lkopf, B. and Platt, J. and Hoffman, T.},
	Pages = {641--648},
	Publisher = {MIT Press},
	Title = {Adaptor grammars: {A} framework for specifying compositional nonparametric {B}ayesian models},
	Year = {2007}}

@inproceedings{Goldwater:2006,
	Author = {Goldwater, S. and Griffiths, T. and Johnson, M.},
	Booktitle = {International Conference on Computational Linguistics and Association for Computational Linguistics},
	Title = {Contextual Dependencies in Unsupervised Word Segmentation},
	Year = {2006}}

@article{Krapivsky:2001,
	Author = {Krapivsky, P. and Redner, S.},
	Journal = {Physical Review E},
	Number = {6},
	Title = {Organization of Growing Random Networks},
	Volume = {63},
	Year = {2001}}

@techreport{Drinea:2006,
	Author = {Drinea, E. and Enachesu, M. and Mitzenmacher, M.},
	Institution = {Harvard University},
	Number = {TR-06-01},
	Title = {Variations on Random Graph Models for the Web},
	Year = {2006}}

@article{Efron:2004,
	Author = {Efron, B. and Hastie, T. and Johnstone, I. and Tibshirani, R.},
	Journal = {Annals of Statistics},
	Number = {2},
	Pages = {407--499},
	Title = {Least Angle Regression},
	Volume = {32},
	Year = {2004}}

@inproceedings{Pang:2005,
	Author = {Pang, B. and Lee, L.},
	Booktitle = {Proceedings of the Association of Computational Linguistics},
	Title = {Seeing Stars: {E}xploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales},
	Year = 2005}

@book{Hastie:2001,
	Author = {Hastie, T. and Tibshirani, R. and Friedman, J.},
	Month = {August},
	Publisher = {Springer},
	Title = {The Elements of Statistical Learning},
	Year = {2001}}

@inproceedings{Quelhas:2005,
	Author = {Quelhas, P. and Monay, F. and Odobez, J.M. and Gatica-Perez, D. and Tuyelaars, T. and Van Gool, L.},
	Booktitle = {ICCV},
	Title = {Modeling Scenes with Local Descriptors and Latent Aspects},
	Year = {2005}}

@book{Johnson:1977,
	Address = {New York},
	Author = {Johnson, N. and Kotz, S.},
	Publisher = {Wiley},
	Title = {Urn Models and Their Applications: {A}n Approach to Modern Discrete Probability Theory},
	Year = {1977}}

@inproceedings{Pang:2002,
	Author = {Pang, B. and Lee, L.},
	Booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	Pages = {79--86},
	Title = {Thumbs up? {S}entiment Classification using Machine Learning Techniques},
	Year = {2002}}

@inproceedings{McCallum:2006,
	Author = {Mc{C}allum, A. and Pal, C. and Druck, G. and Wang, X.},
	Booktitle = {AAAI},
	Title = {Multi-Conditional Learning: {G}enerative/Discriminative Training for Clustering and Classification},
	Year = {2006}}

@article{Fukumizu:2004,
	Author = {Fukumizu, K. and Bach, F. and Jordan, M.},
	Journal = {Journal of Machine Learning Research},
	Pages = {73--99},
	Title = {Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces},
	Volume = {5},
	Year = {2004}}

@book{Cristianini:2000,
	Address = {Cambridge, U.K.},
	Author = {Cristianini, N. and Shawe-Taylor, J.},
	Publisher = {Cambridge University Press},
	Title = {An Introduction to Support Vector Methods},
	Year = {2000}}

@book{Billingsley:1995,
	Author = {Billingsley, P.},
	Publisher = {Wiley-Interscience},
	Title = {Probability and Measure},
	Year = {1995}}

@inproceedings{Sulwani:2006,
	Author = {Sulwani, S. and Jojic, N.},
	Title = {Program verification as probabilistic inference},
	Year = {2006}}

@article{Jojic:2004,
	Author = {Jojic, N. and Caspi, Y. and Reyes-Gomes, M.},
	Title = {Probabilistic index maps for modeling natural signals},
	Year = {2004}}

@article{West:2001,
	Author = {West, M.},
	Journal = {Bayesian Statistics},
	Title = {Bayesian Factor Regression Models in the "Large p, Small n" Paradigm},
	Year = {2001}}

@techreport{Wainwright:2007,
	Author = {Wainwright, M.},
	Institution = {UC Berkeley Department of Statistics},
	Month = {January},
	Title = {Information-theoretic limits on sparsity recovery in the high-dimensional and noisy setting},
	Year = {2007}}

@article{Blei:2007,
	Author = {Blei, D. and Lafferty, J.},
	Journal = {Annals of Applied Statistics},
	Number = {1},
	Pages = {17--35},
	Title = {A Correlated Topic Model of {S}cience},
	Volume = {1},
	Year = {2007}}

@inproceedings{Dudik:2007,
	Author = {Dudik, M. and Blei, D. and Schapire, R.},
	Booktitle = {Proceedings of the 28th International Conference on Machine Learning},
	Title = {Hierarchical Maximum Entropy Density Estimation},
	Year = {2007}}

@article{Bartlett:2006,
	Author = {Bartlett, Peter L. and Jordan, Michael I. and McAuliffe, Jon D.},
	Journal = {Journal of the American Statistical Association},
	Month = {March},
	Number = {473},
	Pages = {138--156},
	Title = {Convexity, classification, and risk bounds},
	Volume = {101},
	Year = {2006}}

@incollection{Airoldi:2007a,
	Author = {Airoldi, E. and Blei, D. and Fienberg, S. and Xing, E.},
	Booktitle = {Statistical Network Analysis: Models, Issues and New Directions},
	Pages = {57--74},
	Publisher = {Springer-Verlag},
	Series = {Lecture Notes in Computer Science},
	Title = {Combining Stochastic Block Models and Mixed Membership for Statistical Network Analysis},
	Year = {2007}}

@article{Erosheva:2007,
	Author = {Erosheva, E. and Fienberg, S. and Joutard, C.},
	Journal = {Annals of Applied Statistics},
	Title = {Describing Disability Through Individual-Level Mixture Models for Multivariate Binary Data},
	Year = {2007}}

@inproceedings{Zhu:2006,
	Author = {Zhu, L. and Chen, Y. and Yuille, A},
	Booktitle = {Neural Information Processing Systems ({N}{I}{P}{S}) 19},
	Title = {Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing},
	Year = {2006}}

@inproceedings{Kim:2006a,
	Author = {Kim, S. and Smyth, P.},
	Booktitle = {Neural Information Processing Systems ({N}{I}{P}{S}) 19},
	Title = {Hierarchical {D}irichlet processes with random effects},
	Year = {2006}}

@article{Nemenman:2004,
	Author = {Nemenman, I. and Bialek, W. and de Ruyter van Steveninck, R.},
	Journal = {Physical Review E.},
	Title = {Entropy and information in neural spike trains: {P}rogress on the sampling problem},
	Volume = {69},
	Year = {2004}}

@inproceedings{Mihalcea:2007,
	Author = {Mihalcea, R.},
	Booktitle = {Proceedings of the ACL},
	Title = {Using Wikipedia for Automatic Word Sense Disambiguation},
	Year = {2007}}

@book{Magnus:2007,
	Author = {Magnus, J. and Neudecker, H.},
	Publisher = {John Wiley \& Sons Ltd.},
	Title = {Matrix Differential Calculus with Applications in Statistics and Econometrics},
	Year = {2007}}

@article{Kokolakis:2007,
	Author = {Kokolakis, G. and Kouvaras, G.},
	Journal = {Bayesian Analysis},
	Number = {1},
	Pages = {213--220},
	Title = {On the Multimodality of Random Process Measures},
	Volume = {2},
	Year = {2007}}

@article{Donnelly:1991,
	Author = {Donnelly, P.},
	Journal = {Journal of Applied Probability},
	Month = {June},
	Number = {2},
	Pages = {321--335},
	Title = {The Heaps Process, Libraries, and Size-Biased Permutations},
	Volume = {28},
	Year = {1991}}

@article{Wei:1990,
	Author = {Wei, G. and Tanner, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {411},
	Pages = {699--704},
	Title = {A {M}onte {C}arlo Implementation of the {EM} Algorithm and the Poor Man's Data Augmentation Algorithms},
	Volume = {85},
	Year = {1990}}

@article{Carlton:2002,
	Author = {Carlton, M.},
	Journal = {Journal of Applied Probability},
	Number = {4},
	Pages = {764--774},
	Title = {A Family of Densities Derived from the Three-Parameter Dirichlet Process},
	Volume = {39},
	Year = {2002}}

@article{Storey:2002,
	Author = {Storey, J.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Pages = {479--498},
	Title = {A direct approach to false discovery rates},
	Volume = {64},
	Year = {2002}}

@article{McIntosh:2004,
	Author = {McIntosh, A. and Lobaugh, N.},
	Journal = {Neuro{I}mage},
	Pages = {8250--8263},
	Title = {Partial Least Squares Analysis of Neuroimaging Data: Applications and Advances},
	Volume = {23},
	Year = {2004}}

@article{Frey:2007a,
	Author = {Frey, B. and Dueck, D.},
	Journal = {Science},
	Number = {972--976},
	Title = {Clustering by Passing Messages Between Data Points},
	Volume = {315},
	Year = {2007}}

@article{Liu:1994,
	Author = {Liu, J.},
	Journal = {Journal of the American Statistical Association},
	Number = {958--966},
	Title = {The Collapsed {G}ibbs Sampler in {B}ayesian Computations with Application to a Gene Regulation Problem},
	Volume = {89},
	Year = {1994}}

@article{Nemenman:2002,
	Author = {Nemenman, I. and Shafee, F. and Bialek, W.},
	Title = {Entropy and Inference, Revisited},
	Year = {2002}}

@article{Kim:2006,
	Author = {Kim, S. and Smyth, P. and Stern, H.},
	Title = {A Nonparametric Bayesian Approach to Detecting Spatial Activation Patterns in {fMRI} Data},
	Year = {2006}}

@article{Cilibrasi:2007,
	Author = {Cilibrasi, R. and Vitanyi, P.},
	Journal = {{IEEE} Transactions on Knowledge and Data Engineering},
	Number = {3},
	Title = {The Google Similarity Distance},
	Volume = {19},
	Year = {2007}}

@article{Aitchison:1984,
	Author = {Aitchison, J.},
	Journal = {Mathematical Geology},
	Number = {6},
	Title = {Reducing the Dimensionality of Compositional Data Sets},
	Volume = {16},
	Year = {1984}}

@article{Lafferty:2006,
	Author = {Lafferty, J. and Wasserman, L.},
	Journal = {Statistica Sinica},
	Pages = {307--322},
	Title = {Challenges in Statistical Machine Learning},
	Volume = {16},
	Year = {2006}}

@article{Nemenman:2006,
	Author = {Nemenman, I. and Lewen, G. and Bialek, W. and de Ruyter van Steveninck, R.},
	Title = {Neural coding of a natural stimulus ensemble: {U}ncovering information at sub-millisecond resolution},
	Year = {2006}}

@inproceedings{Hutchinson:2006,
	Author = {Hutchinson, R. and Mitchell, T. and Rustandi, I.},
	Booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
	Title = {Hidden Process Models},
	Year = {2006}}

@article{Teh:2007,
	Author = {Teh, Y. and Jordan, M. and Beal, M. and Blei, D.},
	Journal = {Journal of the American Statistical Association},
	Number = {476},
	Pages = {1566--1581},
	Title = {Hierarchical {D}irichlet processes},
	Volume = {101},
	Year = {2007}}

@article{Raiko:2007,
	Author = {Raiko, T. and Valpola, H. and Harva, M. and Karhunen, J.},
	Journal = {Journal of Machine Learning Research},
	Pages = {155--201},
	Title = {Building Blocks for Variational {B}ayesian Learning of Latent Variable Models},
	Volume = {8},
	Year = {2007}}

@article{Pitman:2002a,
	Author = {Pitman, J.},
	Journal = {Combinatorics, Probability, and Computing},
	Pages = {501--514},
	Title = {Poisson-{D}irichlet and {GEM} Invariant Distributions for Split-and-Merge Transformations of an Interval Partition},
	Volume = {11},
	Year = {2002}}

@article{Gelman:2004a,
	Author = {Gelman, A.},
	Journal = {Journal of the American Statistical Association},
	Number = {466},
	Pages = {537--545},
	Title = {Parameterization and {B}ayesian Modeling},
	Volume = {99},
	Year = {2004}}

@unpublished{Shewchuk:1994,
	Author = {Shewchuk, J.},
	Title = {An Introduction to the Conjugate Gradient Method Without the Agonizing Pain},
	Year = {1994}}

@inproceedings{Blei:2004a,
	Author = {Blei, D. and Jordan, M.},
	Booktitle = {21st International Conference on Machine Learning},
	Title = {Variational Methods for the {D}irichlet Process},
	Year = {2004}}

@inproceedings{Kurihara:2006a,
	Author = {Kurihara, K. and Kameya, Y. and Sato, T.},
	Booktitle = {Workshop on Information-Based Induction},
	Title = {A Frequency-based Stochastic Blockmodel},
	Year = {2006}}

@article{Wang:2006,
	Author = {Wang, C.},
	Journal = {IEEE Transactions on Neural Networks},
	Title = {Variational {B}ayesian Approach to Canonical Correlation Analysis},
	Year = {2006}}

@article{Giudici:1999,
	Author = {Giudici, P. and Green, P.},
	Journal = {Biometrika},
	Number = {4},
	Pages = {785--801},
	Title = {Decomposable Graphical Gaussian Model Determination},
	Volume = {86},
	Year = {1999}}

@article{Dawid:1993,
	Author = {Dawid, A. and Lauritzen, S.},
	Journal = {The Annals of Statistics},
	Number = {3},
	Pages = {1272--1317},
	Title = {Hyper {M}arkov Laws in the Statistical Analysis of Decomposable Graphical Models},
	Volume = {21},
	Year = {1993}}

@article{Airoldi:2006a,
	Author = {Airoldi, E. and Blei, D. and Fienberg, S. and Xing, E.},
	Journal = {Biometrics (submitted)},
	Title = {Admixtures of Latent Blocks with Application to Protein Interaction Networks},
	Year = {2006}}

@inproceedings{Purver:2006,
	Author = {Purver, M. and K{"o}rding, K. and Griffiths, T. and Tenenbaum, J.},
	Booktitle = {ACL},
	Title = {Unsupervised Topic Modelling for Multi-Party Spoken Discourse},
	Year = {2006}}

@inproceedings{Wei:2006,
	Author = {Wei, X. and Croft, B.},
	Booktitle = {SIGIR},
	Title = {{LDA}-Based Document Models for Ad-hoc Retrieval},
	Year = {2006}}

@article{Holst:1991,
	Author = {Holst, L.},
	Title = {The {P}oisson-{D}irichlet Distribution and Its Relatives Revisited},
	Year = {1991}}

@article{Seeger:2004,
	Author = {Seeger, M. and Kakade, S. and Foster, D.},
	Title = {Worst-Case Bounds for Some Non-Parametric {B}ayesian Methods},
	Year = {2004}}

@inproceedings{Newman:2006,
	Author = {Newman, D. and Chemudugunta, C. and Smyth, P.},
	Booktitle = {Knowledge Discovery and Data Mining},
	Title = {Statistical Entity-Topic Models},
	Year = {2006}}

@phdthesis{Airoldi:2007,
	Author = {Airoldi, E.},
	School = {Carnegie Mellon University},
	Title = {Bayesian Mixed-Membership Models of Complex and Evolving Networks},
	Year = {2007}}

@inproceedings{Kurihara:2007,
	Author = {Kurihara, K. and Welling, M. and Teh, Y.},
	Booktitle = {International Joint Conferences on Artificial Intelligence (IJCAI)},
	Title = {Collapsed Variational {D}irichlet Process Mixture Models},
	Year = {2007}}

@article{Rada:2000,
	Author = {Rada, M. and Tarau, P. and Figa, E.},
	Title = {{PageRank} on Semantic Networks, with Application to Word Sense Disambiguation},
	Year = {2000?}}

@article{Baxter:2001,
	Author = {Baxter, J. and Tridgell, A. and Weaver, L.},
	Title = {Learning to Play Chess Using Temporal Differences},
	Year = {2001}}

@book{Lavine:2005,
	Author = {Lavine, M.},
	Title = {Introduction to Statistical Thought},
	Year = {2005}}

@article{Lafferty:1992,
	Author = {Lafferty, J. and Sleator, D. and Temperley, D.},
	Title = {Grammatical Trigrams: {A} Probablistic Model of Link Grammar},
	Year = {1992}}

@article{Haskell:2006,
	Author = {Haskell, M.},
	Journal = {Dragonsfoot},
	Title = {The Battle for Gib Rus},
	Year = {2006}}

@article{Castelo:2006,
	Author = {Castelo, R. and Roverato, A.},
	Journal = {Journal of Machine Learning Research},
	Pages = {2621--2650},
	Title = {A Robust Procedure for {Gaussian} Graphical Model Search From Microarray Data With $p$ Larger Than $n$},
	Volume = {7},
	Year = {2006}}

@article{Pitman:1996a,
	Author = {Pitman, J.},
	Title = {Some Developments of the {Blackwell}-{MacQueen} Urn Scheme},
	Year = {1996}}

@article{Brownson:1960,
	Author = {Brownson, H.},
	Journal = {Science},
	Number = {3444},
	Pages = {1922--1931},
	Title = {Research on Handling Scientific Information},
	Volume = {132},
	Year = {1960}}

@article{Beard:1952,
	Author = {Beard, R. and Heumann, K.},
	Journal = {Science},
	Number = {3021},
	Title = {The Chemical-Biological Coordination Center: {An} Experiment in Documentation},
	Volume = {116},
	Year = {1952}}

@article{Marsden:1953,
	Author = {Marsden, A. and Beard, R. and Heumann, K.},
	Journal = {Science},
	Number = {3048},
	Pages = {611--612},
	Title = {Documentation},
	Volume = {117},
	Year = {1953}}

@article{Margolis:1967,
	Author = {Margolis, J.},
	Journal = {Science},
	Number = {3767},
	Pages = {1213--1219},
	Title = {Citation Indexing and Evaluation of Scientific Papers},
	Volume = {155},
	Year = {1967}}

@article{Ornstein:1955,
	Author = {Ornstein, J.},
	Journal = {Science},
	Number = {3173},
	Pages = {745--748},
	Title = {Mechanical Translation},
	Volume = {122},
	Year = {1955}}

@article{Kernighan:1982,
	Author = {Kernighan, B. and Morgan, S.},
	Journal = {Science},
	Number = {4534},
	Pages = {779--783},
	Title = {The {UNIX} Operating System: {A} Model for Software Design},
	Volume = {215},
	Year = {1982}}

@article{Roweis:2000,
	Author = {Roweis, S. and Saul, L.},
	Journal = {Science},
	Number = {5500},
	Pages = {2323--2326},
	Title = {Nonlinear Dimensionality Reduction by Locally Linear Embedding},
	Volume = {290},
	Year = {2000}}

@article{Tenenbaum:2000,
	Author = {Tenenbaum, J. and de Silva, V. and Langford, J.},
	Journal = {Science},
	Number = {5500},
	Pages = {2319--2323},
	Title = {A Global Geometric Framework for Nonlinear Dimensionality Reduction},
	Volume = {290},
	Year = {2000}}

@article{Pitman:1996,
	Author = {Pitman, J.},
	Journal = {Advances in Applied Probability},
	Number = {2},
	Pages = {525--539},
	Title = {Random Discrete Distributions Invariant under Size-Biased Permutation},
	Volume = {28},
	Year = {1996}}

@article{Schapire:2003,
	Author = {Schapire, R.},
	Journal = {Nonlinear Estimation and Classification},
	Title = {The Boosting Approach to Machine Learning: {A}n Overview},
	Year = {2003}}

@inproceedings{Leskovec:2005,
	Author = {Leskovec, J. and Kleinberg, J. and Faloutsos, C.},
	Booktitle = {KDD},
	Title = {Graphs over Time: {D}ensification Laws, Shrinking Diameters and Possible Explanations},
	Year = {2005}}

@inproceedings{Boyd-Graber:2006,
	Author = {Boyd-Graber, J. and and D. Osherson, Christiane Fellbaum and Schapire, R.},
	Booktitle = {Proceedings of the Third Global WordNet Meeting Meeting},
	Title = {Adding Dense, Weighted Connections to {W}ord{N}et Connections to WORDNET},
	Year = {2006}}

@phdthesis{Jaakkola:1997,
	Author = {Jaakkola, T.},
	School = {Massachusetts Institute of Technology},
	Title = {Variational Methods for Inference and Estimation in Graphical Models},
	Year = {1997}}

@incollection{Hearst:1998,
	Author = {Hearst, M.},
	Booktitle = {Automated Discovery of {W}ord{N}et Relations},
	Editor = {Fellbaum, C.},
	Publisher = {MIT Press},
	Title = {{W}ord{N}et: {A}n Electronic Lexical Database and Some of its Applications},
	Year = {1998}}

@inproceedings{Snow:2006,
	Address = {Sydney, Australia},
	Author = {Snow, R. and Jurafsky, D. and Ng, A.},
	Booktitle = {Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics},
	Month = {July},
	Pages = {801--808},
	Publisher = {Association for Computational Linguistics},
	Title = {Semantic Taxonomy Induction from Heterogenous Evidence},
	Year = {2006}}

@electronic{Csomai:,
	Author = {Csomai, A.},
	Title = {{W}ord{N}et Bibliography},
	Urldate = {2006}}

@inproceedings{Borman:2005,
	Author = {Borman, A. and Mihalcea, R. and Tarau, P.},
	Booktitle = {American Association for Artificial Intelligence},
	Title = {{PicNet}: {A}ugmenting Semantic Resources with Pictorial Representations},
	Year = {2005}}

@inproceedings{Kipper:2000,
	Author = {Kipper, K. and Dang, H. and Palmer, M.},
	Booktitle = {{AAAI}-2000 Seventeenth National Conference on Artificial Intelligence},
	Title = {Class-based construction of a verb lexicon},
	Year = {2000}}

@inproceedings{Lebanon:2004,
	Author = {Lebanon, G. and Lafferty, J.},
	Title = {Hyperplane margin classifiers on the multinomial manifold},
	Year = {2004?}}

@inproceedings{Murphy:1999,
	Author = {Murphy, K.},
	Booktitle = {UAI 99},
	Title = {A variational approximation for {B}ayesian networks with discrete and continuous latent variables},
	Year = {1999}}

@techreport{Hunter:2005,
	Author = {Hunter, D. and Handcock, M.},
	Institution = {Center for Statistics and the Social Sciences, University of Washington},
	Number = {43},
	Title = {Inference in curved exponential family models for networks},
	Year = {2005}}

@article{Huisman:2003,
	Author = {Huisman, M. and Snijders, T.},
	Journal = {Sociological Methods and Research},
	Number = {2},
	Pages = {253--287},
	Title = {Statistical analysis of longitudinal network data with changing composition},
	Volume = {32},
	Year = {2003}}

@techreport{Hoff:2003b,
	Author = {Hoff, P.},
	Title = {Nonparametric modeling of hierarchically exchangeable data},
	Year = {2003}}

@techreport{Hoff:2004a,
	Author = {Hoff, P.},
	Institution = {University of Washington},
	Number = {448},
	Title = {Clustering based on {D}irichlet mixtures of attribute ensembles},
	Year = {2004}}

@inproceedings{Lasserre:2006,
	Author = {Lasserre, J. and Bishop, C. and Minka, T.},
	Booktitle = {CVPR},
	Title = {Principled hybrids of generative and discriminative models},
	Year = {2006}}

@article{Ulusoy:2005,
	Author = {Ulusoy, I. and Bishop, C.},
	Title = {Generative versus discriminative methods for object recognition},
	Year = {2005}}

@article{Barutcuoglu:2006,
	Author = {Barutcuoglu, Z. and Schapire, R. and Troyanskaya, O.},
	Journal = {Bioinformatics},
	Number = {7},
	Pages = {830--836},
	Title = {Hierarchical multi-label prediction of gene function},
	Volume = {22},
	Year = {2006}}

@article{Landauer:2004,
	Author = {Landauer, T. and Laham, D. and Derr, M.},
	Journal = {Proceedings of the National Academy of Science},
	Pages = {5214--5219},
	Title = {From paragraph to graph: {L}atent semantic analysis for information visualization},
	Volume = {101},
	Year = {2004}}

@inproceedings{Spielman:2004,
	Author = {Spielman, D. and Teng, S.},
	Booktitle = {STOC},
	Title = {Nearly-Linear Time Algorithms for Graph Partitioning, Graph Sparsification, and Solving Linear Systems},
	Year = {2004}}

@article{Pachter:2004,
	Author = {Pachter, L. and Sturmfels, B.},
	Title = {Tropical Geometry of Statistical Models},
	Year = {2004}}

@article{Motter:2002,
	Author = {Motter, A. and Moura, A. and Lai, Y. and Dasgupta, P.},
	Journal = {Physical Review E.},
	Title = {Topology of the Conceptual Network of Language},
	Volume = {65},
	Year = {2002}}

@article{Hill:2006,
	Author = {Hill, S. and Agarwal, D. and Bell, R. and Volinsky, C.},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {1--25},
	Title = {Building an Effective Representation for Dynamic Networks},
	Volume = {15},
	Year = {2006}}

@article{Jorgensen:1998,
	Author = {Jorgensen, B. and Christensen, S. and Song, X. and Sun, L.},
	Title = {A State Space Model for Multivariate Longitudinal Count Data},
	Year = {1998}}

@article{Heckerman:2000,
	Author = {Heckerman, D. and Chickering, M. and Meek, C. and Rounthwaite, R. and Kadie, C.},
	Journal = {Journal of Machine Learning Research},
	Number = {49--75},
	Title = {Dependency Networks for Inference, Collaborative Filtering, and Data Visualization},
	Volume = {1},
	Year = {2000}}

@inproceedings{Bruce:1992,
	Author = {Bruce, R. and Wiebe, J.},
	Title = {Word-Sense Disambiguation Using Decomposable Models},
	Year = {1992?}}

@inproceedings{Lee:2006,
	Author = {Lee, S. and Lee, H. and Abbeel, P. and Ng, A.},
	Booktitle = {AAAI},
	Title = {Efficient $L_1$ Regularized Logistic Regression},
	Year = {2006}}

@article{Ellis:2006,
	Author = {Ellis, S. and Nayakkankuppam, M.},
	Title = {Phylogenetic Analysis Via {DC} Programming},
	Year = {2006}}

@inproceedings{Argyiou:2006,
	Author = {Argyiou, A. and Hauser, R. and Micchelli, C. and Pontil, M.},
	Booktitle = {Proceedings of the 27th International Conference on Machine Learning},
	Title = {A {DC}-Programming Algorithm for Kernel Selection},
	Year = {2006}}

@article{Zou:2005,
	Author = {Zou, H. and Hastie, T.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Pages = {301--320},
	Title = {Regulariational and variable selection via the elastic net},
	Volume = {67},
	Year = {2005}}

@article{Horst:1999,
	Author = {Horst, R. and Thoai, N.},
	Journal = {Journal of Optimization Theory and Applications},
	Number = {1},
	Pages = {1--43},
	Title = {{DC} Programming: {O}verview},
	Volume = {103},
	Year = {1999}}

@article{Handcock:2007,
	Author = {Handcock, M. and Raftery, A.},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Pages = {301--354},
	Title = {Model-based clustering for social networks (with discussion)},
	Volume = {170},
	Year = {2007}}

@inproceedings{Snelson:2006a,
	Author = {Snelson, E. and Ghahramani, Z.},
	Title = {Variable Noise and Dimensionality Reduction for Sparse Gaussian Processes},
	Year = {2006}}

@inproceedings{Teh:2006,
	Author = {Teh, Y. and Newman, D. and Welling, M.},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {A Collapsed Variational {B}ayesian Inference Algorithm for Latent {D}irichlet Allocation},
	Year = {2006}}

@article{Bickel:2006,
	Author = {Bickel, P. and Li, B.},
	Journal = {Sociedad de Estadistica e Investigation Operativa Test},
	Number = {2},
	Title = {Regularization in Statistics},
	Volume = {15},
	Year = {2006}}

@article{Tukey:1962a,
	Author = {Tukey, J.},
	Journal = {The Annals of Mathematical Statistics},
	Number = {1},
	Pages = {1--67},
	Title = {The Future of Data Analysis},
	Volume = {33},
	Year = {1962}}

@article{Tukey:1962,
	Author = {Tukey, J.},
	Journal = {The Annals of Mathematical Statistics},
	Number = {2},
	Pages = {812},
	Title = {Correction to "The Future of Data Analysis"},
	Volume = {33},
	Year = {1962}}

@inproceedings{Kurihara:2007a,
	Author = {Kurihara, K. and Welling, M. and Vlassis, N.},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Accelerated Variational {D}irichlet Process Mixtures},
	Year = {2007}}

@article{Whitehead:1916,
	Author = {Whitehead, A. N.},
	Journal = {Science},
	Number = {1134},
	Pages = {409--419},
	Title = {The organization of thought},
	Volume = {44},
	Year = {1916}}

@article{Balakrishnan:2008,
	Author = {Balakrishnan, S. and Madigan, D.},
	Journal = {Journal of Machine Learning Research},
	Pages = {313--337},
	Title = {Algorithms for Sparse Linear Classifiers in the Massive Data Setting},
	Volume = {9},
	Year = {2008}}

@article{Slonim:2005,
	Author = {Slonim, N. and Gurinder, A. and Tkacik, G. and Bialek, W.},
	Journal = {Proceedings of the National Academy of Science},
	Number = {51},
	Pages = {18297--18302},
	Title = {Information Based Clustering},
	Volume = {102},
	Year = {2005}}

@article{Salton:1994,
	Author = {Salton, G. and Allan, J. and Buckley, C. and Singhal, A.},
	Journal = {Science},
	Number = {5164},
	Pages = {1421--1426},
	Title = {Automatic Analysis, Theme Generation, and Summarization of Machine-Readable Texts},
	Volume = {264},
	Year = {1994}}

@techreport{Lafferty:2005,
	Author = {Lafferty, J. and Wasserman, L.},
	Institution = {Carnegie Mellon University},
	Title = {Rodeo: {S}parse Nonparametric Regression in High Dimensions},
	Year = {2005}}

@article{Lijoi:2004,
	Author = {Lijoi, A. and Regazzini, E.},
	Journal = {The Annals of Probability},
	Number = {2},
	Pages = {1469--1495},
	Title = {Means of a {D}irichlet Process and Multiple Hypergeometric Functions},
	Volume = {32},
	Year = {2004}}

@article{M.:1889,
	Author = {M., A. B.},
	Journal = {Science},
	Number = {320},
	Pages = {226},
	Title = {Curves of Literary Style},
	Volume = {13},
	Year = {1889}}

@inproceedings{Korf:1997,
	Author = {Korf, R.},
	Booktitle = {AAAI},
	Title = {Finding Optimal Solutions to Rubik's Cube Using Pattern Databases},
	Year = {1997}}

@unpublished{Bhattacharya:2006,
	Author = {Bhattacharya, S. and Haslett, J.},
	Title = {Importance Re-sampling {MCMC} for Cross-Validation in Inverse Problems},
	Year = {2006?}}

@inproceedings{Vickrey:2005,
	Author = {Vickrey, D. and Biewald, L. and Teyssier, M. and Koller, D.},
	Booktitle = {Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP)},
	Pages = {771--778},
	Title = {Word-Sense Disambiguation for Machine Translation},
	Year = {2005}}

@unpublished{Fienberg:2006,
	Author = {Fienberg, S. and Rinaldo, A.},
	Title = {Computing Maximum Likelihood Estimates in Log-Linear Models},
	Year = {2006}}

@book{McCullagh:1989,
	Author = {McCullagh, P. and Nelder, J.},
	Publisher = {London: Chapman and Hall},
	Title = {Generalized Linear Models},
	Year = {1989}}

@article{Nelder:1972,
	Author = {Nelder, J. A. and Wedderburn, R. W. M.},
	Journal = {Journal of the Royal Statistical Society. Series A (General)},
	Pages = {370--384},
	Title = {Generalized Linear Models},
	Volume = {135},
	Year = {1972}}

@article{Lee:1996,
	Author = {Lee, Y. and Nelder, J. A.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {4},
	Pages = {619--678},
	Title = {Hierarchical Generalized Linear Models},
	Volume = {58},
	Year = {1996}}

@article{Efron:1986,
	Author = {Efron, B.},
	Journal = {Journal of the American Statistical Association},
	Number = {395},
	Pages = {709--721},
	Title = {Double Exponential Families and Their Use in Generalized Linear Regression},
	Volume = {81},
	Year = {1986}}

@article{Efron:1986b,
	Author = {Efron, B.},
	Journal = {Journal of the American Statistical Association},
	Number = {382},
	Pages = {316--331},
	Title = {Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation},
	Volume = {78},
	Year = {1986}}

@article{Lambert:1995,
	Author = {Lambert, D. and Roeder, K.},
	Journal = {Journal of the American Statistical Association},
	Pages = {1225--1236},
	Title = {Overdispersion Diagnostics for Generalized Linear Models},
	Volume = {90},
	Year = {1995}}

@article{Gelfand:1999,
	Author = {Gelfand, A. E. and Sahu, S. K.},
	Journal = {Journal of the American Statistical Association},
	Pages = {247--253},
	Title = {Identifiability, Improper Priors, and Gibbs Sampling for Generalized Linear Models},
	Volume = {94},
	Year = {1999}}

@article{Gelfand:1990a,
	Author = {Gelfand, A. E. and Dalal, S. R.},
	Journal = {Biometrika},
	Pages = {55--64},
	Title = {A Note on Overdispersed Exponential Families},
	Volume = {77},
	Year = {1990}}

@article{Mukhopadhyay:1997,
	Author = {Mukhopadhyay, S. and Gelfand, A. E.},
	Journal = {Journal of the American Statistical Association},
	Number = {438},
	Pages = {633--639},
	Title = {{D}irichlet Process Mixed Generalized Linear Models},
	Volume = {92},
	Year = {1997}}

@article{Zeger:1991,
	Author = {Zeger, S. L. and Karim, M. R.},
	Journal = {Journal of the American Statistical Association},
	Pages = {79--86},
	Title = {Generalized Linear Models with Random Effect: {A} {G}ibbs Sampling Approach},
	Volume = {86},
	Year = {1991}}

@article{Sammel:1997,
	Author = {Sammel, M. D., Ryan L. M. Legler J. M.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {3},
	Pages = {667--678},
	Title = {Latent Variable Models for Mixed Discrete and Continuous Outcomes},
	Volume = {59},
	Year = {1997}}

@article{Kleinman:1998,
	Author = {Kleinman, K. P. and Ibrahim, J. G.},
	Journal = {Statistics in Medicine},
	Title = {A semi-parametric {B}ayesian approach to generalized linear mixed models},
	Volume = {2579--2596},
	Year = {1998}}

@article{Dunson:2000,
	Author = {Dunson, D.},
	Journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	Number = {2},
	Pages = {355--366},
	Title = {{B}ayesian Latent Variable Models for Clustered Mixed Outcomes},
	Volume = {62},
	Year = {2000}}

@article{Navigli:2005,
	Author = {Navigli, R. and Velardi, P.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {7},
	Pages = {1--12},
	Title = {Structural Semantic Interconnections: {A} Knowledge-Based Approach to Word Sense Disambiguation},
	Volume = {27},
	Year = {2005}}

@article{Brinkman:2005,
	Author = {Brinkman, B. and Charikar, M.},
	Journal = {Journal of the ACM (JACM)},
	Number = {5},
	Pages = {766--788},
	Title = {On the Impossibility of Dimension Reduction in $\ell_1$},
	Volume = {52},
	Year = {2005}}

@article{Hochbaum:2001,
	Author = {Hochbaum, D.},
	Journal = {Journal of the ACM (JACM)},
	Number = {4},
	Pages = {686--701},
	Title = {An Efficient Algorithm for Image Segmentation, {M}arkov Random Fields and Related Problems},
	Volume = {48},
	Year = {2001}}

@article{Flajolet:2006,
	Author = {Flajolet, P. and Szpankowski, W. and Vallee, B.},
	Journal = {Journal of the ACM (JACM)},
	Number = {1},
	Pages = {147--183},
	Title = {Hidden Word Statistics},
	Volume = {53},
	Year = {2006}}

@article{Nott:2004,
	Author = {Nott, D. and Green, P.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {1},
	Pages = {1--17},
	Title = {Bayesian Variable Selection and the {S}wendsen-{W}ang Algorithm},
	Volume = {13},
	Year = {2004}}

@article{Price:1965,
	Author = {Price, D.},
	Journal = {Science},
	Number = {3683},
	Title = {Networks of Scientific Papers},
	Volume = {149},
	Year = {1965}}

@inproceedings{Goldwater:2006a,
	Author = {Goldwater, S. and Griffiths, T. and Johnson, M.},
	Booktitle = {Neural Information Processing Systems},
	Title = {Interpolating between types and tokens by estimating power-law generators},
	Year = {2006}}

@article{Newman:2006a,
	Author = {Newman, D. and Block, S.},
	Journal = {Journal of the American Society of Information Science and Technology},
	Month = {April},
	Title = {Probabilistic Topic Decomposition of an Eighteenth-Century American Newspaper},
	Year = {2006}}

@book{mackay2003information,
	Author = {MacKay, David},
	Date-Modified = {2020-04-13 17:52:13 -0400},
	Publisher = {Cambridge University Press},
	Title = {Information Theory, Inference, and Learning Algorithms},
	Year = {2003}}

@article{Turing:1950,
	Author = {Turing, A.},
	Journal = {Mind},
	Number = {236},
	Pages = {433--460},
	Title = {Computing Machinery and Intelligence},
	Volume = {59},
	Year = {1950}}

@article{Mallows:2006,
	Author = {Mallows, C.},
	Journal = {Technometrics},
	Number = {3},
	Title = {Tukey's Paper After 40 years},
	Volume = {48},
	Year = {2006}}

@article{White:1915,
	Author = {White, H.},
	Journal = {Science},
	Number = {1073},
	Pages = {105--113},
	Title = {Forty years' Fluctuations in Mathematical Research},
	Volume = {42},
	Year = {1915}}

@techreport{Efron:2002,
	Author = {Efron, B. and Hastie, T. and Johnstone, I. and Tibshirani, R.},
	Institution = {Stanford University},
	Title = {Least Angle Regression},
	Year = {2002}}

@article{Tibshirani:1996,
	Author = {Tibshirani, R.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {1},
	Pages = {267--288},
	Title = {Regression Shrinkage and Selection via the Lasso},
	Volume = {58},
	Year = {1996}}

@inproceedings{Mei:2005,
	Author = {Mei, Q. and Zhang, C.},
	Booktitle = {KDD},
	Title = {Discovering evolutionary theme patterns from text -- {A}n exploration of temporal text mining},
	Year = {2005}}

@inproceedings{Jiang:1997,
	Author = {Jiang, J. and Conrath, D.},
	Booktitle = {Proceedings of the International Conference on Research on Computational Linguistics},
	Title = {Semantic similarity based on corpus statistics and taxonomy},
	Year = {1997}}

@article{Damashek:1995,
	Author = {Damashek, M.},
	Journal = {Science},
	Number = {5199},
	Pages = {843--848},
	Title = {Gauging Similarity with n-Grams: {L}anguage-independent categorization of text},
	Volume = {267},
	Year = {1995}}

@article{Lindsay:1994,
	Author = {Lindsay, B.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {1081--1114},
	Title = {Efficiency versus robustness: {T}he case for minimum {H}ellinger distance and related methods},
	Volume = {22},
	Year = {1994}}

@article{Haff:1991,
	Author = {Haff, L.},
	Journal = {The Annals of Statistics},
	Number = {3},
	Pages = {1163--1190},
	Title = {The Variational Form of Certain {B}ayes Estimators},
	Volume = {19},
	Year = {1991}}

@article{Haff:1980,
	Author = {Haff, L.},
	Journal = {The Annals of Statistics},
	Number = {3},
	Pages = {586--597},
	Title = {Empirical {B}ayes Estimation of the Multivariate Normal Covariance Matrix},
	Volume = {8},
	Year = {1980}}

@techreport{Griffin:2004,
	Author = {Griffin, J.},
	Institution = {University of Warwick},
	Title = {Bayesian Nonparametric Modelling of Grouped Data},
	Year = {2004?}}

@article{Carmichael:1913,
	Author = {Carmichael, R.},
	Journal = {Science},
	Number = {990},
	Pages = {863--871},
	Title = {On the Nature of Mathematical and Scientific Demonstration},
	Volume = {38},
	Year = {1913}}

@article{Goldsmith:2001,
	Author = {Goldsmith, J.},
	Journal = {Computational Linguistics},
	Number = {1},
	Title = {Unsupervised Learning of the Morphology of a Natural Language},
	Volume = {27},
	Year = {2001}}

@book{Gelman:2007,
	Author = {Gelman, A. and Hill, J.},
	Publisher = {Cambridge Univ. Press},
	Title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
	Year = {2007}}

@unpublished{Freedman:2004,
	Author = {Freedman, D.},
	Month = {July},
	Title = {Notes on {B}ayesian Statistics},
	Year = {2004}}

@article{Nelson:2004,
	Author = {Nelson, D. and McEvoy, C.},
	Journal = {Behavior Research Methods, Instruments, and Computers},
	Number = {3},
	Pages = {402--407},
	Title = {The {U}niversity of {S}outh {F}lorida free association, rhyme, and word fragment norms},
	Volume = {36},
	Year = {2004}}

@article{Hanneke:2006,
	Author = {Hanneke, S. and Xing, E.},
	Title = {Discrete temporal models of social networks},
	Year = {2006}}

@article{Handcock:2006,
	Author = {Handcock, M.},
	Title = {A Simple Model for Complex Networks with Arbitrary Degree Distribution and Clustering},
	Year = {2006}}

@article{Meinshausen:2006,
	Author = {Meinshausen, N. and Buhlmann, P.},
	Journal = {The Annals of Statistics},
	Number = {3},
	Pages = {1436--1462},
	Title = {High Dimensional Graphs and Variable Selection with the Lasso},
	Volume = {34},
	Year = {2006}}

@article{Frank:1986,
	Author = {Frank, O. and Strauss, D.},
	Journal = {Journal of the American Statistical Association},
	Number = {395},
	Pages = {832--842},
	Title = {Markov Graphs},
	Volume = {81},
	Year = {1986}}

@article{Fraley:2002,
	Author = {Fraley, C. and Raftery, A.},
	Journal = {Journal of the American Statistical Association},
	Number = {458},
	Pages = {611--631},
	Title = {Model-Based Clustering, Discriminant Analysis, and Density Estimation},
	Volume = {97},
	Year = {2002}}

@article{Salton:1970,
	Author = {Salton, G.},
	Journal = {Science},
	Number = {3929},
	Pages = {335--343},
	Title = {Automatic Text Analysis},
	Volume = {168},
	Year = {1970}}

@article{Benjamini:1995,
	Author = {Benjamini, Y. and Hochberg, Y.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {1},
	Pages = {289--300},
	Title = {Controlling the False Discovery Rate: {A} Practical and Powerful Approach to Multiple Testing},
	Volume = {57},
	Year = {1995}}

@article{Snijders:2004,
	Author = {Snijders, R. and Pattison, P. and Robins, G. and Handcock, M.},
	Title = {New Specifications for Exponential Random Graph Models},
	Year = {2004}}

@article{Eckmann:2000,
	Author = {Eckmann, J. and Moses, E.},
	Title = {Curvature of Co-Links Uncovers Hidden Thematic Layers in the World Wide Web},
	Year = {2000}}

@article{Blei:2006c,
	Author = {Blei, D. and Franks, K. and Jordan, M. and Mian, S.},
	Journal = {BMC Bioinformatics},
	Number = {250},
	Title = {Statistical modeling of biomedical corpora: mining the {C}aenorhabditis {G}enetic {C}enter {B}ibliography for genes related to life span},
	Volume = {7},
	Year = {2006}}

@article{Cooper:2004,
	Author = {Cooper, M.},
	Title = {A Mathematical Model of Historical Semantics and the Grouping of Word Meanings into Concepts},
	Year = {2004}}

@article{Berg:2002,
	Author = {Berg, J. and Lassig, M.},
	Title = {Correlated Random Networks},
	Year = {2002}}

@article{Gliozza:2004,
	Author = {Gliozza, A. and Strapparava, C. and Dagan, I.},
	Title = {Unsupervised and Supervised Exploitation of Semantic Domains in Lexical Disambiguation},
	Year = {2004}}

@article{Allman:1976,
	Author = {Allman, J. and Kaas, J.},
	Journal = {Science},
	Number = {4227},
	Pages = {572--575},
	Title = {Representation of the Visual Field on the Medial Wall of Occipital-Parietal in the Owl Monkey},
	Volume = {191},
	Year = {1976}}

@article{Chapman:1880,
	Author = {Chapman, H.},
	Journal = {Science},
	Number = {27},
	Pages = {326--328},
	Title = {The Brain of the Orang},
	Volume = {1},
	Year = {1880}}

@inproceedings{Jaakkola:1996,
	Author = {Jaakkola, T. and Jordan, M.},
	Booktitle = {International Workshop on Artificial Intelligence and Statistics},
	Title = {A Variational Approach to {B}ayesian Logistic Regression Models and Their Extensions},
	Year = {1996}}

@article{Wong:2005,
	Author = {Wong, L. and Pattison, P. and Robins, G.},
	Title = {A Spatial Model for Social Networks},
	Year = {2005}}

@article{Pedersen:2005,
	Author = {Pedersen, T. and Banerjee, S. and Patwardham, S.},
	Title = {Maximizing Semantic Relatedness to Perform Word Sense Disambiguation},
	Year = {2005}}

@article{Duan:2007,
	Author = {Duan, J. and Guindani, M. and Gelfand, A.},
	Journal = {Biometrika},
	Pages = {809--825},
	Title = {Generalized Spatial {D}irichlet Process Models},
	Volume = {94},
	Year = {2007}}

@inproceedings{Daume:2006,
	Author = {Daume, H. and Marcu, D.},
	Booktitle = {Proceedings of the ACL},
	Title = {Bayesian Query-Focused Summarization},
	Year = {2006}}

@inproceedings{McCarthy:2004,
	Author = {McCarthy, D. and Koeling, R. and Weeds, J. and Carroll, J.},
	Booktitle = {Proceedings of the 42nd ACL},
	Pages = {280--287},
	Title = {Finding Predominant Word Senses in Untagged Text},
	Year = {2004}}

@inproceedings{Brody:2006,
	Author = {Brody, S. and Navigli, R. and Lapata, M.},
	Title = {Ensemble Methods for Unsupervised {WSD}},
	Year = {2006}}

@article{Garfield:2006,
	Author = {Garfield, E.},
	Journal = {Journal of the American Medical Association},
	Pages = {90--93},
	Title = {The History and Meaning of the journal Impact Factor},
	Volume = {293},
	Year = {2006}}

@article{Jacobs:1991,
	Author = {Jacobs, K. and Donoghue, J.},
	Journal = {Science},
	Month = feb,
	Pages = {944--947},
	Title = {Reshaping the Cortical Motor Map by Unmasking Latent Intracortical Connections},
	Volume = 251,
	Year = 1991}

@article{Spitzka:1903,
	Author = {Spitzka, E.},
	Journal = {Science},
	Pages = {346},
	Title = {The Brain of Professor Laborde},
	Volume = 18,
	Year = 1903}

@inproceedings{Griffiths:2006a,
	Author = {Griffiths, T. and Ghahramani, Z.},
	Booktitle = {Advances in Neural Information Processing Systems (NIPS)},
	Title = {Infinite latent feature models and the {I}ndian buffet process},
	Year = {2006}}

@article{Kendall:1948,
	Author = {Kendall, D.},
	Journal = {Annals of Mathematical Statistics},
	Number = {1},
	Title = {On the generalized "birth-and-death" process},
	Volume = {19},
	Year = {1948}}

@url{Wikipedia:,
	Author = {Wikipedia},
	Title = {Wikipedia, {T}he Free Encyclopedia (http://en.wikipedia.org/)},
	Urldate = {5, July 2006}}

@article{Kleinberg:1999,
	Author = {Kleinberg, J.},
	Journal = {Journal of the ACM},
	Number = {5},
	Pages = {604--632},
	Title = {authoritative sources in a hyperlinked environment},
	Volume = {46},
	Year = {1999}}

@inproceedings{Ng:2001,
	Author = {Ng, A. and Zheng, A. and Jordan, M.},
	Booktitle = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
	Title = {Stable Algorithms for Link Analysis},
	Year = 2001}

@article{Brin:1998,
	Author = {Brin, S. and Page, L.},
	Journal = {Computer Networks and {ISDN} Systems},
	Pages = {107--117},
	Title = {The anatomy of a large-scale hypertextual {Web} search engine},
	Volume = {30},
	Year = {1998}}

@inproceedings{Gibson:1998,
	Author = {Gibson, D. and Kleinberg, J. and Raghavan, P.},
	Booktitle = {{UK} Conference on Hypertext},
	Pages = {225--234},
	Title = {Inferring Web Communities from Link Topology},
	Year = {1998}}

@inproceedings{Pasula:2002,
	Author = {Pasula, H. and Marthi, B. and Milch, B. and Russell, S. and Shpitser, I.},
	Booktitle = {Advances in Neural Information Processing Systems 15},
	Title = {Identity uncertainty and citation matching},
	Year = {2002}}

@article{Miller:1990,
	Author = {Miller, G. and Beckwith, R. and Fellbaum, C. and Gross, D. and Miller, K.},
	Journal = {International Journal of Lexicography},
	Number = {4},
	Pages = {235--244},
	Title = {Introduction to {W}ord{N}et: {A}n Online Lexical Database},
	Volume = {3},
	Year = {1990}}

@book{Wasserman:1994,
	Author = {Wasserman, S. and Faust, K.},
	Publisher = {Cambridge University Press},
	Title = {Social Network Analysis},
	Year = {1994}}

@book{Arratia:2003,
	Author = {Arratia, R. and Tavare, S. and Barbour, A.},
	Publisher = {European Mathematical Society},
	Title = {Log Combinatorial Structures: {A} Probabilistic Approach},
	Year = {2003}}

@article{Genovese:2001,
	Author = {Genovese, C.},
	Journal = {Journal of the American Statistical Association},
	Pages = {691--703},
	Title = {A {B}ayesian Time-Course Model for Functional Magnetic Resonance Imaging Data},
	Volume = {95},
	Year = {2001}}

@article{Sarkar:2005,
	Author = {Sarkar, P. and Moore, A.},
	Journal = {{SIGKDD} Explorations},
	Title = {Dynamic social network analysis using latent space models},
	Year = {2005}}

@book{Manning:1999,
	Address = {Cambridge, MA},
	Author = {Manning, C. and Schutze, H.},
	Publisher = {The {MIT} Press},
	Title = {Foundations of Statistical Natural Language Processing},
	Year = {1999}}

@inproceedings{Mann:2006,
	Author = {Mann, G. and Mimno, D. and McCallum, A.},
	Booktitle = {Joint Conference on Digital Libraries},
	Title = {Bibliometric Impact measures Leveraging Topic Analysis},
	Year = {2006}}

@misc{JSTOR:0000,
	Title = {{JSTOR} Archive (http://www.jstor.org)}}

@article{Steen:1988,
	Author = {Steen, L.},
	Journal = {Science},
	Number = {4852},
	Pages = {611--616},
	Title = {The Science of Patterns},
	Volume = {240},
	Year = {1988}}

@article{Goffard:1960,
	Author = {Goffard, S. and Windle, C. and Weiss, P. and Buckley, J.},
	Journal = {Science},
	Number = {3427},
	Pages = {625--626},
	Title = {Life of Scientific Publications},
	Volume = {312},
	Year = {1960}}

@article{Dissemination:1972,
	Author = {Dissemination, Selective},
	Journal = {Science},
	Number = {4033},
	Pages = {434--437},
	Title = {Lancaster, F. and Schneider, J.},
	Volume = {176},
	Year = {1972}}

@article{Schneider:1971,
	Author = {Schneider, J.},
	Journal = {Science},
	Number = {3994},
	Pages = {300--308},
	Title = {Selective Dissemination and Indexing of Scientific Information},
	Volume = {173},
	Year = {1971}}

@article{Green:1964,
	Author = {Green, J.},
	Journal = {Science},
	Number = {3619},
	Pages = {646--648},
	Title = {The Information Explosion: {R}eal or Imaginary},
	Volume = {144},
	Year = {1964}}

@article{Brown:1967,
	Author = {Brown, W. and Pierce, J. and Traub, J.},
	Journal = {Science},
	Number = {3805},
	Pages = {1153--1159},
	Title = {The Future of Scientific journals},
	Volume = {158},
	Year = {1967}}

@article{Salton:1964,
	Author = {Salton, G.},
	Journal = {Science},
	Number = {3619},
	Pages = {626--632},
	Title = {Automatic Information Processing in Western Europe},
	Volume = {144},
	Year = {1964}}

@article{Holton:1975,
	Author = {Holton, G.},
	Journal = {Science},
	Number = {4186},
	Pages = {328--334},
	Title = {On the Role of Themata in Scientific Thought},
	Volume = {188},
	Year = {1975}}

@article{Boulding:1980,
	Author = {Boulding, K.},
	Journal = {Science},
	Number = {4433},
	Pages = {831--836},
	Title = {Science: Our Common Heritage},
	Volume = {207},
	Year = {1980}}

@article{Waldrop:1984,
	Author = {Waldrop, M.},
	Journal = {Science},
	Number = {4642},
	Pages = {1279--1282},
	Title = {The Necessity of Knowledge},
	Volume = {223},
	Year = {1984}}

@article{Pearl:1905,
	Author = {Pearl, R.},
	Journal = {Science},
	Number = {523},
	Pages = {32--35},
	Title = {A Notable Advance in the Theory of Correlation},
	Volume = {21},
	Year = {1905}}

@article{Rosen:1967,
	Author = {Rosen, C.},
	Journal = {Science},
	Number = {3771},
	Pages = {38--44},
	Title = {Pattern Classification by Adaptive Machines},
	Volume = {156},
	Year = {1967}}

@article{Griffin:2006,
	Author = {Griffin, J. and Steel, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {473},
	Pages = {179--194},
	Title = {Order-based Dependent {D}irichlet Processes},
	Volume = {101},
	Year = {2006}}

@inproceedings{Blei:2006a,
	Author = {Blei, D. and Lafferty, J.},
	Booktitle = {International Conference on Machine Learning},
	Pages = {113--120},
	Title = {Dynamic topic models},
	Year = {2006}}

@article{Hobert:1999,
	Author = {Hobert, J. and Robert, C. and Titterington, D.},
	Journal = {Statistics and Computing},
	Pages = {287--298},
	Title = {On perfect simulation for some mixtures of distributions},
	Volume = {9},
	Year = {1999}}

@article{Albert:1988,
	Author = {Albert, J.},
	Journal = {Journal of the American Statistical Association},
	Number = {404},
	Pages = {1037--1044},
	Title = {Computational methods using a {B}ayesian hierarchical generalized linear model},
	Volume = {83},
	Year = {1988}}

@article{Hestenes:1987,
	Author = {Hestenes, M.},
	Journal = {ACM?},
	Title = {Conjugacy and gradients},
	Year = {1987}}

@techreport{Handcock:2003,
	Author = {Handcock, M.},
	Institution = {University of Washington},
	Number = {Working Paper 39},
	Title = {Assessing degeneracy in statistical models of social networks},
	Year = {2003}}

@techreport{Kemp:2004,
	Author = {Kemp, C. and Griffiths, T. and Tenenbaum, J.},
	Institution = {Massachusetts Institute of Technology},
	Number = {AI Memo 2004-019},
	Title = {Discovering latent classes in relational data},
	Year = {2004}}

@unpublished{Fowler:2005,
	Author = {Fowler, J.},
	Month = {June},
	Title = {Who is the best connected legislator: {A} study of cosponsorship networks},
	Year = {2005}}

@article{Ibrahim:1991,
	Author = {Ibrahim, J. and Laud, P.},
	Journal = {Journal of the American Statistical Association},
	Number = {416},
	Pages = {981--986},
	Title = {On {B}ayesian analysis of generalized linear models using {J}effrey's's prior},
	Volume = {86},
	Year = {1991}}

@inproceedings{Snelson:2006,
	Address = {Cambridge, MA},
	Author = {Snelson, E. and Ghahramani, Z.},
	Booktitle = {Advances in Neural Information Processing Systems 18},
	Editor = {Weiss, Y. and Sch\"{o}lkopf, B. and Platt, J.},
	Publisher = {MIT Press},
	Title = {Sparse {G}aussian Processes using Pseudo-inputs},
	Year = {2006}}

@inproceedings{Yarowsky:1995,
	Author = {Yarowsky, D.},
	Booktitle = {Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics},
	Pages = {189--196},
	Title = {Unsupervised Word Sense Disambiguation Rivaling Supervised Methods},
	Year = {1995}}

@article{Watanabe:2006,
	Author = {Watanabe, K. and Watanabe, S.},
	Journal = {Journal of Machine Learning Research},
	Number = {625--644},
	Title = {Stochastic Complexities of {G}aussian Mixtures in Variational {B}ayesian Approximation},
	Volume = {7},
	Year = {2006}}

@inproceedings{Wainwright:2003a,
	Author = {Wainwright, M. and Jordan, M.},
	Booktitle = {Allerton Conference on Control, Communication and Computation},
	Title = {Variational Inference in Graphical Models: The View from the Marginal Polytope},
	Year = {2003}}

@article{Penny:2005,
	Author = {Penny, W. and Trujillo-Barreto, N. and Friston, K.},
	Journal = {Neuroimage},
	Pages = {350--362},
	Title = {Bayesian F{MRI} Time Series Analysis with Spatial Priors},
	Volume = {24},
	Year = {2005}}

@article{Ashburner:2005,
	Author = {Ashburner, J. and Friston, K.},
	Journal = {Neuroimage},
	Pages = {839--851},
	Title = {Unified Segmentation},
	Volume = {26},
	Year = {2005}}

@inproceedings{Sudderth:2005,
	Author = {Sudderth, E. and Torralba, A. and Freeman, W. and Willsky, A.},
	Booktitle = {Advances in Neural Information Processing Systems 18},
	Title = {Describing Visual Scenes Using Transformed {D}irichlet Processes},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBALi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzL29wdGltaXphdGlvbi1ieS1zaW11bGF0ZWQtYW5uZWFsaW5nLmJpYk8RAeYAAAAAAeYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM3IwOpIKwAAAAXAlh9vcHRpbWl6YXRpb24tYnktc2ltIzg2MTMyNEYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIYTJP1UJ/bAAAAAAAAAAAAAUAAgAACSAAAAAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAAQAAgAAM3I+SoAAAARAAgAANVCt6wAAAABAAwABcCWAAXAkwACEikAAgBMTWFjaW50b3NoIEhEOlVzZXJzOgBqYWFuYWx0b3NhYXI6AERvd25sb2FkczoAb3B0aW1pemF0aW9uLWJ5LXNpbSM4NjEzMjRGLmJpYgAOAFAAJwBvAHAAdABpAG0AaQB6AGEAdABpAG8AbgAtAGIAeQAtAHMAaQBtAHUAbABhAHQAZQBkAC0AYQBuAG4AZQBhAGwAaQBuAGcALgBiAGkAYgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAERVc2Vycy9qYWFuYWx0b3NhYXIvRG93bmxvYWRzL29wdGltaXphdGlvbi1ieS1zaW11bGF0ZWQtYW5uZWFsaW5nLmJpYgATAAEvAAAVAAIAE///AAAACAANABoAJABnAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAlE=}}

@article{Woolrich:2004,
	Author = {Woolrich, M. and Behrens, T. and Beckmann, C. and Jenkinson, M. and Smith, S.},
	Journal = {Neuroimage},
	Pages = {1732--1747},
	Title = {Multilevel Linear Modeling for F{MRI} Group Analysis Using Bayesian Inference},
	Volume = {21},
	Year = {2004}}

@article{Liu:1998,
	Author = {Liu, C. and Rubin, D. and Wu, Y.},
	Journal = {Biometrika},
	Number = {4},
	Pages = {755--770},
	Title = {Parameter Expansion to Accelerate {EM}: The {PX-EM} Algorithm},
	Volume = {85},
	Year = {1998}}

@unpublished{Hoff:2006,
	Author = {Hoff, P.},
	Month = {January},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Year = {2006}}

@article{Ando:2005,
	Author = {Ando, R. and Zhang, T.},
	Journal = {Journal of Machine Learning Research},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Year = {2005}}

@article{Haxby:2001,
	Author = {Haxby, J. and Gobbini, M. and Furey, M. and Ishai, A. and Schouten, J. and Pietrini, P.},
	Journal = {Science},
	Title = {Distributed and Overlapping Representations of Faces and Objects in Ventral Temporal Cortex},
	Volume = {293},
	Year = {2001}}

@article{Polyn:2005,
	Author = {Polyn, S. and Natu, V. and Cohen, J. and Norman, K.},
	Journal = {Science},
	Pages = {1963--1966},
	Title = {Category-Specific Cortical Activity Precedes Retrieval During Memory (supplementary material) Search},
	Volume = {310},
	Year = {2005}}

@article{Polyn:2005a,
	Author = {Polyn, S. and Natu, V. and Cohen, J. and Norman, K.},
	Journal = {Science},
	Pages = {1963--1966},
	Title = {Category-Specific Cortical Activity Precedes Retrieval During Memory Search},
	Volume = {310},
	Year = {2005}}

@article{Ishai:1999,
	Author = {Ishai, A. and Ungerleider, L. and Martin, A. and Schouten, J. and Haxby, J.},
	Journal = {Proceedings of the National Academy of Science},
	Number = {16},
	Pages = {9379--9384},
	Title = {Distributed Representation of Objects in the Human Ventral Visual Pathway},
	Volume = {96},
	Year = {1999}}

@article{Friston:2005,
	Author = {Friston, K.},
	Journal = {Annual Review of Psychology},
	Pages = {57--87},
	Title = {Models of Brain Function in Neuroimaging},
	Volume = {56},
	Year = {2005}}

@article{Fine:1998,
	Author = {Fine, S. and Singer, Y. and Tishby, N.},
	Journal = {Machine Learning},
	Pages = {41--62},
	Title = {The Hierarchical Hidden {M}arkov Model: Analysis and Applications},
	Volume = {32},
	Year = {1998}}

@inproceedings{Lawrence:2006,
	Author = {Lawrence, J. and Ben-Artzi, A. and DeCoro, C. and Matusik, W. and Hanspeter, P. and Ramamoorthi, R. and Rusinkiewicz, S.},
	Booktitle = {SIGRAPH, 2006},
	Title = {Inverse Shade Trees for Non-Parametric Material Representation and Editing},
	Year = {2006}}

@article{Wolpert:1998,
	Author = {Wolpert, R. and Ickstadt, K.},
	Journal = {Biometrika},
	Number = {2},
	Pages = {251--267},
	Title = {Poisson/Gamma Random Field Models for Spatial Statistics},
	Volume = {85},
	Year = {1998}}

@article{Schutze:1998,
	Author = {Sch\"{u}tze, Hinrich},
	Journal = {Computational Linguistics},
	Number = {1},
	Pages = {97--124},
	Title = {Automatic Word Sense Disambiguation},
	Volume = {24},
	Year = {1998}}

@article{Jedynak:2005,
	Author = {Jedynak, B. and Khudanpur, S.},
	Journal = {Neural Computation},
	Pages = {1--23},
	Title = {Maximum likelihood set for estimating a probability mass function},
	Volume = {17},
	Year = {2005}}

@techreport{Storey:2005,
	Author = {Storey, J.},
	Institution = {University of Washington Biostatistics},
	Number = {259},
	Title = {The optimal discovery procedure: A new approach to simultaneous significance testing},
	Year = {2005}}

@incollection{Steyvers:2006,
	Author = {Steyvers, M. and Griffiths, T.},
	Booktitle = {Latent Semantic Analysis: A Road to Meaning},
	Editor = {Landauer, T. and McNamara, D. and Dennis, S. and Kintsch, W.},
	Publisher = {Laurence Erlbaum},
	Title = {Probabilistic topic models},
	Year = {2006}}

@article{Griffiths:2004a,
	Author = {Griffiths, T. and Steyvers, M.},
	Journal = {Proceedings of the National Academy of Sciences (PNAS)},
	Title = {Finding scientific topics},
	Year = {2004}}

@article{Eisner:2002,
	Author = {Eisner, J.},
	Journal = {Cognitive Science},
	Number = {3},
	Title = {Discovering syntactic deep structure via {B}ayesian statistics},
	Volume = {26},
	Year = {2002}}

@article{Dykstra:1983,
	Author = {Dykstra, R.},
	Journal = {Journal of the American Statistical Association},
	Month = {December},
	Number = {384},
	Pages = {837--842},
	Title = {An algorithm for restricted least squares regression},
	Volume = {78},
	Year = {1983}}

@inproceedings{Skounakis:2003,
	Author = {Skounakis, M. and Craven, M. and Soumya, R.},
	Booktitle = {Proceedings of the 18th International Conference on Artificial Intelligence},
	Publisher = {Morgan Kaufmann publishers},
	Title = {Hierarchical hidden {M}arkov models for information extraction},
	Year = {2003}}

@incollection{Buntine:2006,
	Author = {Buntine, W. and Jakulin, A.},
	Booktitle = {Subspace, Latent Structure and Feature Selection},
	Publisher = {Springer},
	Title = {Discrete component analysis},
	Year = {2006}}

@unpublished{Boyd:2003,
	Author = {Boyd, S. and Dattorro, J.},
	Title = {Alternating projections},
	Year = {2003}}

@article{Gilks:1992,
	Author = {Gilks, W. and Spiegelhalter, D.},
	Journal = {The Statistician},
	Pages = {169--177},
	Title = {A language and program for complex {B}ayesian modelling},
	Volume = {3},
	Year = {1992}}

@article{Smith:1993,
	Author = {Smith, A. and Roberts, G.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {1},
	Pages = {3--23},
	Title = {Bayesian computation via the {G}ibbs sampler and related {M}arkov chain {M}onte {C}arlo methods},
	Volume = {55},
	Year = {1993}}

@article{Mau:1997,
	Author = {Mau, B. and Newton, M.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {1},
	Pages = {122--131},
	Title = {Phylogentic Inference for Binary Data on Dendrograms using Markov Chain Monte Carlo},
	Volume = {6},
	Year = {1997}}

@article{Mau:1999,
	Author = {Mau, B. and Newton, M. and Larget, B.},
	Journal = {Biometrics},
	Pages = {1--12},
	Title = {Bayesian phylogenies via {M}arkov {C}hain {M}onte {C}arlo methods},
	Volume = {55},
	Year = {1999}}

@article{Thomas:2000,
	Author = {Thomas, A. and Gutin, A. and Abkevich, V. and Bansal, A.},
	Journal = {Statistics and Computing},
	Pages = {259--269},
	Title = {Multilocus linkage analysis by blocked {G}ibbs sampling},
	Volume = {10},
	Year = {2000}}

@article{Kalman:1960,
	Author = {Kalman, R.},
	Journal = {Transaction of the AMSE: Journal of Basic Engineering},
	Pages = {35--45},
	Title = {A New Approach to Linear Filtering and Prediction Problems A New Approach to Linear Filtering and Prediction Problems,''},
	Volume = {82},
	Year = {1960}}

@manual{R-Development-Core-Team:2005,
	Address = {Vienna, Austria},
	Author = {{R Development Core Team}},
	Organization = {R Foundation for Statistical Computing},
	Title = {R: A Language and Environment for Statistical Computing},
	Year = 2005}

@article{Fei-Fei:2005,
	Author = {Fei-Fei, L. and Perona, P.},
	Journal = {IEEE Computer Vision and Pattern Recognition},
	Pages = {524--531},
	Title = {A {B}ayesian Hierarchical Model for Learning Natural Scene Categories},
	Year = {2005}}

@article{Anderson-Sprecher:1991,
	Author = {Anderson-Sprecher, R. and Jedolter, J.},
	Journal = {Journal of the American Statistical Association},
	Number = {415},
	Pages = {596--602},
	Title = {State-space analysis of wildlife telemetry data},
	Volume = {86},
	Year = {1991}}

@article{Anderson-Sprecher:1994,
	Author = {Anderson-Sprecher, R.},
	Journal = {Biometrics},
	Number = {2},
	Pages = {406--416},
	Title = {Robust estimates of wildlife location using telemetry data},
	Volume = {50},
	Year = {1994}}

@unpublished{Gelman:2005,
	Author = {Gelman, A. and Stern, H.},
	Month = {December},
	Title = {The difference between "significant" and "not significant" is not itself statistically significant},
	Year = {2005}}

@article{Roberts:2004,
	Author = {Roberts, S.},
	Journal = {Behavioral and Brain Sciences},
	Number = {2},
	Pages = {227--288},
	Title = {Self-experimentation as a source of new ideas: {T}en examples about sleep, mood, health, and weight},
	Volume = {27},
	Year = {2004}}

@article{Lenth:1981,
	Author = {Lenth, R.},
	Journal = {Technometrics},
	Number = {2},
	Pages = {149--154},
	Title = {On finding the source of a signal},
	Volume = {23},
	Year = {1981}}

@unpublished{Blei:2006,
	Author = {Blei, D. and Lafferty, J. and Genovese, C. and Wasserman, L.},
	Note = {(in progress)},
	Title = {Turbo topics},
	Year = {2006}}

@inproceedings{Blei:1999,
	Author = {Blei, D. and Kaelbling, L.},
	Booktitle = {IJCAI Workshop on Adaptive Spatial Representations of Dynamic Environments},
	Title = {Shortest paths in a dynamic uncertain domain},
	Year = {1999}}

@inproceedings{Blei:2006b,
	Author = {Blei, D. and Lafferty, J.},
	Booktitle = {Advances in Neural Information Processing Systems 18 ({NIPS}) 18},
	Pages = {147--154},
	Publisher = {MIT Press},
	Title = {Correlated topic models},
	Year = {2006}}

@inproceedings{Welling:2004,
	Author = {Welling, M. and Rosen-Zvi, M. and Hinton, Geoffrey E.},
	Booktitle = {Neural Information Processing Systems ({N}{I}{P}{S}) 17},
	Title = {Exponential family harmoniums with an application to information retrieval},
	Year = {2004}}

@inproceedings{Rosen-Zvi:2005,
	Author = {Rosen-Zvi, M. and Jordan, M. and Yuille, A},
	Booktitle = {Uncertainty in Artificial Intelligence, Proceedings of the Twenty-First Conference},
	Title = {The {DLR} hierarchy of approximate inference},
	Year = {2005}}

@article{Wainwright:2005b,
	Author = {Wainwright, M. and Jaakkola, T. and Willsky, A.},
	Journal = {IEEE Transactions on Information Theory},
	Title = {{MAP} estimation via agreement on (hyper)trees: {M}essage-passing and linear-programming approaches},
	Year = {2005}}

@article{Wainwright:2005a,
	Author = {Wainwright, M. and Jaakkola, T. and Willsky, A.},
	Journal = {IEEE Transactions on Information Theory},
	Pages = {2313--2335},
	Title = {A new class of upper bounds on the log partition function},
	Volume = {51},
	Year = {2005}}

@article{Winn:2005,
	Author = {Winn, J. and Bishop, C.},
	Journal = {Journal of Machine Learning Research},
	Pages = {661--694},
	Title = {Variational message passing},
	Volume = {6},
	Year = {2005}}

@techreport{Shahbaba:2005,
	Author = {Shahbaba, B. and Neal, R.},
	Institution = {Department of Statistics, University of Toronto},
	Number = {0510},
	Title = {Improving classification when a class hierarchy is available using a hierarchy-based prior},
	Year = {2005}}

@techreport{Yedida:2004,
	Author = {Yedida, J. and Freeman, W. and Weiss, Y.},
	Institution = {MERL},
	Number = {TR-2002-40},
	Title = {Constructing free energy approximations and generalized belief propagation algorithms},
	Year = {2004}}

@inproceedings{Welling:2005,
	Author = {Welling, M. and Minka, T. and Teh, Y.},
	Booktitle = {21st Conference on Uncertainty in Artificial Intelligence},
	Title = {Structured region graphs: {M}orphing {EP} into {GBP}},
	Year = {2005}}

@techreport{Minka:2005,
	Author = {Minka, T.},
	Institution = {Microsoft Research},
	Number = {TR-2005-173},
	Title = {Divergence measures and message passing},
	Year = {2005}}

@phdthesis{Minka:2001b,
	Author = {Minka, T.},
	Month = {January},
	School = {Massachusetts Institute of Technology},
	Title = {A family of algorithms for approximate {B}ayesian inference},
	Year = {2001}}

@techreport{Minka:2004,
	Author = {Minka, T.},
	Institution = {Microsoft Research},
	Number = {MSR-TR-2004-149},
	Title = {Power {EP}},
	Year = {2004}}

@unpublished{Minka:2001a,
	Author = {Minka, T.},
	Month = {August},
	Title = {The {EP} energy function and minimization schemes},
	Year = {2001}}

@article{McAuliffe:2004a,
	Author = {McAuliffe, J. and Pachter, L. and Jordan, M.},
	Journal = {Bioinformatics},
	Number = {12},
	Pages = {1850--1860},
	Title = {Multiple-sequence functional annotation and the generalized hidden {M}arkov phylogeny},
	Volume = {20},
	Year = {2004}}

@article{Andrieu:2003,
	Author = {Andrieu, C. and de Freitas, N. and Doucet, A. and Jordan, M.},
	Journal = {Machine Learning},
	Pages = {5--43},
	Title = {An introduction to {MCMC} for machine learning},
	Volume = {50},
	Year = {2003}}

@article{Gelman:2004,
	Author = {Gelman, A.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {4},
	Pages = {755--779},
	Title = {Exploratory data analysis for complex models},
	Volume = {13},
	Year = {2004}}

@article{Bates:2004,
	Author = {Bates, D.},
	Title = {Sparse matrix representations of linear mixed models},
	Year = {2004}}

@article{Draper:2005a,
	Author = {Draper, D. and Krnjajic, M.},
	Title = {Bayesian model specification},
	Year = {2005}}

@article{Draper:2005,
	Author = {Draper, D.},
	Title = {On the relationship between model uncertainty and inferential/predictive uncertainty},
	Year = {2005}}

@article{Browne:2005,
	Author = {Browne, W. and Draper, D.},
	Title = {A comparison of {B}ayesian and likelihood based methods for fitting multilevel models},
	Year = {2005}}

@article{Jordan:2004,
	Author = {Jordan, M.},
	Journal = {Statistical Science},
	Number = {1},
	Pages = {140--155},
	Title = {Graphical models},
	Volume = {19},
	Year = {2004}}

@inproceedings{Iwata:2004,
	Author = {Iwata, T. and Saito, K. and Ueda, N.},
	Booktitle = {Neural Information Processing Systems ({N}{I}{P}{S}) 17},
	Title = {Parametric embedding for class visualization},
	Year = {2004}}

@inproceedings{Ueda:2004,
	Author = {Ueda, N. and Saito, K.},
	Booktitle = {Advances in Neural Information Processing Systems 17},
	Title = {Parametric Mixture Models for Multi-Labeled Text},
	Year = {2004}}

@book{West:1997,
	Author = {West, M. and Harrison, J.},
	Publisher = {Springer},
	Title = {Bayesian Forecasting and Dynamic Models},
	Year = {1997}}

@incollection{Blei:2003c,
	Author = {Blei, D. and Ng, A. and Jordan, M.},
	Booktitle = {Bayesian Statistics 7},
	Editor = {Bernardo, J. and Berger, J. and Dawid, A. and Heckerman, D. and Smith, A. and West, M.},
	Pages = {25--44},
	Publisher = {Oxford University Press},
	Title = {Hierarchical {B}ayesian models for applications in information retrieval},
	Volume = {7},
	Year = {2003}}

@article{Erosheva:2004,
	Author = {Erosheva, E. and Fienberg, S. and Lafferty, J.},
	Journal = {Proceedings of the National Academy of Science},
	Number = {22},
	Pages = {11885--11892},
	Title = {Mixed-membership models of scientific publications},
	Volume = {97},
	Year = {2004}}

@article{Hoff:2003a,
	Author = {Hoff, P.},
	Title = {Bilinear Mixed Effects Models for Dyadic Data},
	Year = {2003}}

@inproceedings{MacEachern:1999,
	Author = {MacEachern, S.},
	Booktitle = {ASA Proceedings of the Section on Bayesian Statistical Science},
	Title = {Dependent Nonparametric Processes},
	Year = {1999}}

@article{Nabieva:2005,
	Author = {Nabieva, E. and Kam, J. and Agarwal, A. and Chazelle, B. and Singh, M.},
	Journal = {Bioinformatics},
	Number = {Suppl. 1},
	Pages = {i302--i310},
	Title = {Whole-proteome prediction of protein function via graph-theoretic analysis of interaction maps},
	Volume = {21},
	Year = {2005}}

@article{Hoff:2004,
	Author = {Hoff, P. and Ward, M.},
	Journal = {Political Analysis},
	Number = {2},
	Pages = {160--175},
	Title = {Modeling dependencies in international relations networks},
	Volume = {12},
	Year = {2004}}

@inproceedings{Kannan:2005,
	Author = {Kannan, R. and Salmasian, H. and Vempala, S.},
	Booktitle = {COLT},
	Title = {The spectral method for general mixture models},
	Year = {2005}}

@article{Dasgupta:1999,
	Author = {Dasgupta, S.},
	Title = {Learning mixtures of {G}aussians},
	Year = {1999}}

@article{Chib:1995,
	Author = {Chib, S.},
	Journal = {Journal of the American Statistical Association},
	Number = {432},
	Pages = {1313--1321},
	Title = {Marginal likelihood from the {G}ibbs output},
	Volume = {90},
	Year = {1995}}

@article{Postman:1986,
	Author = {Postman, M. and Huchra, J. and Geller, M.},
	Journal = {The Astronomical journal},
	Pages = {1238--1247},
	Title = {Probes of large-scale structure in the {C}orona {B}orealis region},
	Volume = {92},
	Year = {1986}}

@article{Stephens:2000a,
	Author = {Stephens, M.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {4},
	Pages = {795--809},
	Title = {Dealing with label switching in mixture models},
	Volume = {62},
	Year = {2000}}

@article{Stephens:2000,
	Author = {Stephens, M.},
	Journal = {The Annals of Statistics},
	Number = {1},
	Pages = {40--74},
	Title = {Bayesian analysis of mixture models with an unknown number of components---an alternative to reversible jump methods},
	Volume = {28},
	Year = {2000}}

@article{Hjort:1990,
	Author = {Hjort, N.},
	Journal = {The Annals of Statistics},
	Number = {3},
	Title = {Nonparametric Bayes Estimators Based on Beta Processes in Models for Life History Data},
	Volume = {18},
	Year = {1990}}

@article{Izenman:1988,
	Author = {Izenman, A. and Sommer, C.},
	Journal = {Journal of the American Statistical Association},
	Number = {404},
	Pages = {941--953},
	Title = {Philatelic mixtures and multimodal densities},
	Volume = {83},
	Year = {1988}}

@article{Crawford:1994,
	Author = {Crawford, S.},
	Journal = {Journal of the American Statistical Association},
	Number = {425},
	Pages = {259--267},
	Title = {An application of the {L}aplace method to finite mitxure distributions},
	Volume = {89},
	Year = {1994}}

@article{Basford:1997,
	Author = {Basford, K. and McLachlan, G. and York, M.},
	Journal = {Journal of Applied Statistics},
	Number = {2},
	Pages = {169--180},
	Title = {Modelling the distribution of stamp paper thickness via finite normal mixtures: {T}he 1872 {H}idalgo stamp issue of {M}exico revisited},
	Volume = {24},
	Year = {1997}}

@article{Carlin:1995,
	Author = {Carlin, B. and Chib, S.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {3},
	Pages = {473--484},
	Title = {Bayesian model choice via {M}arkov chain {M}onte {C}arlo methods},
	Volume = {57},
	Year = {1995}}

@article{Ishwaran:2002b,
	Author = {Ishwaran, J. and James, L.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {3},
	Pages = {1--26},
	Title = {Approximate {D}irichlet process computing in finite normal mixtures: {S}moothing and prior information},
	Volume = {11},
	Year = {2002}}

@article{Roeder:1992,
	Author = {Roeder, K.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {929--943},
	Title = {Semiparametric estimation of normal mixture densities},
	Volume = {20},
	Year = {1992}}

@article{Muller:1998,
	Author = {Muller, P. and Vidakovic, B.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {4},
	Pages = {456--468},
	Title = {Bayesian inference with wavelets: {D}ensity estimation},
	Volume = {7},
	Year = {1998}}

@article{Richardson:1997,
	Author = {Richardson, S. and Green, P.},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Number = {4},
	Pages = {731--792},
	Title = {On {B}ayesian analysis of mixtures with unknown number of components},
	Volume = {59},
	Year = {1997}}

@techreport{Newman:2003a,
	Author = {Newman, M.},
	Title = {Mixing patterns in networks},
	Year = {2003}}

@incollection{MacEachern:1998a,
	Author = {MacEachern, S.},
	Booktitle = {Practical Nonparametric and Semiparametric Bayesian Statistics},
	Editor = {Dey, D. and Muller, P. and Sinha, D.},
	Pages = {23--44},
	Publisher = {Springer},
	Title = {Computational Methods for Mixture of {D}irichlet Process Models},
	Year = {1998}}

@article{Jain:2004,
	Author = {Jain, S. and Neal, R.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {1},
	Pages = {158--182},
	Title = {A split-merge {M}arkov chain {M}onte {C}arlo procedure for the {D}irichlet process mixture model},
	Volume = {13},
	Year = {2004}}

@techreport{Meila:2002,
	Author = {Meila, M.},
	Institution = {Statistics Department, University of Washington},
	Number = {418},
	Title = {Comparing Clusterings},
	Year = {2002}}

@article{Ishwaran:2000,
	Author = {Ishwaran, J. and Zarepour, M.},
	Journal = {Biometrika},
	Number = {2},
	Pages = {371--390},
	Title = {Markov Chain Monte {C}arlo in approximate {D}irichlet and beta two-parameter process hierarchical models},
	Volume = {87},
	Year = {2000}}

@article{MacEachern:1994,
	Author = {MacEachern, S.},
	Journal = {Communications in Statistics B},
	Pages = {727--741},
	Title = {Estimating Normal Means with a Conjugate Style Dirichlet Process Prior},
	Volume = {23},
	Year = {1994}}

@article{Barabasi:1999a,
	Author = {Barabasi, A. and Albert, R. and Jeong, H.},
	Title = {Mean-field theory for scale free random networks},
	Year = {1999}}

@article{Ishwaran:2002a,
	Author = {Ishwaran, H. and Zarepour, M.},
	Journal = {Statistica Sinica},
	Pages = {941--963},
	Title = {Dirichlet Prior Sieves in Finite Normal Mixtures},
	Volume = {12},
	Year = {2002}}

@article{Bensmail:1997,
	Author = {Bensmail, H. and Gilles, C. and Raftery, A. and Robert, C.},
	Journal = {Statistics and Computing},
	Pages = {1--10},
	Title = {Inference in model-based cluster analysis},
	Volume = {7},
	Year = {1997}}

@techreport{Hoff:2003,
	Author = {Hoff, P.},
	Institution = {Center for Statistics and the Social Sciences, University of Washington},
	Number = {28},
	Title = {Random Effects Models for Network Data},
	Type = {Working Paper},
	Year = {2003}}

@article{Barabasi:1999,
	Author = {Barabasi, A. and Reka, A.},
	Journal = {Science},
	Number = {5439},
	Pages = {509--512},
	Title = {Emergence of Scaling in Random Networks},
	Volume = {286},
	Year = {1999}}

@article{Albert:2002,
	Author = {Albert, R. and Barabasi, A.},
	Journal = {Reviews of Modern Physics},
	Number = {1},
	Pages = {47--97},
	Title = {Statistical Mechanics of Complex Networks},
	Volume = {74},
	Year = {2002}}

@article{Hoff:2002,
	Author = {Hoff, P. and Raftery, A. and Handcock, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {460},
	Pages = {1090--1098},
	Title = {Latent space approaches to social network analysis},
	Volume = {97},
	Year = {2002}}

@article{Strauss:1990,
	Author = {Strauss, D. and Ikeda, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {409},
	Title = {Pseudolikelihood Estimation for Social Networks},
	Volume = {85},
	Year = {1990}}

@article{Besag:1975,
	Author = {Besag, J.},
	Journal = {The Statistician},
	Number = {3},
	Pages = {179--195},
	Title = {Statistical Analysis of Non-Lattice Data},
	Volume = {24},
	Year = {1975}}

@article{Efron:1996,
	Author = {Efron, B.},
	Journal = {Journal of the American Statistical Association},
	Number = {434},
	Pages = {538--550},
	Title = {Empirical {B}ayes methods for Combining Likelihoods},
	Volume = {91},
	Year = {1996}}

@article{Nowicki:2001,
	Author = {Nowicki, K. and Snijders, T.},
	Journal = {Journal of the American Statistical Association},
	Number = {455},
	Pages = {1077--1087},
	Title = {Estimation and Prediction for Stochastic Blockstructures},
	Volume = {96},
	Year = {2001}}

@article{Wang:1987,
	Author = {Wang, Y. and Wong, G.},
	Journal = {Journal of the American Statistical Association},
	Number = {397},
	Pages = {8--19},
	Title = {Stochastic Block Models for Directed Graphs},
	Volume = {82},
	Year = {1987}}

@article{Besag:1974,
	Author = {Besag, J.},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
	Number = {2},
	Pages = {192--236},
	Title = {Spatial Interaction and the Statistical Analysis of Lattice Systems},
	Volume = {36},
	Year = {1974}}

@article{Falish:2003,
	Author = {Falish, D. and Stephens, M. and Pritchard, J.},
	Journal = {Genetics},
	Month = {August},
	Pages = {1567--1587},
	Title = {Inference of Population Structure Using Multilocus Genotype Data: Linked Loci and Correlated Allele Frequencies},
	Volume = {164},
	Year = {2003}}

@article{Holland:1981,
	Author = {Holland, P. and Leinhardt, S.},
	Journal = {Journal of the American Statistical Association},
	Number = {373},
	Pages = {33--50},
	Title = {An Exponential Family of Probability Distributions for Directed Graphs},
	Volume = {76},
	Year = {1981}}

@inproceedings{Taskar:2001,
	Author = {Taskar, B. and Segal, E. and Koller, D.},
	Booktitle = {Proceedings of the 17th International Joint Conference on Artificial Intelligence},
	Pages = {870--876},
	Title = {Probabilistic Classification and Clustering in Relational Data},
	Year = {2001}}

@book{McLachlan:2000,
	Author = {McLachlan, G. and Peel, D.},
	Publisher = {Wiley-Interscience},
	Title = {Finite mixture models},
	Year = {2000}}

@inproceedings{Kurland:2004,
	Author = {Kurland, O. and Lee, L.},
	Booktitle = {SIGIR},
	Title = {Corpus Structure, Language Models, and Ad Hoc Information Retrieval},
	Year = {2004}}

@unpublished{Blei:2003d,
	Author = {Blei, D.},
	Title = {Expectation Propagation Explanation},
	Year = {2003}}

@article{McCallum:2007,
	Author = {McCallum, A. and Wang, X. and Corrada-Emmanuel, A.},
	Journal = {Journal of Artificial Intelligence Research},
	Pages = {249--272},
	Title = {Topic and Role Discovery in Social Networks},
	Volume = {30},
	Year = {2007}}

@manual{Gungman:,
	Author = {Gungman, J. and Gough, B.},
	Title = {{GSL}: {GNU} Scientific Library}}

@article{Saul:1996,
	Author = {Saul, L. and Jaakkola, T. and Jordan, M.},
	Journal = {Journal of Artificial Intelligence Research},
	Pages = {61--76},
	Title = {Mean Field Theory for Sigmoid Belief Networks},
	Volume = {4},
	Year = {1996}}

@article{Saul:1996b,
	Author = {Saul, Lawrence K and Jordan, Michael I},
	Journal = {Advances in neural information processing systems},
	Pages = {486--492},
	Publisher = {MORGAN KAUFMANN PUBLISHERS},
	Title = {Exploiting tractable substructures in intractable networks},
	Year = {1996}}

@inproceedings{Rosen-Zvi:2004,
	Author = {Rosen-Zvi, M. and Griffiths, T. and Steyvers, M. and Smith, P.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {The Author-Topic Model for authors and Documents},
	Year = {2004}}

@incollection{Wainwright:2005,
	Author = {Wainwright, M. and Jordan, M.},
	Booktitle = {New Directions in Statistical Signal Processing},
	Chapter = {11},
	Publisher = {MIT Press},
	Title = {A Variational Principle for Graphical Models},
	Year = {2005}}

@article{Daniels:1999,
	Author = {Daniels, M. and Kass, R.},
	Journal = {Journal of the American Statistical Association},
	Number = {448},
	Pages = {1254--1263},
	Title = {Nonconjugate {B}ayesian Estimation of Covariance Matrices and its use in Hierarchical Models},
	Volume = {94},
	Year = {1999}}

@article{Efron:1973,
	Author = {Efron, B. and Morris, C.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Number = {3},
	Pages = {379--421},
	Title = {Combining Possibly Related Estimation Problems},
	Volume = {35},
	Year = {1973}}

@techreport{Sivic:2005,
	Author = {Sivic, J. and Russell, B. and Efros, A. and Zisserman, A. and Freeman, W.},
	Institution = {CSAIL, Massachusetts Institute of Technology},
	Title = {Discovering Object Categories in Image Collections},
	Year = {2005}}

@unpublished{Abney:2004,
	Author = {Abney, S.},
	Title = {Understanding the {Y}arowsky Algorithm},
	Year = {2004}}

@inproceedings{Taskar:2004,
	Author = {Taskar, B. and Klein, D. and Collins, M. and Koller, D. and Manning, C.},
	Booktitle = {Empirical Methods in Natural Language Processing},
	Title = {Max-Margin Parsing},
	Year = {2004}}

@article{Bejerano:2001,
	Author = {Bejerano, G. and Yona, G.},
	Journal = {Bioinformatics},
	Number = {1},
	Pages = {23--43},
	Title = {Variations on Probabilistic Suffix Trees: Statistical Modeling and Prediction of Protein Families},
	Volume = {17},
	Year = {2001}}

@article{Aitchison:1985a,
	Author = {Aitchison, J.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Number = {1},
	Pages = {136--146},
	Title = {A General Class of Distributions on the Simplex},
	Volume = {47},
	Year = {1985}}

@article{Blei:2005,
	Author = {Blei, D. and Jordan, M.},
	Journal = {Journal of Bayesian Analysis},
	Number = {1},
	Pages = {121--144},
	Title = {Variational inference for {D}irichlet process mixtures},
	Volume = {1},
	Year = {2005}}

@article{Aitchison:1980,
	Author = {Aitchison, J. and Shen, S.},
	Journal = {Biometrika},
	Month = {August},
	Number = {2},
	Pages = {261--272},
	Title = {Logistic Normal Distributions: Some Properties and Uses},
	Volume = {67},
	Year = {1980}}

@article{Aitchison:1989,
	Author = {Aitchison, J. and Ho, C.},
	Journal = {Biometrika},
	Month = {December},
	Number = {4},
	Pages = {643--653},
	Title = {The Multivariate Poisson-Log Normal Distribution},
	Volume = {76},
	Year = {1989}}

@book{Boyd:2004,
	Author = {Boyd, S. and Vandenberghe, L.},
	Publisher = {Cambridge University Press},
	Title = {Convex Optimization},
	Year = {2004}}

@unpublished{Roweis:1999a,
	Author = {Roweis, S.},
	Title = {Matrix Identities},
	Year = {1999}}

@unpublished{Blum:,
	Author = {Blum, A.},
	Title = {On-line Algorithms in Machine Learning}}

@article{Kubokawa:1999,
	Author = {Kubokawa, T. and Srivastava, M.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {600--609},
	Title = {Robust Improvement in Estimation of a Covariance Matrix in an Elliptically Contoured Distribution},
	Volume = {27},
	Year = {1999}}

@techreport{Vanderbei:1997,
	Author = {Vanderbei, R. and Shanno, D.},
	Institution = {Statistics and Operations Research, Princeton University},
	Number = {SOR-9-21},
	Title = {An Interior-Point Algorithm for Nonconvex Nonlinear Programming},
	Year = {1997}}

@article{Daniels:2001,
	Author = {Daniels, M. and Kass, R.},
	Journal = {Biometrics},
	Month = {December},
	Pages = {1173--1184},
	Title = {Shrinkage Estimators for Covariance Matrices},
	Volume = {57},
	Year = {2001}}

@article{Banfield:1993,
	Author = {Banfield, J. and Raftery, A.},
	Journal = {Biometrics},
	Month = {September},
	Pages = {803--821},
	Title = {Model-Based Gaussian and Non-Gaussian Clustering},
	Volume = {49},
	Year = {1993}}

@book{Abramowitz:1970,
	Address = {New York},
	Author = {Abramowitz, M. and Stegun, I.},
	Publisher = {Dover},
	Title = {Handbook of Mathematical Functions},
	Year = {1970}}

@incollection{Aldous:1985,
	Address = {Berlin},
	Author = {Aldous, D.},
	Booktitle = {{\'E}cole d'{\'e}t{\'e} de probabilit{\'e}s de Saint-Flour, XIII---1983},
	Pages = {1--198},
	Publisher = {Springer},
	Title = {Exchangeability and related topics},
	Year = {1985}}

@article{Antoniak:1974,
	Author = {Antoniak, C.},
	Journal = {The Annals of Statistics},
	Number = {6},
	Pages = {1152-1174},
	Title = {Mixtures of {D}irichlet processes with applications to {B}ayesian nonparametric problems},
	Volume = {2},
	Year = {1974}}

@unpublished{Shlens:2003,
	Author = {Shlens, J.},
	Title = {A Tutorial on Principal Component Analysis},
	Year = {2003}}

@inproceedings{Aslandogan:1997,
	Author = {Aslandogan, Y. and Thier, C. and Yu, C. and Zou, J. and Rishe, N.},
	Booktitle = {Proceedings of the 20th annual international ACM SIGIR Conference on Research and Development in Information Retrieval},
	Pages = {286--295},
	Publisher = {ACM Press},
	Title = {Using Semantic Contents and {W}ord{N}et in Image Retrieval},
	Year = {1997}}

@article{Aitchison:1982,
	Author = {Aitchison, J.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Number = {2},
	Pages = {139--177},
	Title = {The Statistical Analysis of Compositional Data},
	Volume = {44},
	Year = {1982}}

@inproceedings{Attias:2000,
	Author = {Attias, H.},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {A variational {B}ayesian framework for graphical models},
	Year = {2000}}

@book{Baeza-Yates:1999,
	Address = {New York},
	Author = {Baeza-Yates, R. and Ribeiro-Neto, B.},
	Publisher = {ACM Press},
	Title = {Modern Information Retrieval},
	Year = {1999}}

@article{Barnard:2003,
	Author = {Barnard, K. and Duygulu, P. and de Freitas, N. and Forsyth, D. and Blei, D. and Jordan, M.},
	Journal = {Journal of Machine Learning Research},
	Pages = {1107-1135},
	Title = {Matching Words and Pictures},
	Volume = {3},
	Year = {2003}}

@inproceedings{Duygulu:2002,
	Author = {Pinar Duygulu and Kobus Barnard and Jo{\~a}o F. G. de Freitas and David A. Forsyth},
	Booktitle = {ECCV},
	Title = {Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary},
	Year = {2002}}

@inproceedings{Beal:2002,
	Address = {Cambridge, MA},
	Author = {Beal, M. and Ghahramani, Z. and Rasmussen, C.},
	Booktitle = {Advances in Neural Information Processing Systems 14},
	Editor = {Dietterich, T. and Becker, S. and Ghahramani, Z.},
	Publisher = {MIT Press},
	Title = {The Infinite Hidden {M}arkov Model},
	Year = {2002}}

@phdthesis{Beal:2003,
	Author = {Beal, M.},
	School = {Gatsby Computational Neuroscience Unit, University College London},
	Title = {Variational algorithms for approximate {B}ayesian inference},
	Year = {2003}}

@book{Bernardo:1994,
	Address = {Chichester},
	Author = {Bernardo, J. and Smith, A.},
	Publisher = {John Wiley \& Sons Ltd.},
	Title = {{B}ayesian theory},
	Year = {1994}}

@book{Bertsekas:1999,
	Author = {Bertsekas, D.},
	Publisher = {Athena Scientific},
	Title = {Nonlinear Programming},
	Year = {1999}}

@article{Blackwell:1973,
	Author = {Blackwell, D. and MacQueen, J.},
	Journal = {The Annals of Statistics},
	Number = {2},
	Pages = {353-355},
	Title = {Ferguson distributions via {P}\'olya urn schemes},
	Volume = {1},
	Year = {1973}}

@inproceedings{Blei:2001,
	Author = {Blei, D. and Moreno, P.},
	Booktitle = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
	Pages = {343--348},
	Publisher = {ACM Press},
	Title = {Topic segmentation with an aspect hidden Markov model},
	Year = {2001}}

@techreport{Blei:2002b,
	Author = {Blei, D. and Jordan, M.},
	Institution = {U.C. Berkeley Computer Science Division},
	Number = {UCB//CSD-02-1202},
	Title = {Modeling annotated data},
	Year = {2002}}

@article{Blei:2003b,
	Author = {Blei, D. and Ng, A. and Jordan, M.},
	Journal = {Journal of Machine Learning Research},
	Month = {January},
	Pages = {993--1022},
	Title = {Latent {D}irichlet Allocation},
	Volume = {3},
	Year = {2003}}

@inproceedings{Blei:2003a,
	Author = {Blei, D. and Jordan, M.},
	Booktitle = {Proceedings of the 26th annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
	Pages = {127--134},
	Publisher = {ACM Press},
	Title = {Modeling annotated data},
	Year = {2003}}

@inproceedings{Blei:2003,
	Author = {Blei, D. and Griffiths, T. and Jordan, M. and Tenenbaum, J.},
	Booktitle = {NIPS},
	Title = {Hierarchical Topic Models and the Nested {C}hinese Restaurant Process},
	Year = {2003}}

@inproceedings{Brochu:2003,
	Author = {Brochu, E. and de Freitas, N.},
	Booktitle = {Advances in Neural Information Processing Systems 15},
	Title = {Name that Song: {A} probabilistic approach to querying on music and text},
	Year = {2003}}

@book{Brown:1986,
	Address = {Hayward, CA},
	Author = {Brown, L.},
	Publisher = {Institute of Mathematical Statistics},
	Title = {Fundamentals of Statistical Exponential Families},
	Year = {1986}}

@inproceedings{Buntine:2004,
	Author = {Buntine, W. and Jakulin, A.},
	Booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence},
	Pages = {59--66},
	Publisher = {AUAI Press},
	Title = {Applying Discrete {PCA} in Data Analysis},
	Year = {2004}}

@inproceedings{Cohn:2001,
	Author = {Cohn, D. and Hofmann, T.},
	Booktitle = {Advances in Neural Information Processing Systems 13},
	Title = {The Missing Link---{A} Probabilistic Model of Document Content and Hypertext Connectivity},
	Year = {2001}}

@article{Connor:1969,
	Author = {Connor, R. and Mosimann, J.},
	Journal = {Journal of the American Statistical Association},
	Number = {325},
	Pages = {194--206},
	Title = {Concepts of Independence for Proportions with a Generalization of the {D}irichlet Distribution},
	Volume = {64},
	Year = {1969}}

@book{Finetti:1990,
	Address = {Chichester},
	Author = {de Finetti, B.},
	Publisher = {John Wiley \& Sons Ltd.},
	Title = {Theory of probability. {V}ol.\ 1-2},
	Year = {1990}}

@article{Deerwester:1990,
	Author = {Deerwester, S. and Dumais, S. and Landauer, T. and Furnas, G. and Harshman, R.},
	Journal = {Journal of the American Society of Information Science},
	Number = {6},
	Pages = {391-407},
	Title = {Indexing by Latent Semantic Analysis},
	Volume = {41},
	Year = {1990}}

@article{Dempster:1977,
	Author = {Dempster, A. and Laird, N. and Rubin, D.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Pages = {1--38},
	Title = {Maximum likelihood from incomplete data via the {EM} algorithm},
	Volume = {39},
	Year = {1977}}

@incollection{Diaconis:1988,
	Address = {New York},
	Author = {Diaconis, P.},
	Booktitle = {Bayesian statistics, 3 (Valencia, 1987)},
	Pages = {111--125},
	Publisher = {Oxford Univ. Press},
	Title = {Recent progress on de {F}inetti's notions of exchangeability},
	Year = {1988}}

@article{Dickey:1983,
	Author = {Dickey, J.},
	Journal = {Journal of the American Statistical Association},
	Pages = {628-637},
	Title = {Multiple Hypergeometric Functions: Probabilistic Interpretations and Statistical Uses},
	Volume = {78},
	Year = {1983}}

@article{Dickey:1987,
	Author = {Dickey, J. and Jiang, J. and Kadane, J.},
	Journal = {Journal of the American Statistical Association},
	Pages = {773-781},
	Title = {Bayesian Methods for Censored Categorical Data},
	Volume = {82},
	Year = {1987}}

@article{Diebolt:1994,
	Author = {Diebolt, J. and Robert, C.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Pages = {363-375},
	Title = {Estimation of finite mixture distributions through {B}ayesian sampling},
	Volume = {56},
	Year = {1994}}

@book{Jordan:1999a,
	Address = {Cambridge, MA},
	Editor = {Jordan, M.},
	Publisher = {MIT Press},
	Title = {Learning in Graphical Models},
	Year = {1999}}

@phdthesis{Erosheva:2002,
	Author = {Erosheva, E.},
	School = {Carnegie Mellon University, Department of Statistics},
	Title = {Grade of membership and latent structure models with application to disability survey data},
	Year = {2002}}

@article{Escobar:1995,
	Author = {Escobar, M. and West, M.},
	Journal = {Journal of the American Statistical Association},
	Pages = {577--588},
	Title = {Bayesian density estimation and inference using mixtures},
	Volume = {90},
	Year = {1995}}

@article{Ewens:1972,
	Author = {Ewens, W.},
	Journal = {Theor. Popul. Biol.},
	Pages = {87--112},
	Title = {The sampling theory of selective neutral alleles},
	Volume = {3},
	Year = {1972}}

@article{Ferguson:1973,
	Author = {Ferguson, T.},
	Journal = {The Annals of Statistics},
	Pages = {209-230},
	Title = {A {B}ayesian analysis of some nonparametric problems},
	Volume = {1},
	Year = {1973}}

@inproceedings{Friedman:1999,
	Author = {Friedman, N. and Getoor, L. and Koller, D. and Pfeffer, A.},
	Booktitle = {Proceedings of the 16th International Joint Conference on Artificial Intelligence (IJCAI)},
	Pages = {1300--1307},
	Title = {Learning Probabilistic Relational Models},
	Year = {1999}}

@article{Gelfand:1990,
	Author = {Gelfand, A. and Smith, A.},
	Journal = {Journal of the American Statistical Association},
	Pages = {398--409},
	Title = {Sampling Based Approaches to Calculating Marginal Densities},
	Volume = {85},
	Year = {1990}}

@book{Gelman:2003,
	Address = {London},
	Author = {Gelman, A. and Carlin, J. and Stern, H. and Rubin, D.},
	Edition = {2nd},
	Publisher = {Chapman \& Hall},
	Title = {{Bayesian Data Analysis, Second Edition}},
	Year = {2003}}

@article{Kass:1989,
	Author = {Kass, R. and Steffey, D.},
	Journal = {Journal of the American Statistical Association},
	Number = {407},
	Pages = {717--726},
	Title = {Approximate {B}ayesian inference in conditionally independent hierarchical models (parametric empirical {B}ayes models)},
	Volume = {84},
	Year = {1989}}

@article{Morris:1983,
	Author = {Morris, C.},
	Journal = {Journal of the American Statistical Association},
	Number = {381},
	Pages = {47--65},
	Title = {Parametric empirical {B}ayes inference: {T}heory and applications},
	Volume = {78},
	Year = {1983}}

@article{Geman:1984,
	Author = {Geman, S. and Geman, D.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Pages = {721--741},
	Title = {Stochastic relaxation, {G}ibbs distributions and the {B}ayesian restoration of images},
	Volume = {6},
	Year = {1984}}

@inproceedings{Ghahramani:2001,
	Author = {Ghahramani, Z. and Beal, M.},
	Booktitle = {NIPS 13},
	Pages = {507--513},
	Title = {Propagation Algorithms for Variational {B}ayesian Learning},
	Year = {2001}}

@book{Gilks:1996,
	Author = {Gilks, W. and Richardson, S. and Spiegelhalter, D.},
	Publisher = {Chapman and Hall},
	Title = {{M}arkov chain {M}onte {C}arlo Methods in Practice},
	Year = {1996}}

@inproceedings{Girolami:2003,
	Author = {Girolami, M. and Kaban, A.},
	Booktitle = {26th Annual International ACM Conference on Research and Development in Information Retrieval(SIGIR03)},
	Pages = {433--434},
	Title = {On an equivalence between {PLSI} and {LDA}},
	Year = {2003}}

@inproceedings{Girolami:2004,
	Author = {Girolami, M. and Kaban, A.},
	Booktitle = {Advances in Neural Information Procesing Systems 16},
	Pages = {9--16},
	Publisher = {MIT Press},
	Title = {Simplicial Mixtures of {M}arkov Chains: Distributed Modelling of Dynamic User Profiles},
	Year = {2004}}

@article{Goodrum:2000,
	Author = {Goodrum, A.},
	Journal = {Informing Science},
	Number = {2},
	Pages = {63--67},
	Title = {Image Information Retrieval: {A}n Overview of Current Research},
	Volume = {3},
	Year = {2000}}

@article{Green:2001,
	Author = {Green, P. and Richardson, S.},
	Journal = {Scand. J. Statistics},
	Pages = {355--377},
	Title = {Modelling heterogeneity with and without the {D}irichlet process},
	Volume = {28},
	Year = {2001}}

@article{Hastings:1970,
	Author = {Hastings, W.},
	Journal = {Biometrika},
	Pages = {97--109},
	Title = {{M}onte {C}arlo sampling methods using {M}arkov chains and their applications},
	Volume = {57},
	Year = {1970}}

@article{Hofmann:1999a,
	Author = {Hofmann, T.},
	Journal = {Research and Development in Information Retrieval},
	Pages = {50--57},
	Title = {Probabilistic Latent Semantic Indexing},
	Year = {1999}}

@inproceedings{Hofmann:1999,
	Author = {Hofmann, T.},
	Booktitle = {International Joint Conferences on Artificial Intelligence},
	Pages = {682--687},
	Title = {The Cluster-Abstraction Model: {U}nsupervised Learning of Topic Hierarchies from Text Data},
	Year = {1999}}

@article{Ishwaran:2003,
	Author = {Ishwaran, H. and James, L.},
	Journal = {Statistica Sinica},
	Pages = {1211--1235},
	Title = {Generalized Weighted {C}hinese Restaurant Processes for Species Sampling Mixture Models},
	Volume = {13},
	Year = {2003}}

@article{Ishwaran:2001,
	Author = {Ishwaran, H. and James, L.},
	Journal = {Journal of the American Statistical Association},
	Pages = {161--174},
	Title = {Gibbs Sampling Methods for Stick-Breaking Priors},
	Volume = {96},
	Year = {2001}}

@article{Ishwaran:2002,
	Author = {Ishwaran, H. and Zarepour, M.},
	Journal = {Canadian Journal of Statistics},
	Title = {Exact and approximate sum-representations for the {D}irichlet process},
	Year = {2002}}

@book{Jelinek:1997,
	Address = {Cambridge, MA},
	Author = {Jelinek, F.},
	Publisher = {MIT Press},
	Title = {Statistical Methods for Speech Recognition},
	Year = {1997}}

@article{Jiang:1992,
	Author = {Jiang, T. and Kadane, J. and Dickey, J.},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {231-251},
	Title = {Computation of {C}arlson's Multiple Hypergeometric Functions $R$ for {B}ayesian Applications},
	Volume = {1},
	Year = {1992}}

@incollection{Joachims:1999,
	Author = {Joachims, T.},
	Booktitle = {Advances in Kernel Methods - Support Vector Learning},
	Publisher = {M.I.T. Press},
	Title = {Making large-Scale {SVM} Learning Practical},
	Year = {1999}}

@article{Jordan:1999,
	Author = {Jordan, M. and Ghahramani, Z. and Jaakkola, T. and Saul, L.},
	Journal = {Machine Learning},
	Pages = {183-233},
	Title = {Introduction to Variational Methods for Graphical Models},
	Volume = {37},
	Year = {1999}}

@article{Kass:1995,
	Author = {Kass, R. and Raftery, A.},
	Journal = {Journal of the American Statistical Association},
	Number = {430},
	Pages = {773--795},
	Title = {{B}ayes factors},
	Volume = {90},
	Year = {1995}}

@article{Gelfand:2002,
	Author = {Gelfand, A. and Kottas, A.},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {289--305},
	Title = {A Computational Approach for Full Nonparametric {B}ayesian Inference Under {D}irichlet Process Mixture Models},
	Volume = {11},
	Year = {2002}}

@article{Leisink:2001,
	Author = {Leisink, M. and Kappen, H.},
	Journal = {Neural Computation},
	Month = {September},
	Number = {9},
	Pages = {2149--2171},
	Title = {A Tighter Bound for Graphical Models},
	Volume = {13},
	Year = {2001}}

@inproceedings{Leisink:2002,
	Author = {Leisink, M. and Kappen, H.},
	Booktitle = {Uncertainty in Artificial Intelligence, Proceedings of the Eighteenth Conference},
	Title = {General lower bounds based on computer generated higher order expansions},
	Year = {2002}}

@article{Liu:1996,
	Author = {Liu, J.},
	Journal = {The Annals of Statistics},
	Pages = {911-930},
	Title = {Nonparametric hierarchical Bayes via sequential imputation},
	Volume = {24},
	Year = {1996}}

@article{Lo:1984,
	Author = {Lo, A.},
	Journal = {The Annals of Statistics},
	Number = {1},
	Pages = {351-357},
	Title = {On a class of {B}ayesian nonparametric estimates: I. {D}ensity estimates},
	Volume = {12},
	Year = {1984}}

@article{MacEachern:1998,
	Author = {MacEachern, S. and Muller, P.},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {223-238},
	Title = {Estimating mixture of {D}irichlet process models},
	Volume = {7},
	Year = {1998}}

@book{Maritz:1989,
	Address = {London},
	Author = {Maritz, J. and Lwin, T.},
	Publisher = {Chapman \& Hall},
	Series = {Monographs on Statistics and Applied Probability},
	Title = {Empirical {B}ayes methods},
	Year = {1989}}

@article{Meghini:2001,
	Author = {Meghini, C. and Sebastiani, F. and Straccia, U.},
	Journal = {Journal of the ACM (JACM)},
	Number = {5},
	Pages = {909--970},
	Title = {A model of multimedia information retrieval},
	Volume = {48},
	Year = {2001}}

@inproceedings{Meghini:1997,
	Address = {Pisa, IT},
	Author = {Meghini, C. and Sebastiani, F. and U., Straccia},
	Booktitle = {Proceedings of ECDL-97, 1st European Conference on Research and Advanced Technology for Digital Libraries},
	Editor = {Peters, Carol and Thanos, Costantino},
	Pages = {325--344},
	Title = {Modelling the Retrieval of Structured Documents Containing Texts and Images},
	Year = {1997}}

@article{Heckerman:2001,
	Author = {Heckerman, D. and Meila, M.},
	Journal = {Machine Learning},
	Pages = {9-29},
	Title = {An Experimental Comparison of Several Clustering and Initialization Methods},
	Volume = {42},
	Year = {2001}}

@techreport{Minka:2000,
	Author = {Minka, T.},
	Institution = {M.I.T.},
	Title = {Estimating a {D}irichlet Distribution},
	Year = {2000}}

@article{Naphade:2001,
	Author = {Naphade, M. and Huang, T.},
	Journal = {IEEE Transactions on Multimedia},
	Month = {March},
	Number = {1},
	Pages = {141--151},
	Title = {A Probabilistic Framework for Semantic Video Indexing, Filtering and Retrieval},
	Volume = {3},
	Year = {2001}}

@article{Neal:2000,
	Author = {Neal, R.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {2},
	Pages = {249--265},
	Title = {{M}arkov Chain Sampling Methods for {D}irichlet Process Mixture Models},
	Volume = {9},
	Year = {2000}}

@techreport{Neal:1993,
	Author = {Neal, R.},
	Institution = {Department of Computer Science, University of Toronto},
	Number = {CRG-TR-93-1},
	Title = {Probabilistic Inference Using {M}arkov Chain {M}onte {C}arlo Methods},
	Year = {1993}}

@incollection{Neal:1999,
	Author = {Neal, Radford M. and Hinton, Geoffrey E.},
	Booktitle = {Learning in graphical models},
	Pages = {355--368},
	Publisher = {MIT Press},
	Title = {A view of the {EM} algorithm that justifies incremental, sparse, and other variants},
	Year = {1999}}

@article{Newman:2003,
	Author = {Newman, M.},
	Journal = {SIAM Review},
	Pages = {167--256},
	Title = {The structure and function of complex networks},
	Volume = {45},
	Year = {2003}}

@article{Nigam:2000,
	Author = {Nigam, K. and Mc{C}allum, A. and Thrun, S. and Mitchell, T.},
	Journal = {Machine Learning},
	Number = {2/3},
	Pages = {103--134},
	Title = {Text Classification from Labeled and Unlabeled Documents using {EM}},
	Volume = {39},
	Year = {2000}}

@article{Nigam:1999,
	Author = {Nigam, K. and Lafferty, J. and Mc{C}allum, A.},
	Journal = {IJCAI-99 Workshop on Machine Learning for Information Filtering},
	Pages = {61-67},
	Title = {Using Maximum Entropy for Text Classification},
	Year = {1999}}

@inproceedings{Papadimitriou:1998,
	Author = {Papadimitriou, C. and Tamaki, H. and Raghavan, P. and Vempala, S.},
	Booktitle = {Proceedings of the 17th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
	Pages = {159--168},
	Title = {Latent Semantic Indexing: {A} Probabilistic Analysis},
	Year = {1998}}

@book{Pitman:2002,
	Address = {New York, NY},
	Author = {Pitman, J.},
	Publisher = {Springer-Verlag},
	Series = {Lecture Notes for St. Flour Summer School},
	Title = {Combinatorial Stochastic Processes},
	Year = {2002}}

@inproceedings{Ponte:1998,
	Author = {Ponte, J. and Croft, B.},
	Booktitle = {ACM SIGIR 1998},
	Pages = {275--281},
	Title = {A Language Modeling Approach to Information Retrieval},
	Year = {1998}}

@inproceedings{Popescul:2001,
	Author = {Popescul, A. and Ungar, L. and Pennock, D. and Lawrence, S.},
	Booktitle = {Uncertainty in Artificial Intelligence, Proceedings of the Seventeenth Conference},
	Title = {Probabilistic Models for Unified Collaborative and Content-Based Recommendation in Sparse-Data Environments},
	Year = {2001}}

@article{Potthoff:2000,
	Author = {Potthoff, R. and Manton, K. and Woodbury, M.},
	Journal = {Journal of Classification},
	Pages = {315--353},
	Title = {{D}irichlet generalizations of latent-class models},
	Volume = {17},
	Year = {2000}}

@article{Pritchard:2000,
	Author = {Pritchard, J. and Stephens, M. and Donnelly, P.},
	Journal = {Genetics},
	Month = {June},
	Pages = {945--959},
	Title = {Inference of population structure using multilocus genotype data},
	Volume = {155},
	Year = {2000}}

@article{Raftery:1992,
	Author = {Raftery, A. and Lewis, S.},
	Journal = {Statistical Science},
	Pages = {493--497},
	Title = {One long run with diagnostics: {I}mplementation strategies for {M}arkov chain {M}onte {C}arlo},
	Volume = {7},
	Year = {1992}}

@inproceedings{Rasmussen:2002,
	Address = {Cambridge, MA},
	Author = {Rasmussen, C. and Ghahramani, Z.},
	Booktitle = {Advances in Neural Information Processing Systems 14},
	Editor = {Dietterich, T. and Becker, S. and Ghahramani, Z.},
	Publisher = {MIT Press},
	Title = {Infinite Mixtures of {G}aussian Process Experts},
	Year = {2002}}

@inproceedings{Rasmussen:2003,
	Address = {Cambridge, MA},
	Author = {Rasmussen, C. and Gharamani, Z.},
	Booktitle = {Advances in Neural Information Processing Systems 15},
	Publisher = {MIT Press},
	Title = {Bayesian Monte Carlo},
	Year = {2003}}

@techreport{Rennie:2001,
	Author = {Rennie, J.},
	Institution = {M.I.T.},
	Number = {AITR-2001-004},
	Title = {Improving Multi-Class Text Classification with Naive {B}ayes},
	Year = {2001}}

@inproceedings{Robbins:,
	Author = {Robbins, H.},
	Booktitle = {Proc. Berkeley Symposium on Math. Statist. and Prob.},
	Pages = {131--148},
	Title = {An empirical {B}ayes approach to statistics}}

@book{Rockafellar:1970,
	Author = {Rockafellar},
	Publisher = {Princeton University Press},
	Title = {Convex Analysis},
	Year = {1970}}

@article{Ronning:1989,
	Author = {Ronning, G.},
	Journal = {Journal of Statistcal Computation and Simulation},
	Number = {4},
	Pages = {215-221},
	Title = {Maximum Likelihood Estimation of {D}irichlet Distributions},
	Volume = {34},
	Year = {1989}}

@book{Salton:1983,
	Author = {Salton, G. and McGill, M.},
	Editor = {Salton, G. and McGill, M.},
	Publisher = {McGraw-Hill},
	Title = {Introduction to Modern Information Retrieval},
	Year = {1983}}

@inproceedings{Segal:2002,
	Address = {Cambridge, MA},
	Author = {Segal, E. and Koller, D. and Ormoneit, D.},
	Booktitle = {Advances in Neural Information Processing Systems 14},
	Editor = {Dietterich, T. G. and Becker, S. and Ghahramani, Z.},
	Publisher = {MIT Press},
	Title = {Probabilistic Abstraction Hierarchies},
	Year = {2002}}

@article{Sethuraman:1994,
	Author = {Sethuraman, J.},
	Journal = {Statistica Sinica},
	Pages = {639--650},
	Title = {A Constructive Definition of {D}irichlet Priors},
	Volume = {4},
	Year = {1994}}

@article{Shi:2000,
	Author = {Shi, J. and Malik, J.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {9},
	Pages = {888--905},
	Title = {Normalized cuts and image segmentation},
	Volume = {22},
	Year = {2000}}

@article{Ueda:2002,
	Author = {Ueda, N. and Ghahramani, Z.},
	Journal = {Neural Netw.},
	Number = {10},
	Pages = {1223--1241},
	Title = {Bayesian model search for mixture models based on optimizing variational bounds},
	Volume = {15},
	Year = {2002}}

@article{Wainwright:2008,
	Author = {Wainwright, M. and Jordan, M.},
	Journal = {Foundations and Trends in Machine Learning},
	Number = {1--2},
	Pages = {1--305},
	Title = {Graphical models, exponential families, and variational inference},
	Volume = {1},
	Year = {2008}}

@article{Wang:2001,
	Author = {Wang, J. and Li, J. and Wiederhold, G.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Month = {September},
	Number = {9},
	Pages = {947--983},
	Title = {{SIMPLI}city: {S}emantics-sensitive Integrated Matching for Picture Libraries},
	Volume = {23},
	Year = {2001}}

@inproceedings{Wang:2002,
	Author = {Wang, J. and Li, J.},
	Booktitle = {Proceedings of the 2002 ACM workshops on Multimedia},
	Title = {Learning-based Linguistic Indexing of PIctures with 2-{D} {MHMM}s},
	Year = {2002}}

@incollection{West:1994,
	Author = {West, M. and Muller, P. and Escobar, M.},
	Booktitle = {Aspects of Uncertainty},
	Editor = {Freeman, P. and Smith, A.},
	Pages = {363-386},
	Publisher = {John Wiley},
	Title = {Hierarchical priors and mixture models, with application in regression and density estimation},
	Year = {1994}}

@inproceedings{Yedidia:2001,
	Author = {Yedidia, J. S. and Freeman, W. T. and Weiss, Y.},
	Booktitle = {NIPS 13},
	Pages = {689--695},
	Publisher = {MIT Press},
	Title = {Generalized belief propagation},
	Year = {2001}}

@article{Rijsbergen:1975,
	Author = {van Rijsbergen, C. and Croft, W.},
	Journal = {Information Processing and Management},
	Pages = {71-182},
	Title = {Document Clustering: An Evaluation of Some Experiments with the Cranfield 1400 Collection},
	Volume = {11},
	Year = {1975}}

@inproceedings{Griffiths:2002,
	Author = {Griffiths, T. and Steyvers, M.},
	Booktitle = {Proceedings of the 24th Annual Conference of the Cognitive Science Society},
	Title = {A probabilistic approach to semantic representation},
	Year = {2002}}

@inproceedings{Blei:2002a,
	Address = {Cambridge, MA},
	Author = {Blei, D. and Ng, A. and Jordan, M.},
	Booktitle = {Advances in Neural Information Processing Systems ({NIPS}) 12},
	Editor = {Dietterich, T. G. and Becker, S. and Ghahramani, Z.},
	Publisher = {MIT Press},
	Title = {Latent {D}irichlet Allocation},
	Year = {2002}}

@inproceedings{Minka:2002,
	Author = {Minka, T. and Lafferty, J.},
	Booktitle = {Uncertainty in Artificial Intelligence (UAI)},
	Title = {Expectation-propagation for the generative aspect model},
	Year = {2002}}

@inproceedings{Minka:2001,
	Author = {Minka, T.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Expectation propagation for approximate {B}ayesian inference},
	Year = {2001}}

@article{Avery:2002,
	Author = {Avery, L.},
	Title = {Caenorrhabditis Genetic Center Bibliography},
	Year = {2002}}

@misc{Roweis:1987,
	Author = {Roweis, S.},
	Title = {{NIPS} Abstracts},
	Year = {1987--1999}}

@inproceedings{Harman:1992,
	Author = {Harman, D.},
	Booktitle = {Proceedings of the First Text Retrieval Conference (TREC-1)},
	Pages = {1--20},
	Title = {Overview of the First Text Retrieval Conference ({TREC-1})},
	Year = {1992}}

@article{Bush:1945,
	Author = {Bush, V.},
	Journal = {The Atlantic monthly},
	Title = {As We May Think},
	Year = {1945}}

@article{Beeferman:1999,
	Author = {Beeferman, D. and Berger, A. and Lafferty, J.},
	Journal = {Machine Learning},
	Pages = {177--210},
	Title = {Statistical models for text segmentation},
	Volume = {34},
	Year = {1999}}

@article{Rabiner:1989,
	Author = {Rabiner, L. R.},
	Journal = {Proceedings of the IEEE},
	Pages = {257--286},
	Title = {A tutorial on hidden {M}arkov models and selected applications in speech recognition.},
	Volume = {77},
	Year = {1989}}

@article{Pietra:1997,
	Author = {Pietra, S. Della and Pietra, V. Della and Lafferty, J.},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Pages = {380-393},
	Title = {Inducing Features of Random Fields},
	Volume = {19},
	Year = {1997}}

@inproceedings{Lafferty:2001,
	Author = {Lafferty, J. and McCallum, A. and Pereira, F.},
	Booktitle = {Proc. 18th International Conf. on Machine Learning},
	Pages = {282--289},
	Publisher = {Morgan Kaufmann, San Francisco, CA},
	Title = {Conditional Random Fields: {P}robabilistic Models for Segmenting and Labeling Sequence Data},
	Year = {2001}}

@inproceedings{Blei:2002,
	Address = {San Francisco, CA},
	Author = {Blei, D. and Bagnell, J. and McCallum, A.},
	Booktitle = {Uncertainty in Artificial Intelligence: Proceedings of the Eighteenth Conference (UAI-2002)},
	Pages = {53--60},
	Publisher = {Morgan Kaufmann publishers},
	Title = {Learning with Scope, with Application to Information Extraction and Classification},
	Year = {2002}}

@mastersthesis{Marlin:2004,
	Author = {Marlin, B.},
	School = {University of Toronto},
	Title = {Collaborative Filtering: {A} Machine Learning Perspective},
	Year = {2004}}

@techreport{Heckerman:2004,
	Author = {Heckerman, D. and Meek, C. and Koller, D.},
	Institution = {Microsoft Research},
	Month = {March},
	Number = {MSR-TR-2004-30},
	Title = {Probabilistic Models for Relational Data},
	Year = {2004}}

@inproceedings{Bishop:2003,
	Author = {Bishop, C. and Spiegelhalter, D. and Winn, J.},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {{VIBES}: A Variational Inference Engine for {B}ayesian Networks},
	Year = {2003}}

@inproceedings{Xing:2003,
	Author = {Xing, E. and Jordan, M. and Russell, S.},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {A generalized mean field algorithm for variational inference in exponential families},
	Year = {2003}}

@article{Ghahramani:1997,
	Author = {Ghahramani, Z. and Jordan, M.},
	Journal = {Machine Learning},
	Number = {1},
	Title = {Factorial Hidden {M}arkov Models},
	Volume = {31},
	Year = {1997}}

@book{Robert:2004,
	Address = {New York, NY},
	Author = {Robert, C. and Casella, G.},
	Publisher = {Springer-Verlag},
	Series = {Springer Texts in Statistics},
	Title = {Monte {C}arlo Statistical Methods},
	Year = {2004}}

@inproceedings{Canny:2004,
	Author = {Canny, J.},
	Booktitle = {Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
	Title = {{G}a{P}: {A} Factor Model for Discrete Data},
	Year = {2004}}

@phdthesis{Blei:2004,
	Author = {Blei, D.},
	School = {U.C. Berkeley, Division of Computer Science},
	Title = {Probabilistic Models of Text and Images},
	Year = {2004}}

@article{McAuliffe:2006,
	Author = {McAuliffe, J. and Blei, D. and Jordan, M.},
	Journal = {Statistics and Computing},
	Number = {1},
	Pages = {5--14},
	Title = {Nonparametric Empirical {B}ayes for the {D}irichlet Process Mixture Model},
	Volume = {16},
	Year = {2006}}

@inproceedings{Griffiths:2005,
	Address = {Cambridge, MA},
	Author = {Griffiths, T. and Steyvers, M. and Blei, D. and Tenenbaum, J.},
	Booktitle = {Advances in Neural Information Processing Systems 17},
	Editor = {Saul, Lawrence K. and Weiss, Yair and Bottou, {L\'{e}on}},
	Pages = {537-544},
	Publisher = {MIT Press},
	Title = {Integrating Topics and Syntax},
	Year = {2005}}

@article{Aitchison:1985,
	Author = {Aitchison, J. and Lauder, I.},
	Journal = {Applied Statistics},
	Number = {2},
	Pages = {129--137},
	Title = {Kernel Density Estimation for Compositional Data},
	Volume = {34},
	Year = {1985}}

@article{Rosner:2004,
	Author = {Rosner, Gary},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Number = {3},
	Pages = {735-749},
	Title = {A method for combining inference across related nonparametric Bayesian models},
	Volume = {66},
	Year = {2004}}

@book{Croft:2003,
	Address = {Norwell, MA, USA},
	Author = {Croft, W. and Lafferty, J.},
	Publisher = {Kluwer Academic publishers},
	Title = {Language Modeling for Information Retrieval},
	Year = {2003}}

@article{Zhai:2004,
	Author = {Zhai, Chengxiang and Lafferty, John},
	Journal = {ACM Trans. Inf. Syst.},
	Number = {2},
	Pages = {179--214},
	Title = {A study of smoothing methods for language models applied to information retrieval},
	Volume = {22},
	Year = {2004}}

@inproceedings{Lafferty:2003,
	Address = {Norwell, MA, USA},
	Author = {Lafferty, John and Zhai, ChengXiang},
	Booktitle = {Language Modeling for Information Retrieval},
	Editor = {Croft, W. Bruce and Lafferty, John},
	Publisher = {Kluwer Academic publishers},
	Title = {Probabilistic relevance models based on document and query generation},
	Year = {2003}}

@article{Howard:2002,
	Author = {Howard, M. and Kahana, M.},
	Journal = {Journal of Mathematical Psychology},
	Pages = {269-299},
	Title = {A distributed representation of temporal context},
	Volume = {46},
	Year = {2002}}

@article{Manns:2007,
	Author = {Manns, J. and Howard, M. and Eichenbaum, H.},
	Journal = {Neuron},
	Month = {Nov},
	Number = {3},
	Pages = {530--40},
	Title = {Gradual changes in hippocampal activity support remembering the order of events},
	Volume = {56},
	Year = {2007}}

@incollection{Steyvers:2004,
	Address = {Washington, D. C.},
	Author = {Steyvers, M. and Shiffrin, R. and Nelson, D.},
	Booktitle = {Experimental Cognitive Psychology and its Applications},
	Editor = {Healy, A.},
	Publisher = {American Psychological Association},
	Title = {Word Association Spaces for Predicting Semantic Similarity Effects in Episodic Memory},
	Year = {2004}}

@article{Howard:1999,
	Author = {Howard, M. and Kahana, M.},
	Journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	Pages = {923},
	Title = {Contextual Variability and Serial Position Effects in Free Recall.},
	Volume = {25},
	Year = {1999}}

@article{Kahana:1996,
	Author = {Kahana, M.},
	Journal = {Memory and Cognition},
	Pages = {103-109},
	Title = {Associative retrieval processes in free recall},
	Volume = {24},
	Year = {1996}}

@article{Polyn:2005b,
	Author = {Polyn, S. and Natu, V. and Cohen, J. and Norman, K.},
	Journal = {Science},
	Month = {Dec},
	Number = {5756},
	Pages = {1963--1966},
	Title = {Category-specific cortical activity precedes retrieval during memory search},
	Volume = {310},
	Year = {2005}}

@article{Norman:2006,
	Author = {Norman, K. and Polyn, S. and Detre, G. and Haxby, J.},
	Journal = {Trends Cogn Sci},
	Month = {Sep},
	Number = {9},
	Pages = {424--430},
	Title = {Beyond mind-reading: {M}ulti-voxel pattern analysis of {fMRI} data.},
	Volume = {10},
	Year = {2006}}

@article{McDuff:2010,
	Author = {McDuff, S. and Frankel, H. and Norman, K.},
	Journal = {Journal of Neuroscience},
	Title = {Multi-voxel pattern analysis reveals increased memory targeting and reduced use of retrieved details during single-agenda source monitoring},
	Year = {in press}}

@incollection{Norman:2010,
	Address = {New York},
	Author = {Norman, K. and Quamme, J. and Newman, E.},
	Booktitle = {Neuroimaging of Human Memory},
	Editor = {Roesler, F. and Ranganath, C. and Roeder, B. and Kluwe, R. H.},
	Publisher = {Oxford University Press},
	Title = {Multivariate methods for tracking cognitive states},
	Year = {in press}}

@article{Polyn:2010,
	Author = {Polyn, S. and Norman, K. and Kahana, M.},
	Journal = {Psychological Review},
	Title = {Episodic and semantic organization during free recall: The control of memory search},
	Year = {in press}}

@incollection{Norman:2008,
	Address = {New York},
	Author = {Norman, K. and Detre, G. and Polyn, S.},
	Booktitle = {The {Cambridge} handbook of computational psychology},
	Editor = {Sun, R.},
	Publisher = {Cambridge University Press},
	Title = {Computational models of episodic memory},
	Year = {2008}}

@article{Detre:2006,
	Author = {Detre, G. and Polyn, S. and Moore, C. and Natu, V. and Singer, B. and Cohen, J. and Haxby, J. and Norman, K.},
	Journal = {Poster presented at the Annual Meeting of the Organization for Human Brain Mapping},
	Title = {{The Multi-Voxel Pattern Analysis (MVPA) toolbox}},
	Year = {2006}}

@article{Amari:1998,
	Author = {Amari, S.},
	Journal = {Neural computation},
	Number = {2},
	Pages = {251--276},
	Title = {Natural gradient works efficiently in learning},
	Volume = {10},
	Year = {1998}}

@article{Blei:2012,
	Author = {Blei, D.},
	Journal = {Communications of the ACM},
	Number = {4},
	Pages = {77--84},
	Title = {Probabilistic Topic Models},
	Volume = {55},
	Year = {2012}}

@book{Fox:2010,
	Author = {Fox, J.},
	Publisher = {Springer Verlag},
	Title = {Bayesian Item Response Modeling: {T}heory and Applications},
	Year = {2010}}

@article{Fox:2011,
	Author = {Fox, Emily B and Sudderth, Erik B and Jordan, Michael I and Willsky, Alan S},
	Journal = {The Annals of Applied Statistics},
	Pages = {1020--1056},
	Publisher = {JSTOR},
	Title = {A sticky HDP-HMM with application to speaker diarization},
	Year = {2011}}

@inproceedings{Gershman:2012a,
	Author = {S. Gershman and M. Hoffman and D. Blei},
	Booktitle = {International Conference on Machine Learning},
	Title = {Nonparametric Variational Inference},
	Year = {2012}}

@book{Kushner:1997,
	Author = {Kushner, H. and Yin, G.},
	Date-Added = {2012-07-11 12:01:23 -0400},
	Date-Modified = {2012-07-11 12:01:50 -0400},
	Publisher = {Springer New York},
	Title = {Stochastic Approximation Algorithms and Applications},
	Year = {1997}}

@article{Paisley:2015,
	Author = {Paisley, John and Wang, Chingyue and Blei, David M and Jordan, Michael and others},
	Journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	Number = {2},
	Pages = {256--270},
	Publisher = {IEEE},
	Title = {Nested hierarchical Dirichlet processes},
	Volume = {37},
	Year = {2015}}

@article{Geisser:1975,
	Author = {Geisser, Seymour},
	Journal = {Journal of the American Statistical Association},
	Number = {350},
	Pages = {320--328},
	Publisher = {Taylor \& Francis Group},
	Title = {The predictive sample reuse method with applications},
	Volume = {70},
	Year = {1975}}

@article{Foti:2015,
	Author = {Foti, Nicholas J and Williamson, Sinead and others},
	Journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	Number = {2},
	Pages = {359--371},
	Publisher = {IEEE},
	Title = {A survey of non-exchangeable priors for Bayesian nonparametric models},
	Volume = {37},
	Year = {2015}}

@article{Shah:2014,
	Author = {Shah, Amar and Wilson, Andrew Gordon and Ghahramani, Zoubin},
	Journal = {arXiv preprint arXiv:1402.4306},
	Title = {Student-t processes as alternatives to Gaussian processes},
	Year = {2014}}

@article{Griffin:2014,
	Author = {Griffin, Jim E and Leisen, Fabrizio},
	Journal = {arXiv preprint arXiv:1410.0611},
	Title = {Compound random measures and their use in Bayesian nonparametrics},
	Year = {2014}}

@inproceedings{Titsias:2009,
	Author = {Titsias, Michalis K},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Pages = {567--574},
	Title = {Variational learning of inducing variables in sparse Gaussian processes},
	Year = {2009}}

@article{Salimans:2013,
	Author = {Salimans, Tim and Knowles, David A and others},
	Journal = {Bayesian Analysis},
	Number = {4},
	Pages = {837--882},
	Publisher = {International Society for Bayesian Analysis},
	Title = {Fixed-form variational posterior approximation through stochastic linear regression},
	Volume = {8},
	Year = {2013}}

@inproceedings{Ranganath:2014,
	Author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David},
	Booktitle = {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics},
	Pages = {814--822},
	Title = {$\{$Black Box Variational Inference$\}$},
	Year = {2014}}

@article{Rezende:2014,
	Archiveprefix = {arXiv},
	Author = {{Rezende}, D. and {Mohamed}, S. and {Wierstra}, D.},
	Eprint = {1401.4082},
	Journal = {ArXiv e-prints},
	Month = Jan,
	Primaryclass = {stat.ML},
	Title = {Stochastic Back-propagation and Variational Infernece in Deep Latent Gaussian Models},
	Year = 2014}

@inproceedings{Titsias:2014,
	Author = {Titsias, Michalis and L{\'a}zaro-Gredilla, Miguel},
	Booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
	Pages = {1971--1979},
	Title = {Doubly stochastic variational bayes for non-conjugate inference},
	Year = {2014}}

@inproceedings{Kingma:2014,
	Author = {{Kingma}, D. and {Welling}, M.},
	Booktitle = {International Conference on Learning Representations (ICLR-14)},
	Title = {Auto-Encoding Variational Bayes},
	Year = 2014}

@inproceedings{Rezende:2015,
	Author = {Rezende, Danilo J., and Mohamed, Shakir},
	Booktitle = {International Conference on Machine Learning},
	Date-Modified = {2017-02-24 21:21:51 +0000},
	Title = {Variational Inference with Normalizing Flows},
	Year = {2015}}

@inproceedings{Stuhlmuller:2013,
	Author = {Stuhlm{\"u}ller, Andreas and Taylor, Jacob and Goodman, Noah},
	Booktitle = {Advances in neural information processing systems},
	Pages = {3048--3056},
	Title = {Learning stochastic inverses},
	Year = {2013}}

@article{Assaraf:1999,
	Author = {Assaraf, Roland and Caffarel, Michel},
	Journal = {Physical review letters},
	Number = {23},
	Pages = {4682},
	Publisher = {APS},
	Title = {Zero-variance principle for monte carlo algorithms},
	Volume = {83},
	Year = {1999}}

@inproceedings{Williams:1992,
	Author = {Ronald J. Williams},
	Booktitle = {Machine Learning},
	Pages = {229--256},
	Title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	Year = {1992}}

@misc{stan-software:2015,
	Author = {{Stan Development Team}},
	Title = {Stan: A C++ Library for Probability and Sampling, Version 2.8.0},
	Url = {http://mc-stan.org/},
	Year = {2015},
	Bdsk-Url-1 = {http://mc-stan.org/}}

@inproceedings{Bergstra:2010,
	Author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
	Booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
	Location = {Austin, TX},
	Month = jun,
	Title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
	Year = {2010}}

@article{Finetti:1931,
	Author = {De Finetti, Bruno},
	Publisher = {Academia Nazionale del Linceo},
	Title = {Funzione caratteristica di un fenomeno aleatorio},
	Year = {1931}}

@article{Dayan:2000,
	Author = {Dayan, Peter},
	Journal = {Handbook of Brain Theory and Neural Network. MIT Press, Cambridge, MA},
	Title = {Helmholtz machines and wake-sleep learning},
	Year = {2000}}

@inproceedings{Titsias:2015,
	Author = {Titsias, Michalis K},
	Booktitle = {Neural Information Processing Systems},
	Title = {{Local Expectation Gradients for Doubly Stochastic Variational Inference}},
	Year = {2015}}

@incollection{Jaakkola:1998,
	Address = {Dordrecht},
	Author = {Jaakkola, Tommi S and Jordan, Michael I},
	Booktitle = {Learning in Graphical Models},
	Pages = {163--173},
	Publisher = {Springer Netherlands},
	Title = {{Improving the Mean Field Approximation Via the Use of Mixture Distributions}},
	Year = {1998}}

@inproceedings{Kucukelbir:2015,
	Author = {Kucukelbir, Alp and Ranganath, Rajesh and Gelman, Andrew and Blei, David M},
	Booktitle = {Neural Information Processing Systems},
	Title = {{Automatic Variational Inference in Stan}},
	Year = {2015}}

@inproceedings{Mnih:2014,
	Author = {Mnih, Andriy and Gregor, Karol},
	Booktitle = {International Conference on Machine Learning},
	Title = {Neural variational inference and learning in belief networks},
	Year = {2014}}

@inproceedings{Tran:2015,
	Author = {Dustin Tran and David M. Blei and Edoardo M. Airoldi},
	Booktitle = {Neural Information Processing Systems},
	Title = {Copula variational inference},
	Year = {2015}}

@inproceedings{Ranganath:2015,
	Author = {Ranganath, Rajesh and Tang, Linpeng and Charlin, Laurent and Blei, David M},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {{Deep Exponential Families}},
	Year = {2015}}

@book{Nelsen:2006,
	Author = {Nelsen, Roger B.},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {An Introduction to Copulas (Springer Series in Statistics)},
	Year = {2006}}

@article{Robbins:1964,
	Author = {Robbins, Herbert},
	Journal = {The Annals of Mathematical Statistics},
	Pages = {1--20},
	Publisher = {JSTOR},
	Title = {The empirical Bayes approach to statistical decision problems},
	Year = {1964}}

@incollection{Ruckstiess:2008,
	Author = {R{\"u}ckstie{\ss}, Thomas and Felder, Martin and Schmidhuber, J{\"u}rgen},
	Booktitle = {Machine Learning and Knowledge Discovery in Databases},
	Pages = {234--249},
	Publisher = {Springer},
	Title = {State-dependent exploration for policy gradient methods},
	Year = {2008}}

@incollection{Sehnke:2008,
	Author = {Sehnke, Frank and Osendorfer, Christian and R{\"u}ckstie{\ss}, Thomas and Graves, Alex and Peters, Jan and Schmidhuber, J{\"u}rgen},
	Booktitle = {Artificial Neural Networks-ICANN 2008},
	Pages = {387--396},
	Publisher = {Springer},
	Title = {Policy gradients with parameter-based exploration for control},
	Year = {2008}}

@book{efron2012large,
	Author = {Efron, Bradley},
	Publisher = {Cambridge University Press},
	Title = {Large-scale inference: empirical Bayes methods for estimation, testing, and prediction},
	Volume = {1},
	Year = {2012}}

@inproceedings{rezende2014stochastic,
	Author = {Rezende, Danilo J. and Mohamed, Shakir and Wierstra, Daan},
	Booktitle = {International Conference on Machine Learning},
	Date-Modified = {2020-05-19 11:32:40 -0400},
	Title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
	Year = {2014}}

@inproceedings{ranganath2015deep,
	Author = {Ranganath, Rajesh and Tang, Linpeng and Charlin, Laurent and Blei, David M},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Deep Exponential Families},
	Year = {2015}}

@inproceedings{gregor2015draw,
	Author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
	Booktitle = {International Conference on Machine Learning},
	Title = {{DRAW}: {A} Recurrent Neural Network For Image Generation},
	Year = {2015}}

@inproceedings{hinton1993keeping,
	Author = {Hinton, G. and Van Camp, D.},
	Booktitle = {Computational Learning Theory},
	Organization = {ACM},
	Pages = {5--13},
	Title = {Keeping the neural networks simple by minimizing the description length of the weights},
	Year = {1993}}

@inproceedings{waterhouse1996bayesian,
	Author = {Waterhouse, S. and MacKay, D. and Robinson, T.},
	Booktitle = {Neural Information Processing Systems},
	Title = {{B}ayesian methods for mixtures of experts},
	Year = {1996}}

@article{jordan1999introduction,
	Author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
	Date-Modified = {2017-02-24 21:36:50 +0000},
	Journal = {Machine Learning},
	Number = {2},
	Pages = {183--233},
	Publisher = {Springer},
	Title = {An introduction to variational methods for graphical models},
	Volume = {37},
	Year = {1999}}

@article{wainwright2008graphical,
	Author = {Wainwright, Martin J. and Jordan, Michael I.},
	Date-Modified = {2017-02-24 21:24:26 +0000},
	Journal = {Foundations and Trends in Machine Learning},
	Number = {1-2},
	Pages = {1--305},
	Publisher = {Now Publishers Inc.},
	Title = {Graphical models, exponential families, and variational inference},
	Volume = {1},
	Year = {2008}}

@inproceedings{damianou2013deep,
	Author = {Damianou, Andreas C and Lawrence, Neil D},
	Booktitle = {Artificial Intelligence and Statistics},
	Title = {Deep {G}aussian Processes},
	Year = {2013}}

@book{gelman2013bayesian,
	Author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
	Edition = {Third},
	Publisher = {CRC Press, Boca Raton, FL},
	Series = {Texts in Statistical Science Series},
	Title = {{Bayesian data analysis}},
	Year = {2013}}

@article{blei2014build,
	Author = {Blei, David M},
	Journal = {Annual Review of Statistics and Its Application},
	Title = {{Build, compute, critique, repeat: Data analysis with latent variable models}},
	Year = {2014}}

@inproceedings{ranganath2016hierarchical,
	Author = {Ranganath, Rajesh and Tran, Dustin and Blei, David M},
	Booktitle = {International Conference on Machine Learning},
	Title = {Hierarchical variational models},
	Year = {2016}}

@inproceedings{tran2016variational,
	Author = {Tran, Dustin and Ranganath, Rajesh and Blei, David M},
	Booktitle = {International Conference on Learning Representations},
	Title = {The variational {G}aussian process},
	Year = {2016}}

@article{hoffman2013stochastic,
	Author = {Hoffman, Matthew D. and Blei, David M. and Wang, Chong and Paisley, John},
	Date-Modified = {2017-02-24 21:05:38 +0000},
	Journal = {Journal of Machine Learning Research},
	Pages = {1303--1347},
	Title = {Stochastic Variational Inference},
	Volume = {14},
	Year = {2013}}

@inproceedings{kingma2014autoencoding,
	Author = {Kingma, Diederik P and Welling, Max},
	Booktitle = {International Conference on Learning Representations},
	Title = {Auto-Encoding Variational {B}ayes},
	Year = {2014}}

@inproceedings{minka2001expectation,
	Author = {Thomas P. Minka},
	Booktitle = {Uncertainty in Artificial Intelligence},
	Title = {Expectation Propagation for approximate {B}ayesian inference},
	Year = {2001}}

@techreport{minka2004power,
	Author = {Thomas P. Minka},
	Institution = {Microsoft Research, Cambridge},
	Title = {Power {EP}},
	Year = {2004}}

@article{gelman2014expectation,
	Author = {Gelman, Andrew and Vehtari, Aki and Jyl{\"a}nki, Pasi and Robert, Christian and Chopin, Nicolas and Cunningham, John P},
	Journal = {arXiv preprint arXiv:1412.4869},
	Title = {Expectation propagation as a way of life},
	Year = {2014}}

@inproceedings{goodfellow2014generative,
	Author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, M and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	Booktitle = {Neural Information Processing Systems},
	Title = {{Generative adversarial nets}},
	Year = {2014}}

@inproceedings{kingma2014semi,
	Author = {Kingma, Diederik P and Rezende, Danilo J and Mohamed, Shakir and Welling, Max},
	Booktitle = {Neural Information Processing Systems},
	Title = {{Semi-supervised Learning with Deep Generative Models}},
	Year = {2014}}

@article{rezende2016one,
	Author = {Rezende, D J and Mohamed, S and Danihelka, I and Gregor, Karol and Wierstra, Daan},
	Eprint = {16418227374416270076},
	Eprinttype = {scholar},
	Journal = {arXiv.org},
	Title = {{One-Shot Generalization in Deep Generative Models}},
	Year = {2016}}

@article{xu2015show,
	Author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
	Journal = {arXiv preprint arXiv:1502.03044},
	Title = {Show, attend and tell: Neural image caption generation with visual attention},
	Year = {2015}}

@article{hernandezlobato2015black,
	Author = {Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Li, Yingzhen and Rowland, Mark and Hern{\'a}ndez-Lobato, Daniel and Bui, Thang and Turner, Richard E},
	Eprint = {1511.03243},
	Eprinttype = {arxiv},
	Journal = {arXiv.org},
	Month = nov,
	Title = {{Black-box $\alpha$-divergence Minimization}},
	Year = {2015}}

@article{parikh2014proximal,
	Author = {Parikh, Neal and Boyd, Stephen and others},
	Journal = {Foundations and Trends{\textregistered} in Optimization},
	Number = {3},
	Pages = {127--239},
	Publisher = {Now Publishers, Inc.},
	Title = {Proximal algorithms},
	Volume = {1},
	Year = {2014}}
